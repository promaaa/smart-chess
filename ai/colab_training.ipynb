{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a272705",
   "metadata": {},
   "source": [
    "# üöÄ Entra√Ænement Chess NN sur GPU (Google Colab)\n",
    "\n",
    "Ce notebook entra√Æne ton r√©seau de neurones d'√©valuation d'√©checs sur GPU.\n",
    "\n",
    "## ‚ö° Configuration GPU\n",
    "**IMPORTANT**: Active le GPU avant de commencer !\n",
    "- Menu: **Runtime** ‚Üí **Change runtime type**\n",
    "- Hardware accelerator: **GPU (T4)**\n",
    "- Clique **Save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa491698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier que le GPU est bien activ√©\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è AUCUN GPU D√âTECT√â! Va dans Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaed9a",
   "metadata": {},
   "source": [
    "## üì¶ Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas tqdm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2116a4ba",
   "metadata": {},
   "source": [
    "## üìÇ Upload du code et dataset\n",
    "\n",
    "**Option 1: Upload direct** (pour petits fichiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04aef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Upload tes fichiers Python\n",
    "print(\"Upload Chess.py, torch_nn_evaluator.py, train_torch.py\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# IMPORTANT: Pour le dataset (13M lignes = gros fichier),\n",
    "# utilise plut√¥t Google Drive (voir Option 2 ci-dessous)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf7c6c",
   "metadata": {},
   "source": [
    "**Option 2: Google Drive** (RECOMMAND√â pour gros dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copie ton dataset dans Google Drive d'abord (via l'interface web)\n",
    "# Puis adapte ce chemin:\n",
    "# !cp \"/content/drive/MyDrive/chessData.csv\" .\n",
    "\n",
    "# Ou upload les fichiers Python depuis ton repo GitHub:\n",
    "# !git clone https://github.com/promaaa/smart-chess.git\n",
    "# !cp smart-chess/ai/*.py ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4bf55",
   "metadata": {},
   "source": [
    "## üîß Code: Chess.py\n",
    "Colle ton code Chess.py ici (ou upload via la cellule pr√©c√©dente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94800dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Chess.py\n",
    "# COLLE TON CODE Chess.py ICI\n",
    "# Ou skip cette cellule si tu as upload√© le fichier\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf07f6b",
   "metadata": {},
   "source": [
    "## üîß Code: torch_nn_evaluator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc836e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile torch_nn_evaluator.py\n",
    "# COLLE TON CODE torch_nn_evaluator.py ICI\n",
    "# Ou skip cette cellule si tu as upload√© le fichier\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9abf1",
   "metadata": {},
   "source": [
    "## üîß Code: train_torch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_torch.py\n",
    "# COLLE TON CODE train_torch.py ICI\n",
    "# Ou skip cette cellule si tu as upload√© le fichier\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e8f33",
   "metadata": {},
   "source": [
    "## üöÄ Lancer l'entra√Ænement!\n",
    "\n",
    "Modifie les hyperparam√®tres si n√©cessaire dans train_torch.py, puis lance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_torch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a88641c",
   "metadata": {},
   "source": [
    "## üíæ T√©l√©charger les poids entra√Æn√©s\n",
    "\n",
    "√Ä la fin de l'entra√Ænement, t√©l√©charge les poids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7234f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# T√©l√©charge les poids au format NumPy (compatible avec ton code existant)\n",
    "files.download('chess_nn_weights.npz')\n",
    "\n",
    "# T√©l√©charge aussi le checkpoint PyTorch (pour continuer l'entra√Ænement plus tard)\n",
    "files.download('chess_model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4ab17",
   "metadata": {},
   "source": [
    "## üß™ Test rapide du mod√®le entra√Æn√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4542bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chess import Chess\n",
    "from torch_nn_evaluator import load_from_npz\n",
    "import torch\n",
    "\n",
    "# Charger le mod√®le\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model, _ = load_from_npz('chess_nn_weights.npz', device=device)\n",
    "\n",
    "# Tester sur quelques positions\n",
    "chess = Chess()\n",
    "\n",
    "# Position initiale\n",
    "chess.load_fen(\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\")\n",
    "score = model.evaluate_position(chess, device=device)\n",
    "print(f\"Position initiale: {score:.2f} centipawns (devrait √™tre proche de 0)\")\n",
    "\n",
    "# Position avec avantage blanc\n",
    "chess.load_fen(\"rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2\")\n",
    "score = model.evaluate_position(chess, device=device)\n",
    "print(f\"Position sym√©trique: {score:.2f} centipawns\")\n",
    "\n",
    "# Mat en 1\n",
    "chess.load_fen(\"r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR b KQkq - 0 1\")\n",
    "score = model.evaluate_position(chess, device=device)\n",
    "print(f\"Mat en 1 (blancs gagnent): {score:.2f} centipawns (devrait √™tre tr√®s positif)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d57b0",
   "metadata": {},
   "source": [
    "## üìä Visualiser les performances\n",
    "\n",
    "Tu peux aussi copier-coller ton script test_generalization.py pour voir la g√©n√©ralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163656a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üí° Conseils\n",
    "\n",
    "1. **Augmente MAX_SAMPLES** : Avec un GPU, tu peux facilement faire 1M positions/epoch\n",
    "2. **Batch size** : Augmente √† 256 ou 512 si tu as assez de GPU memory\n",
    "3. **Sauvegarde r√©guli√®re** : Colab peut te d√©connecter apr√®s 12h, sauvegarde r√©guli√®rement!\n",
    "4. **Reprendre l'entra√Ænement** : Upload le checkpoint .pt et il continuera o√π tu en √©tais\n",
    "\n",
    "## üêõ Debugging\n",
    "\n",
    "Si tu as des erreurs:\n",
    "- V√©rifie que le GPU est bien activ√© (cellule 1)\n",
    "- V√©rifie que tous les fichiers sont bien upload√©s\n",
    "- R√©duis BATCH_SIZE si out of memory\n",
    "- R√©duis MAX_SAMPLES si le dataset prend trop de RAM"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
