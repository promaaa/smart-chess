# Fix: Persistance des poids et moments Adam

## üêõ Probl√®me identifi√©

L'entra√Ænement semblait r√©initialiser les poids entre les ex√©cutions. Le probl√®me √©tait en fait **la r√©initialisation des moments Adam** qui rendait l'optimisation inefficace.

### Causes :

1. **Moments Adam r√©initialis√©s √† z√©ro** √† chaque ex√©cution
   - Adam utilise des moyennes exponentielles (momentum + variance adaptative)
   - Ces moments s'accumulent au fil de l'entra√Ænement
   - Les r√©initialiser = perdre tout l'historique d'optimisation

2. **Warm-start du biais de sortie** appliqu√© m√™me sur un r√©seau d√©j√† entra√Æn√©
   - √âcrasait le biais appris

3. **Pas de diff√©renciation** entre nouveau r√©seau et r√©seau charg√©

## ‚úÖ Solution impl√©ment√©e

### 1. Sauvegarde des moments Adam

**Fichier : `nn_evaluator.py`**

```python
def save_weights(evaluator, filename, adam_moments=None):
    """
    Sauvegarde les poids + moments Adam (optionnel)
    """
    save_dict = {
        'w1': evaluator.weights1, 'b1': evaluator.biases1,
        'w2': evaluator.weights2, 'b2': evaluator.biases2,
        'w3': evaluator.weights3, 'b3': evaluator.biases3
    }
    
    if adam_moments is not None:
        save_dict.update(adam_moments)  # Ajouter m_w1, v_w1, m_b1, v_b1, ..., adam_step
    
    np.savez(filename, **save_dict)
```

### 2. Chargement des moments Adam

```python
def load_evaluator_from_file(filename):
    """
    Charge poids + moments Adam (si disponibles)
    Returns: (evaluator, adam_moments)
    """
    data = np.load(filename)
    evaluator = NeuralNetworkEvaluator(...)
    
    # Charger les moments Adam s'ils existent
    adam_keys = ['m_w1', 'v_w1', 'm_b1', 'v_b1', ..., 'adam_step']
    if all(key in data for key in adam_keys):
        adam_moments = {key: data[key] for key in adam_keys}
    else:
        adam_moments = None
    
    return evaluator, adam_moments
```

### 3. Gestion dans train.py

**Chargement intelligent :**

```python
if os.path.exists(WEIGHTS_FILE):
    evaluator, adam_moments_loaded = load_evaluator_from_file(WEIGHTS_FILE)
    is_new_network = False
else:
    evaluator = NeuralNetworkEvaluator.create_untrained_network()
    adam_moments_loaded = None
    is_new_network = True

# Warm-start SEULEMENT pour nouveau r√©seau
if is_new_network:
    evaluator.biases3[0, 0] = eval_mean
```

**Initialisation des moments :**

```python
if USE_ADAM:
    if adam_moments_loaded:
        # Charger les moments existants
        m_w1 = adam_moments_loaded['m_w1']
        v_w1 = adam_moments_loaded['v_w1']
        # ...
        adam_step = int(adam_moments_loaded['adam_step'])
    else:
        # Cr√©er de nouveaux moments
        m_w1 = np.zeros_like(evaluator.weights1)
        # ...
        adam_step = 0
```

**Sauvegarde avec moments :**

```python
if USE_ADAM:
    adam_dict = {
        'm_w1': m_w1, 'v_w1': v_w1,
        # ... tous les moments
        'adam_step': np.array(adam_step)
    }
    save_weights(evaluator, WEIGHTS_FILE, adam_moments=adam_dict)
else:
    save_weights(evaluator, WEIGHTS_FILE)
```

## üìä Impact attendu

### Avant (avec bug) :
- Moments Adam r√©initialis√©s ‚Üí Learning rate adaptatif inefficace
- Warm-start √©crasait le biais appris
- Optimisation repartait de z√©ro √† chaque ex√©cution

### Apr√®s (fix) :
- ‚úì Moments Adam persist√©s ‚Üí Optimisation continue correctement
- ‚úì Warm-start seulement pour nouveaux r√©seaux
- ‚úì Vrai entra√Ænement incr√©mental possible

## üß™ Test de validation

Script : `test_adam_persistence.py`

```bash
python test_adam_persistence.py
```

R√©sultat : **‚úì‚úì SUCC√àS - Les moments Adam sont correctement persist√©s!**

## üöÄ Prochaines √©tapes

1. **Supprimer l'ancien fichier** (sans moments Adam) :
   ```bash
   Remove-Item chess_nn_weights.npz -Force
   ```

2. **Relancer l'entra√Ænement** :
   ```bash
   python train.py
   ```

3. **V√©rifier la continuit√©** :
   - Premier run : "Initialisation de nouveaux moments Adam"
   - Runs suivants : "Moments Adam charg√©s (step=XXX)"

4. **Monitorer les am√©liorations** :
   - RMSE devrait descendre progressivement
   - Corr√©lation devrait augmenter
   - Pas de r√©gression entre les ex√©cutions

## üìù Notes techniques

- Fichier de poids maintenant plus gros (~4MB au lieu de 2MB)
- Backward compatible : anciens fichiers sans moments = cr√©ation de nouveaux moments
- Adam step global : permet de reprendre bias correction au bon endroit
- Format .npz conserve tous les arrays NumPy efficacement

## ‚úÖ Validation finale

Pour v√©rifier que tout fonctionne :

```bash
# 1. Premi√®re ex√©cution (quelques epochs)
python train.py  # ‚Üí "Initialisation de nouveaux moments Adam"

# 2. V√©rifier signature des poids
python check_weights_persistence.py  # ‚Üí Signature sauvegard√©e

# 3. Deuxi√®me ex√©cution
python train.py  # ‚Üí "Moments Adam charg√©s (step=XXX)"

# 4. Re-v√©rifier signature
python check_weights_persistence.py  # ‚Üí "‚úì Les poids ont chang√©!"
```

---

**Probl√®me r√©solu !** üéâ
