{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b5a4df",
   "metadata": {},
   "source": [
    "# Entraînement du Neural Network pour Smart Chess sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entraîner le réseau de neurones pour l'évaluation d'échecs en utilisant les ressources GPU de Google Colab.\n",
    "\n",
    "**Chemin du projet sur Drive:** `MyDrive/smart_chess_drive/smart-chess`\n",
    "\n",
    "## Instructions\n",
    "1. Aller dans **Runtime > Change runtime type > GPU** (T4 ou mieux)\n",
    "2. Exécuter les cellules dans l'ordre\n",
    "3. Les modèles seront sauvegardés automatiquement sur votre Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b4590",
   "metadata": {},
   "source": [
    "## 1. Vérification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier la disponibilité du GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddd742",
   "metadata": {},
   "source": [
    "## 2. Montage Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf2990",
   "metadata": {},
   "source": [
    "## 3. Configuration du chemin du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le chemin vers le projet sur votre Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "os.chdir(PROJECT_PATH)\n",
    "sys.path.insert(0, PROJECT_PATH)\n",
    "\n",
    "print(f\"Répertoire de travail: {os.getcwd()}\")\n",
    "print(f\"\\nContenu du répertoire:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20e36c",
   "metadata": {},
   "source": [
    "## 4. Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les packages nécessaires\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy matplotlib tqdm\n",
    "\n",
    "print(\"✓ Installation terminée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25365688",
   "metadata": {},
   "source": [
    "## 5. Vérification de l'environnement PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION SYSTÈME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"\\nCUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"Mémoire GPU totale: {props.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"⚠️ ATTENTION: GPU non disponible, l'entraînement sera très lent!\")\n",
    "    print(\"   Allez dans Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a1e23",
   "metadata": {},
   "source": [
    "## 6. Import des modules du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7397821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les modules nécessaires depuis le projet\n",
    "try:\n",
    "    from ai.NN.train_torch import (\n",
    "        train_model,\n",
    "        generate_training_data,\n",
    "        ChessDataset,\n",
    "        ChessNet\n",
    "    )\n",
    "    from ai.Chess_v2 import Chess\n",
    "    print(\"✓ Modules importés avec succès!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Erreur d'import: {e}\")\n",
    "    print(\"\\nVérifiez que vous êtes dans le bon répertoire et que tous les fichiers sont présents.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e668793",
   "metadata": {},
   "source": [
    "## 7. Configuration de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f87f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres d'entraînement\n",
    "CONFIG = {\n",
    "    # Génération de données\n",
    "    'num_games': 10000,          # Nombre de parties à générer pour l'entraînement\n",
    "    \n",
    "    # Hyperparamètres\n",
    "    'batch_size': 256,           # Taille du batch (augmenter si GPU puissant)\n",
    "    'epochs': 50,                # Nombre d'époques d'entraînement\n",
    "    'learning_rate': 0.001,      # Taux d'apprentissage\n",
    "    \n",
    "    # Configuration système\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 2,            # Workers pour le DataLoader\n",
    "    \n",
    "    # Sauvegarde\n",
    "    'checkpoint_path': 'ai/chess_model_checkpoint.pt',\n",
    "    'save_interval': 5,          # Sauvegarder tous les N époques\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION DE L'ENTRAÎNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    print(\"\\n⚠️ ATTENTION: Entraînement sur CPU détecté!\")\n",
    "    print(\"   Réduisez num_games et epochs pour un test rapide.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ad90f",
   "metadata": {},
   "source": [
    "## 8. Génération des données d'entraînement\n",
    "\n",
    "Cette étape génère des parties d'échecs aléatoires et calcule les évaluations de position.\n",
    "**Attention:** Cela peut prendre 15-30 minutes selon le nombre de parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(f\"Génération de {CONFIG['num_games']} parties...\")\n",
    "print(\"Cette opération peut prendre du temps, soyez patient!\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Générer les données\n",
    "X_train, y_train = generate_training_data(CONFIG['num_games'])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONNÉES GÉNÉRÉES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Forme de X_train: {X_train.shape}\")\n",
    "print(f\"Forme de y_train: {y_train.shape}\")\n",
    "print(f\"Nombre total de positions: {len(X_train):,}\")\n",
    "print(f\"Temps écoulé: {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n",
    "print(f\"Positions/seconde: {len(X_train)/elapsed_time:.1f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques sur les données\n",
    "print(f\"\\nStatistiques sur les évaluations:\")\n",
    "print(f\"  Min: {y_train.min():.4f}\")\n",
    "print(f\"  Max: {y_train.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.4f}\")\n",
    "print(f\"  Écart-type: {y_train.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea4dd7",
   "metadata": {},
   "source": [
    "## 9. Création du dataset et du dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Créer le dataset\n",
    "dataset = ChessDataset(X_train, y_train)\n",
    "\n",
    "# Créer le dataloader\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATALOADER CONFIGURÉ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Taille du dataset: {len(dataset):,} échantillons\")\n",
    "print(f\"Nombre de batches: {len(train_loader):,}\")\n",
    "print(f\"Taille du batch: {CONFIG['batch_size']}\")\n",
    "print(f\"Dernière batch: {len(dataset) % CONFIG['batch_size']} échantillons\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dda22",
   "metadata": {},
   "source": [
    "## 10. Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le modèle et le déplacer sur le device approprié\n",
    "model = ChessNet().to(CONFIG['device'])\n",
    "\n",
    "# Afficher l'architecture\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHITECTURE DU MODÈLE\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compter les paramètres\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nNombre total de paramètres: {total_params:,}\")\n",
    "print(f\"Paramètres entraînables: {trainable_params:,}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "\n",
    "# Estimer la taille mémoire du modèle\n",
    "param_size_mb = total_params * 4 / (1024 ** 2)  # 4 bytes par float32\n",
    "print(f\"Taille estimée du modèle: {param_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ba4a7",
   "metadata": {},
   "source": [
    "## 11. Entraînement du modèle\n",
    "\n",
    "Cette étape lance l'entraînement complet. Les checkpoints sont sauvegardés automatiquement sur votre Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DÉBUT DE L'ENTRAÎNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Époques: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device'],\n",
    "    checkpoint_path=CONFIG['checkpoint_path'],\n",
    "    save_interval=CONFIG['save_interval']\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENTRAÎNEMENT TERMINÉ!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Temps total: {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "print(f\"Temps par époque: {training_time/CONFIG['epochs']:.1f}s\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf4e17",
   "metadata": {},
   "source": [
    "## 12. Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46daebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurer le style des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Graphique 1: Loss\n",
    "axes[0].plot(history['loss'], linewidth=2, color='#2E86AB', label='Training Loss')\n",
    "axes[0].set_xlabel('Époque', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('Évolution de la perte pendant l\\'entraînement', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Afficher les valeurs min/max\n",
    "min_loss = min(history['loss'])\n",
    "max_loss = max(history['loss'])\n",
    "axes[0].axhline(y=min_loss, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_loss:.6f}')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Graphique 2: MAE (si disponible)\n",
    "if 'mae' in history:\n",
    "    axes[1].plot(history['mae'], linewidth=2, color='#F77F00', label='MAE')\n",
    "    axes[1].set_xlabel('Époque', fontsize=12)\n",
    "    axes[1].set_ylabel('MAE', fontsize=12)\n",
    "    axes[1].set_title('Erreur absolue moyenne', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    min_mae = min(history['mae'])\n",
    "    axes[1].axhline(y=min_mae, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_mae:.6f}')\n",
    "    axes[1].legend(fontsize=10)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'MAE non disponible', \n",
    "                ha='center', va='center', fontsize=14, transform=axes[1].transAxes)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Afficher les statistiques finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"Perte minimale: {min_loss:.6f} (époque {history['loss'].index(min_loss) + 1})\")\n",
    "if 'mae' in history:\n",
    "    print(f\"MAE final: {history['mae'][-1]:.6f}\")\n",
    "    print(f\"MAE minimal: {min_mae:.6f} (époque {history['mae'].index(min_mae) + 1})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f7779",
   "metadata": {},
   "source": [
    "## 13. Sauvegarde du modèle final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Timestamp pour identifier cette sauvegarde\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Sauvegarder le modèle complet avec l'historique\n",
    "final_model_path = f'ai/chess_model_final_{timestamp}.pt'\n",
    "torch.save({\n",
    "    'epoch': CONFIG['epochs'],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'history': history,\n",
    "    'timestamp': timestamp,\n",
    "}, final_model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAUVEGARDE DES MODÈLES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"✓ Modèle final: {final_model_path}\")\n",
    "\n",
    "# Sauvegarder aussi au format .npz pour compatibilité avec l'ancien code\n",
    "weights_path = 'ai/NN/chess_nn_weights.npz'\n",
    "weights = {name: param.cpu().detach().numpy() for name, param in model.named_parameters()}\n",
    "np.savez(weights_path, **weights)\n",
    "print(f\"✓ Poids .npz: {weights_path}\")\n",
    "\n",
    "# Copier aussi le checkpoint dans NN/\n",
    "import shutil\n",
    "checkpoint_backup = f'ai/NN/chess_model_checkpoint_{timestamp}.pt'\n",
    "if os.path.exists(CONFIG['checkpoint_path']):\n",
    "    shutil.copy(CONFIG['checkpoint_path'], checkpoint_backup)\n",
    "    print(f\"✓ Checkpoint backup: {checkpoint_backup}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n✅ Tous les fichiers sont sauvegardés sur votre Google Drive!\")\n",
    "print(f\"   Chemin: {PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd244",
   "metadata": {},
   "source": [
    "## 14. Test du modèle sur des positions aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0315c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passer le modèle en mode évaluation\n",
    "model.eval()\n",
    "\n",
    "# Tester sur quelques positions aléatoires\n",
    "num_tests = 10\n",
    "test_indices = np.random.choice(len(X_train), num_tests, replace=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TEST SUR {num_tests} POSITIONS ALÉATOIRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(test_indices, 1):\n",
    "        x = torch.FloatTensor(X_train[idx:idx+1]).to(CONFIG['device'])\n",
    "        y_true = y_train[idx]\n",
    "        y_pred = model(x).cpu().numpy()[0, 0]\n",
    "        error = abs(y_true - y_pred)\n",
    "        errors.append(error)\n",
    "        \n",
    "        print(f\"\\nPosition {i}:\")\n",
    "        print(f\"  Évaluation réelle:  {y_true:+8.4f}\")\n",
    "        print(f\"  Prédiction modèle:  {y_pred:+8.4f}\")\n",
    "        print(f\"  Erreur absolue:     {error:8.4f}\")\n",
    "        \n",
    "        # Indicateur visuel de la qualité\n",
    "        if error < 0.1:\n",
    "            print(f\"  Qualité: ✅ Excellente\")\n",
    "        elif error < 0.3:\n",
    "            print(f\"  Qualité: ✓ Bonne\")\n",
    "        elif error < 0.5:\n",
    "            print(f\"  Qualité: ⚠ Moyenne\")\n",
    "        else:\n",
    "            print(f\"  Qualité: ❌ Faible\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DES TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Erreur moyenne: {np.mean(errors):.4f}\")\n",
    "print(f\"Erreur médiane: {np.median(errors):.4f}\")\n",
    "print(f\"Erreur min:     {np.min(errors):.4f}\")\n",
    "print(f\"Erreur max:     {np.max(errors):.4f}\")\n",
    "print(f\"Écart-type:     {np.std(errors):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9184e",
   "metadata": {},
   "source": [
    "## 15. Résumé et fichiers générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 RÉSUMÉ DE L'ENTRAÎNEMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n📍 Projet: {PROJECT_PATH}\")\n",
    "print(f\"\\n⚙️ Configuration:\")\n",
    "print(f\"   • Parties générées: {CONFIG['num_games']:,}\")\n",
    "print(f\"   • Positions d'entraînement: {len(X_train):,}\")\n",
    "print(f\"   • Époques: {CONFIG['epochs']}\")\n",
    "print(f\"   • Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   • Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   • Device: {CONFIG['device']}\")\n",
    "\n",
    "print(f\"\\n📈 Résultats:\")\n",
    "print(f\"   • Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"   • Perte minimale: {min(history['loss']):.6f}\")\n",
    "if 'mae' in history:\n",
    "    print(f\"   • MAE final: {history['mae'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\n💾 Fichiers sauvegardés sur Drive:\")\n",
    "files_to_check = [\n",
    "    final_model_path,\n",
    "    CONFIG['checkpoint_path'],\n",
    "    weights_path,\n",
    "    'training_history.png'\n",
    "]\n",
    "\n",
    "for filepath in files_to_check:\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / (1024 * 1024)  # Convertir en MB\n",
    "        print(f\"   ✓ {filepath} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ✗ {filepath} (non trouvé)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ ENTRAÎNEMENT TERMINÉ AVEC SUCCÈS!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTous les fichiers sont automatiquement synchronisés avec votre Google Drive.\")\n",
    "print(\"Vous pouvez fermer ce notebook en toute sécurité.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f74c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localiser le dataset sur Google Drive et préparer le dossier de checkpoints\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Chemin attendu du dossier contenant le dataset (donné par l'utilisateur)\n",
    "DATASET_DIR = '/content/drive/MyDrive/smart_chess_drive/chessData'\n",
    "\n",
    "# Chercher un fichier .csv dans DATASET_DIR\n",
    "DATASET_CSV = None\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    csvs = glob(os.path.join(DATASET_DIR, '*.csv'))\n",
    "    if len(csvs) > 0:\n",
    "        DATASET_CSV = csvs[0]\n",
    "        print(f'✅ Dataset CSV trouvé: {DATASET_CSV}')\n",
    "    else:\n",
    "        print(f'❌ Aucun fichier .csv trouvé dans {DATASET_DIR}. Placez votre fichier chessData.csv dans ce dossier.')\n",
    "else:\n",
    "    print(f'❌ Dossier dataset introuvable: {DATASET_DIR}. Vérifiez le chemin sur votre Drive.')\n",
    "\n",
    "# Créer un dossier de checkpoints dans le repo sur Drive (persistant)\n",
    "CKPT_DIR = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "print('Dossier de checkpoints (créé si manquant):', CKPT_DIR)\n",
    "\n",
    "# Exposer variables utiles\n",
    "print('\\nVariables exposées:')\n",
    "print(' DATASET_CSV =', DATASET_CSV)\n",
    "print(' CKPT_DIR =', CKPT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer et lancer le script d'entraînement `ai.NN.train_torch` en adaptant les chemins pour Colab/Drive\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "if DATASET_CSV is None:\n",
    "    raise FileNotFoundError(f\"Dataset non trouvé dans: {DATASET_DIR}\")\n",
    "\n",
    "# Importer le module d'entraînement\n",
    "import ai.NN.train_torch as trainer\n",
    "\n",
    "# Rediriger les chemins dataset et checkpoints vers Drive\n",
    "trainer.DATASET_PATH = DATASET_CSV\n",
    "trainer.CHECKPOINT_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.CHECKPOINT_FILE))\n",
    "trainer.WEIGHTS_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.WEIGHTS_FILE))\n",
    "\n",
    "# Optionnel: réduire pour test rapide (décommentez si besoin)\n",
    "# trainer.EPOCHS = 2\n",
    "# trainer.MAX_SAMPLES = 5000\n",
    "\n",
    "print('Configuration trainer:')\n",
    "print(' DATASET_PATH=', trainer.DATASET_PATH)\n",
    "print(' CHECKPOINT_FILE=', trainer.CHECKPOINT_FILE)\n",
    "print(' WEIGHTS_FILE=', trainer.WEIGHTS_FILE)\n",
    "print(' EPOCHS=', trainer.EPOCHS)\n",
    "print(' MAX_SAMPLES=', trainer.MAX_SAMPLES)\n",
    "\n",
    "# Lancer l'entraînement\n",
    "trainer.main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
