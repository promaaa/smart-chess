{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b5a4df",
   "metadata": {
    "id": "12b5a4df"
   },
   "source": [
    "# Entra√Ænement du Neural Network pour Smart Chess sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entra√Æner le r√©seau de neurones pour l'√©valuation d'√©checs en utilisant les ressources GPU de Google Colab.\n",
    "\n",
    "**Chemin du projet sur Drive:** `MyDrive/smart_chess_drive/smart-chess`\n",
    "\n",
    "## Instructions\n",
    "1. Aller dans **Runtime > Change runtime type > GPU** (T4 ou mieux)\n",
    "2. Ex√©cuter les cellules dans l'ordre\n",
    "3. Les mod√®les seront sauvegard√©s automatiquement sur votre Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b4590",
   "metadata": {
    "id": "de1b4590"
   },
   "source": [
    "## 1. V√©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5e0dc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1763024099794,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "8d5e0dc5",
    "outputId": "4ced9e3d-ee05-43bd-ddf8-d9f7fa3747ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 13 08:54:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   62C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier la disponibilit√© du GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddd742",
   "metadata": {
    "id": "89ddd742"
   },
   "source": [
    "## 2. Montage Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5e4f04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17026,
     "status": "ok",
     "timestamp": 1763024122124,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "ce5e4f04",
    "outputId": "a5b97670-f0af-490b-9594-1a042d2175a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf2990",
   "metadata": {
    "id": "1ccf2990"
   },
   "source": [
    "## 3. Configuration du chemin du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabb986a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1763024124843,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "fabb986a",
    "outputId": "87bc538b-4bf3-4ccb-9e65-8cdeb1561261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n",
      "\n",
      "Contenu du r√©pertoire:\n",
      "  - README.md\n",
      "  - ai\n",
      "  - docs\n",
      "  - prototypes\n"
     ]
    }
   ],
   "source": [
    "# D√©finir le chemin vers le projet sur votre Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "os.chdir(PROJECT_PATH)\n",
    "sys.path.insert(0, PROJECT_PATH)\n",
    "\n",
    "print(f\"R√©pertoire de travail: {os.getcwd()}\")\n",
    "print(f\"\\nContenu du r√©pertoire:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20e36c",
   "metadata": {
    "id": "3f20e36c"
   },
   "source": [
    "## 4. Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7783beaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8776,
     "status": "ok",
     "timestamp": 1763024138488,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "7783beaf",
    "outputId": "8a97de08-4654-4aa1-f56d-a04853ce816b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Installation termin√©e\n"
     ]
    }
   ],
   "source": [
    "# Installer les packages n√©cessaires\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy matplotlib tqdm\n",
    "\n",
    "print(\"‚úì Installation termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25365688",
   "metadata": {
    "id": "25365688"
   },
   "source": [
    "## 5. V√©rification de l'environnement PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76e678b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3769,
     "status": "ok",
     "timestamp": 1763024153636,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "a76e678b",
    "outputId": "df2186fb-7045-4077-f4d9-e290c5d1347c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION SYST√àME\n",
      "============================================================\n",
      "PyTorch version: 2.8.0+cu126\n",
      "NumPy version: 2.0.2\n",
      "\n",
      "CUDA disponible: True\n",
      "CUDA version: 12.6\n",
      "Nom du GPU: Tesla T4\n",
      "M√©moire GPU totale: 15.83 GB\n",
      "Compute Capability: 7.5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION SYST√àME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"\\nCUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"M√©moire GPU totale: {props.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ATTENTION: GPU non disponible, l'entra√Ænement sera tr√®s lent!\")\n",
    "    print(\"   Allez dans Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a1e23",
   "metadata": {
    "id": "f91a1e23"
   },
   "source": [
    "## 6. Import des modules du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7397821",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1763024215470,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "c7397821",
    "outputId": "500fb069-a1c6-44e1-db73-2b255a8c35e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n",
      "\n",
      "Quelques fichiers √† la racine du projet:\n",
      "['README.md', 'ai', 'docs', 'prototypes']\n",
      "\n",
      "Contenu du dossier ai/:\n",
      "['AI_reduction', 'Chess.py', 'ChessInteractif - v7.py', 'ChessInteractifv10.py', 'ChessInteractifv2.py', 'Chess_v2.py', 'NN', 'Null_move_AI', 'Old_AI', 'Player.py', 'Profile', 'Tests.py', '__init__.py', '__pycache__', 'alphabeta.py', 'alphabeta_engine.py', 'alphabeta_engine_v2.py', 'analyze_reduction_overhead.py', 'base_engine.py', 'check_dataset_stats.py', 'check_gpu.py', 'check_performance.py', 'checkpoints', 'chess_model_checkpoint.pt', 'debug_conversion.py', 'engine.py', 'engine_match.py', 'evaluator.py', 'example_move_reduction.py', 'fast_evaluator.py', 'gaviota.py', 'journal-experiments.md', 'optimized_chess.py', 'pgn.py', 'polyglot.py', 'profile_report_1760344602.txt', 'py.typed', 'svg.py', 'syzygy.py', 'test_depth_6_performance.py', 'test_depth_6_quick.py', 'test_depth_effectiveness.py', 'test_engines_v2.py', 'test_evaluator_performance.py', 'test_generalization.py', 'test_move_reduction.py', 'test_null_move.py', 'test_null_move_comparison.py', 'test_null_move_effectiveness.py', 'test_null_move_final.py', 'test_null_move_optimization.py', 'test_null_move_quick.py', 'test_timeout_fix.py', 'variant.py', 'visualize_sampling.py']\n",
      "\n",
      "‚úÖ Import direct `Chess` OK (module trouv√© via sys.path)\n",
      "üñ•Ô∏è  Device: cuda\n",
      "üöÄ GPU: Tesla T4\n",
      "üíæ GPU Memory: 15.83 GB\n",
      "\n",
      "‚úì Modules import√©s avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "# Importer les modules n√©cessaires depuis le projet (robuste √† l'emplacement du repo sur Drive)\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Assurez-vous que PROJECT_PATH est d√©fini et ajoutez √©galement le dossier `ai` au PYTHONPATH\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "AI_SUBDIR = os.path.join(PROJECT_PATH, 'ai')\n",
    "\n",
    "# V√©rifier les chemins alternatifs (si l'utilisateur a copi√© le repo dans /content)\n",
    "ALT_PATH = '/content/smart-chess'\n",
    "\n",
    "# Choisir un chemin existant\n",
    "if not os.path.isdir(PROJECT_PATH) and os.path.isdir(ALT_PATH):\n",
    "    PROJECT_PATH = ALT_PATH\n",
    "\n",
    "if not os.path.isdir(PROJECT_PATH):\n",
    "    raise FileNotFoundError(f\"R√©pertoire projet introuvable: {PROJECT_PATH}. Montez Drive et v√©rifiez le chemin.\")\n",
    "\n",
    "# Ajouter au sys.path si n√©cessaire\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_PATH)\n",
    "if AI_SUBDIR not in sys.path and os.path.isdir(AI_SUBDIR):\n",
    "    sys.path.insert(0, AI_SUBDIR)\n",
    "\n",
    "# Se placer dans le r√©pertoire projet\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "print('R√©pertoire de travail:', os.getcwd())\n",
    "print('\\nQuelques fichiers √† la racine du projet:')\n",
    "print(sorted(os.listdir(PROJECT_PATH))[:50])\n",
    "print('\\nContenu du dossier ai/:')\n",
    "print(sorted(os.listdir(AI_SUBDIR))[:100])\n",
    "\n",
    "# Diagnostic d'import direct pour le module Chess\n",
    "try:\n",
    "    import Chess\n",
    "    print('\\n‚úÖ Import direct `Chess` OK (module trouv√© via sys.path)')\n",
    "except Exception as e:\n",
    "    print('\\n‚ùå Import direct `Chess` a √©chou√©:', e)\n",
    "    print('V√©rifiez que `ai/Chess.py` existe et que le dossier ai/ est dans sys.path')\n",
    "\n",
    "# Maintenant importer le module d'entra√Ænement (trainer) - UPDATED to torch_train\n",
    "try:\n",
    "    import ai.NN.torch_train as trainer\n",
    "    import ai.NN.torch_nn_evaluator as torch_eval\n",
    "    from ai.Chess_v2 import Chess\n",
    "    print('\\n‚úì Modules import√©s avec succ√®s!')\n",
    "except Exception as e:\n",
    "    print('\\n‚ùå Erreur d\\'import lors de l\\'import du trainer:', e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e668793",
   "metadata": {
    "id": "0e668793"
   },
   "source": [
    "## 7. Configuration de l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f87f8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1763024223070,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "c9f87f8d",
    "outputId": "47077b3a-3215-4283-f8c7-fdceb7d7bb1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION DE L'ENTRA√éNEMENT\n",
      "============================================================\n",
      "num_games           : 10000\n",
      "batch_size          : 256\n",
      "epochs              : 50\n",
      "learning_rate       : 0.001\n",
      "device              : cuda\n",
      "num_workers         : 2\n",
      "checkpoint_path     : ai/chess_model_checkpoint.pt\n",
      "save_interval       : 5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Param√®tres d'entra√Ænement (NNUE architecture)\n",
    "CONFIG = {\n",
    "    # G√©n√©ration de donn√©es\n",
    "    'num_games': 10000,          # Nombre de parties √† g√©n√©rer pour l'entra√Ænement\n",
    "\n",
    "    # Hyperparam√®tres NNUE\n",
    "    'batch_size': 256,           # Taille du batch (augmenter si GPU puissant)\n",
    "    'epochs': 50,                # Nombre d'√©poques d'entra√Ænement\n",
    "    'learning_rate': 0.001,      # Taux d'apprentissage\n",
    "\n",
    "    # Architecture NNUE (768 ‚Üí 4096 ‚Üí 256 ‚Üí 32 ‚Üí 1)\n",
    "    'hidden1': 4096,\n",
    "    'hidden2': 256,\n",
    "    'hidden3': 32,\n",
    "    'dropout': 0.0,              # NNUE ne use pas de dropout\n",
    "\n",
    "    # Configuration syst√®me\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 2,            # Workers pour le DataLoader\n",
    "\n",
    "    # Sauvegarde\n",
    "    'checkpoint_path': 'ai/chess_model_checkpoint.pt',\n",
    "    'save_interval': 5,          # Sauvegarder tous les N √©poques\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION DE L'ENTRA√éNEMENT (NNUE)\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    print(\"\\n‚ö†Ô∏è ATTENTION: Entra√Ænement sur CPU d√©tect√©!\")\n",
    "    print(\"   R√©duisez num_games et epochs pour un test rapide.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ad90f",
   "metadata": {
    "id": "f72ad90f"
   },
   "source": [
    "## 8. G√©n√©ration des donn√©es d'entra√Ænement\n",
    "\n",
    "Cette √©tape g√©n√®re des parties d'√©checs al√©atoires et calcule les √©valuations de position.\n",
    "**Attention:** Cela peut prendre 15-30 minutes selon le nombre de parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76f74c05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1763024227026,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "76f74c05",
    "outputId": "3ca27354-a84b-4318-a5d7-e6d0e40fb094"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset CSV trouv√©: /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      "Dossier de checkpoints (cr√©√© si manquant): /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n",
      "\n",
      "Variables expos√©es:\n",
      " DATASET_CSV = /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      " CKPT_DIR = /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Localiser le dataset sur Google Drive et pr√©parer le dossier de checkpoints\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Chemin attendu du dossier contenant le dataset (donn√© par l'user)\n",
    "# Updated based on user's feedback that the file is directly in smart_chess_drive\n",
    "DATASET_DIR = '/content/drive/MyDrive/smart_chess_drive/'\n",
    "\n",
    "# Chercher un fichier .csv dans DATASET_DIR\n",
    "DATASET_CSV = None\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    csvs = glob(os.path.join(DATASET_DIR, '*.csv'))\n",
    "    if len(csvs) > 0:\n",
    "        # Assuming there's only one relevant CSV in that dir, pick the first one\n",
    "        DATASET_CSV = csvs[0]\n",
    "        print(f'‚úÖ Dataset CSV trouv√©: {DATASET_CSV}')\n",
    "    else:\n",
    "        print(f'‚ùå Aucun fichier .csv trouv√© dans {DATASET_DIR}. Placez votre fichier chessData.csv dans ce dossier.')\n",
    "else:\n",
    "    print(f'‚ùå Dossier dataset introuvable: {DATASET_DIR}. V√©rifiez le chemin sur votre Drive.')\n",
    "\n",
    "# Cr√©er un dossier de checkpoints dans le repo sur Drive (persistant)\n",
    "CKPT_DIR = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "print('Dossier de checkpoints (cr√©√© si manquant):', CKPT_DIR)\n",
    "\n",
    "# Exposer variables utiles\n",
    "print('\\nVariables expos√©es:')\n",
    "print(' DATASET_CSV =', DATASET_CSV)\n",
    "print(' CKPT_DIR =', CKPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f1e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19749,
     "status": "ok",
     "timestamp": 1763024249760,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "4504f1e6",
    "outputId": "772989b7-3975-4a48-e97d-8de82ff253aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset (depuis chessData)...\n",
      "üìÇ Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "üßπ Nettoyage : 190154 lignes corrompues supprim√©es.\n",
      "‚úÖ 12,767,881 positions valides charg√©es.\n",
      "\n",
      "============================================================\n",
      "DONN√âES CHARG√âES\n",
      "============================================================\n",
      "Nombre total de positions: 12,767,881\n",
      "Temps √©coul√©: 19.6s (0.3 min)\n",
      "============================================================\n",
      "\n",
      "Statistiques sur les √©valuations:\n",
      "  Min: -15.3120\n",
      "  Max: 15.3190\n",
      "  Moyenne: 0.0455\n",
      "  √âcart-type: 0.8139\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Chargement du dataset (depuis chessData)...\")\n",
    "\n",
    "# Pr√©f√©rer la variable DATASET_CSV (d√©finie apr√®s le montage Drive) sinon utiliser la valeur par d√©faut du module trainer\n",
    "dataset_path = globals().get('DATASET_CSV')\n",
    "\n",
    "if dataset_path is None:\n",
    "    raise FileNotFoundError('Aucun chemin de dataset d√©fini. Montez Drive et placez le fichier CSV dans MyDrive/smart_chess_drive/chessData')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Utiliser la fonction de chargement du script d'entra√Ænement pour assurer le m√™me pr√©traitement\n",
    "fens, evaluations = trainer.load_data(dataset_path)\n",
    "\n",
    "# Variables attendues plus bas dans le notebook\n",
    "X_train = fens\n",
    "y_train = evaluations\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONN√âES CHARG√âES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nombre total de positions: {len(X_train):,}\")\n",
    "print(f\"Temps √©coul√©: {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques sur les √©valuations\n",
    "print(f\"\\nStatistiques sur les √©valuations:\")\n",
    "print(f\"  Min: {y_train.min():.4f}\")\n",
    "print(f\"  Max: {y_train.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.4f}\")\n",
    "print(f\"  √âcart-type: {y_train.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc365442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1762160541382,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "cc365442",
    "outputId": "a4714828-a578-4569-9436-3362073a1b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code of trainer.load_data:\n",
      "============================================================\n",
      "def load_data(filepath: str):\n",
      "    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n",
      "    print(f\"üìÇ Chargement du dataset depuis {filepath}...\")\n",
      "    \n",
      "    df = pd.read_csv(\n",
      "        filepath, \n",
      "        names=['FEN', 'Evaluation'], \n",
      "        skiprows=1,\n",
      "        comment='#'\n",
      "    )\n",
      "    \n",
      "    initial_count = len(df)\n",
      "    df.dropna(inplace=True)\n",
      "    cleaned_count = len(df)\n",
      "    \n",
      "    if initial_count > cleaned_count:\n",
      "        print(f\"üßπ Nettoyage : {initial_count - cleaned_count} lignes corrompues supprim√©es.\")\n",
      "    \n",
      "    fens = df['FEN'].values\n",
      "    EVAL_SCALE_FACTOR = 1000.0\n",
      "    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n",
      "    \n",
      "    print(f\"‚úÖ {len(fens):,} positions valides charg√©es.\")\n",
      "    return fens, evaluations\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import ai.NN.torch_train as trainer\n",
    "\n",
    "try:\n",
    "    # Get the source code of the load_data function\n",
    "    source_code = inspect.getsource(trainer.load_data)\n",
    "    print(\"Source code of trainer.load_data:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(source_code)\n",
    "    print(\"=\" * 60)\n",
    "except TypeError:\n",
    "    print(\"Could not get source code for trainer.load_data. It might not be a function defined in the file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find the torch_train.py file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to get source code: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3c66b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1762160541399,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "e0b3c66b",
    "outputId": "6ddb0746-64d6-4f67-9602-7136916db718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the function definition 'def load_data():' in /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py. Please inspect the file manually.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/torch_train.py')\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Assuming the load_data function signature is currently load_data(filepath: str):\n",
    "# We need to verify it accepts a filepath parameter\n",
    "if 'def load_data(filepath:' in content or 'def load_data(filepath)' in content:\n",
    "    print(f\"‚úÖ La fonction load_data dans {file_path} accepte d√©j√† un param√®tre filepath.\")\n",
    "    print(\"Aucune modification n√©cessaire.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è La fonction load_data pourrait n√©cessiter une modification.\")\n",
    "    print(\"V√©rifiez manuellement si elle accepte un chemin de fichier en param√®tre.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea4dd7",
   "metadata": {
    "id": "fdea4dd7"
   },
   "source": [
    "## 9. Cr√©ation du dataset et du dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45e62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1763024276939,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "d0c45e62",
    "outputId": "f2d72070-ee42-4b53-d8c1-06282a9631ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATALOADER CONFIGUR√â\n",
      "============================================================\n",
      "Taille du dataset: 12,767,881 √©chantillons\n",
      "Nombre de batches: 49,875\n",
      "Taille du batch: 256\n",
      "Derni√®re batch: 137 √©chantillons\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from ai.NN.torch_train import ChessDataset\n",
    "\n",
    "# Cr√©er le dataset\n",
    "dataset = ChessDataset(X_train, y_train)\n",
    "\n",
    "# Cr√©er le dataloader\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATALOADER CONFIGUR√â\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Taille du dataset: {len(dataset):,} √©chantillons\")\n",
    "print(f\"Nombre de batches: {len(train_loader):,}\")\n",
    "print(f\"Taille du batch: {CONFIG['batch_size']}\")\n",
    "print(f\"Derni√®re batch: {len(dataset) % CONFIG['batch_size']} √©chantillons\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dda22",
   "metadata": {
    "id": "f05dda22"
   },
   "source": [
    "## 10. Cr√©ation du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d2b3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1763024290170,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "056d2b3a",
    "outputId": "b2986907-2f5f-456b-9ee0-05decda166f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARCHITECTURE DU MOD√àLE\n",
      "============================================================\n",
      "TorchNNEvaluator(\n",
      "  (l1): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (l3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (act): LeakyReLU(negative_slope=0.01)\n",
      "  (drop1): Dropout(p=0.3, inplace=False)\n",
      "  (drop2): Dropout(p=0.3, inplace=False)\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "============================================================\n",
      "\n",
      "Nombre total de param√®tres: 262,913\n",
      "Param√®tres entra√Ænables: 262,913\n",
      "Device: cuda\n",
      "Taille estim√©e du mod√®le: 1.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er le mod√®le NNUE et le d√©placer sur le device appropri√©\n",
    "from ai.NN.torch_nn_evaluator import TorchNNEvaluator\n",
    "\n",
    "model = TorchNNEvaluator(\n",
    "    hidden1=CONFIG['hidden1'],\n",
    "    hidden2=CONFIG['hidden2'],\n",
    "    hidden3=CONFIG['hidden3'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "# Afficher l'architecture\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHITECTURE DU MOD√àLE (NNUE-LIKE)\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compter les param√®tres\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nNombre total de param√®tres: {total_params:,}\")\n",
    "print(f\"Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "\n",
    "# Estimer la taille m√©moire du mod√®le\n",
    "param_size_mb = total_params * 4 / (1024 ** 2)  # 4 bytes par float32\n",
    "print(f\"Taille estim√©e du mod√®le: {param_size_mb:.2f} MB\")\n",
    "\n",
    "# Afficher les dimensions des couches\n",
    "print(f\"\\nArchitecture d√©taill√©e:\")\n",
    "print(f\"  Input:  {model.l1.in_features}\")\n",
    "print(f\"  Layer 1: {model.l1.out_features} (ReLU)\")\n",
    "print(f\"  Layer 2: {model.l2.out_features} (ReLU)\")\n",
    "print(f\"  Layer 3: {model.l3.out_features} (ReLU)\")\n",
    "print(f\"  Output: {model.l4.out_features} (Linear)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ba4a7",
   "metadata": {
    "id": "aa1ba4a7"
   },
   "source": [
    "## 11. Entra√Ænement du mod√®le\n",
    "\n",
    "Cette √©tape lance l'entra√Ænement complet. Les checkpoints sont sauvegard√©s automatiquement sur votre Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d4b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214583,
     "status": "ok",
     "timestamp": 1763024539505,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "9887d4b8",
    "outputId": "6d5bf9b3-6720-40c0-d4b7-c21e20120d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Device: cuda\n",
      "üöÄ GPU: Tesla T4\n",
      "üíæ GPU Memory: 15.83 GB\n",
      "‚úÖ Harmonisation: trainer.BATCH_SIZE = 256\n",
      "‚úÖ Applied global changes: trainer.HIDDEN_SIZE=512, trainer.MAX_SAMPLES=200000\n",
      "Configuration trainer:\n",
      " DATASET_PATH= /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      " CHECKPOINT_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      " WEIGHTS_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      " EPOCHS= 10\n",
      " MAX_SAMPLES= 200000\n",
      "üìÇ Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "üßπ Nettoyage : 190154 lignes corrompues supprim√©es.\n",
      "‚úÖ 12,767,881 positions valides charg√©es.\n",
      "\n",
      "üìä Dataset complet: 12,767,881 positions\n",
      "üì• Chargement du checkpoint PyTorch: /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "‚úÖ Checkpoint charg√© (step 10), best_rmse=0.4897010028362274\n",
      "‚ÑπÔ∏è Learning rate enregistr√© d√©tect√©: 0.000050\n",
      "Saisir le learning rate de d√©part [0.000050]: 0.00005\n",
      "‚û°Ô∏è Learning rate initial utilis√© pour l'entra√Ænement: 0.000050\n",
      "\n",
      "======================================================================\n",
      "üîé Mod√®le d√©tect√©: 768 ‚Üí 512 ‚Üí 512 ‚Üí 1\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  √âchantillon/epoch: 200,000 positions\n",
      "  Architecture: 768 ‚Üí 512 ‚Üí 512 ‚Üí 1\n",
      "  Dropout: 0.5\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.0001 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 ‚Üí 0.0001)\n",
      "  LR Scheduler: True (patience: 3)\n",
      "  Batch size: 256\n",
      "  Epochs: 10\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "‚ÑπÔ∏è Reprise d√©tect√©e: d√©sactivation du LR warmup pour utiliser le LR sauvegard√©/pr√©c√©dent.\n",
      "\n",
      "[Epoch 1] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rEpoch 1/10:   0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=0 grad_norm=3.883689 max_abs_grad=1.877332 param_norm=2232.449923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   1%|          | 6/782 [00:01<01:48,  7.14it/s, loss=0.8750]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=-0.0469 std=0.7605; preds mean=0.0561 std=0.1002; RMSE=0.7847; corr=-0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  14%|‚ñà‚ñç        | 108/782 [00:03<00:14, 46.11it/s, loss=0.8304]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=100 grad_norm=4.359676 max_abs_grad=0.407767 param_norm=2232.449781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  26%|‚ñà‚ñà‚ñã       | 206/782 [00:05<00:10, 53.04it/s, loss=0.8230]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=200 grad_norm=1.898690 max_abs_grad=0.422694 param_norm=2232.454049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 310/782 [00:06<00:08, 57.87it/s, loss=0.8211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=300 grad_norm=2.281097 max_abs_grad=0.742846 param_norm=2232.456832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 408/782 [00:08<00:08, 43.21it/s, loss=0.8245]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=400 grad_norm=3.400215 max_abs_grad=1.297210 param_norm=2232.460444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 511/782 [00:10<00:04, 55.59it/s, loss=0.8224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=500 grad_norm=2.076759 max_abs_grad=0.449151 param_norm=2232.464940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 609/782 [00:12<00:03, 51.38it/s, loss=0.8166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=600 grad_norm=1.969042 max_abs_grad=0.465678 param_norm=2232.469329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 706/782 [00:14<00:01, 48.36it/s, loss=0.8165]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=1 batch=700 grad_norm=2.050190 max_abs_grad=0.806817 param_norm=2232.471371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:16<00:00, 48.70it/s, loss=0.8147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8174  (baseline: 0.8189)\n",
      "  MAE:         0.3008\n",
      "  Am√©lioration: +0.2% vs baseline\n",
      "  Corr√©lation: 0.1794\n",
      "  Std preds:   0.0103  (cible: 0.8189)\n",
      "  Mean preds:  0.0173  (cible: 0.0379)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 2] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   1%|          | 5/782 [00:00<00:16, 45.83it/s, loss=0.7910]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=0 grad_norm=2.244361 max_abs_grad=0.609474 param_norm=2232.473339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  14%|‚ñà‚ñç        | 108/782 [00:02<00:12, 54.31it/s, loss=0.8224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=100 grad_norm=2.190279 max_abs_grad=0.251801 param_norm=2232.476260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  27%|‚ñà‚ñà‚ñã       | 211/782 [00:03<00:10, 57.08it/s, loss=0.8051]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=200 grad_norm=4.879444 max_abs_grad=1.524861 param_norm=2232.477084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 309/782 [00:05<00:08, 54.87it/s, loss=0.8036]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=300 grad_norm=2.003355 max_abs_grad=0.579072 param_norm=2232.478779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 409/782 [00:07<00:06, 58.46it/s, loss=0.8065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=400 grad_norm=2.597729 max_abs_grad=0.701982 param_norm=2232.481266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 506/782 [00:09<00:05, 48.78it/s, loss=0.8083]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=500 grad_norm=5.734575 max_abs_grad=1.710648 param_norm=2232.483668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 607/782 [00:11<00:03, 45.99it/s, loss=0.8080]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=600 grad_norm=2.782097 max_abs_grad=0.404744 param_norm=2232.486432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 711/782 [00:13<00:01, 56.75it/s, loss=0.8105]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=2 batch=700 grad_norm=6.329337 max_abs_grad=2.494345 param_norm=2232.489085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:14<00:00, 52.42it/s, loss=0.8115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7977  (baseline: 0.7989)\n",
      "  MAE:         0.3029\n",
      "  Am√©lioration: +0.1% vs baseline\n",
      "  Corr√©lation: 0.1166\n",
      "  Std preds:   0.0110  (cible: 0.7989)\n",
      "  Mean preds:  0.0476  (cible: 0.0431)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 3] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:   1%|          | 5/782 [00:00<00:16, 46.16it/s, loss=0.8161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=0 grad_norm=1.641571 max_abs_grad=0.580186 param_norm=2232.491705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  14%|‚ñà‚ñé        | 106/782 [00:01<00:11, 57.76it/s, loss=0.8155]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=100 grad_norm=1.315633 max_abs_grad=0.527161 param_norm=2232.492927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  27%|‚ñà‚ñà‚ñã       | 209/782 [00:03<00:10, 52.37it/s, loss=0.8063]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=200 grad_norm=2.233931 max_abs_grad=0.510228 param_norm=2232.495468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  39%|‚ñà‚ñà‚ñà‚ñâ      | 308/782 [00:05<00:08, 58.39it/s, loss=0.8030]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=300 grad_norm=1.884898 max_abs_grad=1.088397 param_norm=2232.497293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 408/782 [00:07<00:07, 47.34it/s, loss=0.8066]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=400 grad_norm=3.248831 max_abs_grad=1.356399 param_norm=2232.500421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 507/782 [00:09<00:05, 50.14it/s, loss=0.8042]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=500 grad_norm=3.484993 max_abs_grad=1.170666 param_norm=2232.502328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 607/782 [00:11<00:03, 54.32it/s, loss=0.8055]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=600 grad_norm=17.571875 max_abs_grad=4.874732 param_norm=2232.504212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 699/782 [00:13<00:01, 53.01it/s, loss=0.8086]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=3 batch=700 grad_norm=3.254562 max_abs_grad=1.869562 param_norm=2232.506396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:14<00:00, 52.58it/s, loss=0.8082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8294  (baseline: 0.8304)\n",
      "  MAE:         0.3136\n",
      "  Am√©lioration: +0.1% vs baseline\n",
      "  Corr√©lation: 0.1340\n",
      "  Std preds:   0.0103  (cible: 0.8304)\n",
      "  Mean preds:  0.0719  (cible: 0.0495)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 4] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:   1%|          | 5/782 [00:00<00:18, 43.03it/s, loss=0.7866]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=0 grad_norm=14.889532 max_abs_grad=6.488861 param_norm=2232.508339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  14%|‚ñà‚ñç        | 109/782 [00:02<00:11, 58.13it/s, loss=0.8443]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=100 grad_norm=3.358769 max_abs_grad=0.574702 param_norm=2232.510071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  27%|‚ñà‚ñà‚ñã       | 208/782 [00:04<00:12, 47.43it/s, loss=0.8232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=200 grad_norm=5.200048 max_abs_grad=0.725123 param_norm=2232.512675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 309/782 [00:06<00:10, 46.70it/s, loss=0.8240]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=300 grad_norm=1.476597 max_abs_grad=0.449057 param_norm=2232.515956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 412/782 [00:08<00:06, 58.80it/s, loss=0.8143]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=400 grad_norm=1.674245 max_abs_grad=0.384426 param_norm=2232.518717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 505/782 [00:10<00:06, 40.69it/s, loss=0.8100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=500 grad_norm=3.251169 max_abs_grad=0.428811 param_norm=2232.520569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 607/782 [00:12<00:02, 59.22it/s, loss=0.8137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=600 grad_norm=1.596696 max_abs_grad=0.764232 param_norm=2232.524696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 711/782 [00:13<00:01, 56.24it/s, loss=0.8138]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=4 batch=700 grad_norm=4.660102 max_abs_grad=0.869688 param_norm=2232.527216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:15<00:00, 51.54it/s, loss=0.8122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 4...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 4/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7883  (baseline: 0.7893)\n",
      "  MAE:         0.3033\n",
      "  Am√©lioration: +0.1% vs baseline\n",
      "  Corr√©lation: 0.0897\n",
      "  Std preds:   0.0129  (cible: 0.7893)\n",
      "  Mean preds:  0.0697  (cible: 0.0571)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 5] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:   1%|          | 5/782 [00:00<00:15, 49.13it/s, loss=0.7232]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=0 grad_norm=2.297178 max_abs_grad=0.525420 param_norm=2232.529443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  14%|‚ñà‚ñé        | 107/782 [00:02<00:14, 45.30it/s, loss=0.8132]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=100 grad_norm=2.692090 max_abs_grad=0.341387 param_norm=2232.530710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  26%|‚ñà‚ñà‚ñã       | 206/782 [00:04<00:10, 56.59it/s, loss=0.8079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=200 grad_norm=1.521599 max_abs_grad=0.728859 param_norm=2232.532799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 310/782 [00:06<00:08, 57.17it/s, loss=0.8123]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=300 grad_norm=2.203867 max_abs_grad=0.781315 param_norm=2232.535474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 408/782 [00:08<00:06, 55.77it/s, loss=0.8070]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=400 grad_norm=2.383246 max_abs_grad=0.395894 param_norm=2232.537542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 507/782 [00:09<00:05, 53.43it/s, loss=0.8059]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=500 grad_norm=1.813779 max_abs_grad=0.297263 param_norm=2232.540273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 611/782 [00:11<00:03, 56.81it/s, loss=0.8061]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=600 grad_norm=0.890272 max_abs_grad=0.238522 param_norm=2232.544708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 708/782 [00:13<00:01, 53.96it/s, loss=0.8046]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=5 batch=700 grad_norm=1.997057 max_abs_grad=0.273588 param_norm=2232.548127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:15<00:00, 51.81it/s, loss=0.8034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 5...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 5/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8042  (baseline: 0.8054)\n",
      "  MAE:         0.3043\n",
      "  Am√©lioration: +0.2% vs baseline\n",
      "  Corr√©lation: 0.1755\n",
      "  Std preds:   0.0073  (cible: 0.8054)\n",
      "  Mean preds:  0.0473  (cible: 0.0469)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 6] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:   1%|          | 5/782 [00:00<00:17, 44.86it/s, loss=0.8721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=0 grad_norm=8.605802 max_abs_grad=5.575995 param_norm=2232.550222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  14%|‚ñà‚ñç        | 109/782 [00:02<00:12, 55.80it/s, loss=0.8512]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=100 grad_norm=3.296148 max_abs_grad=0.413601 param_norm=2232.553381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  26%|‚ñà‚ñà‚ñã       | 206/782 [00:03<00:10, 53.95it/s, loss=0.8322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=200 grad_norm=1.676006 max_abs_grad=0.372852 param_norm=2232.557651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 309/782 [00:05<00:08, 54.37it/s, loss=0.8182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=300 grad_norm=3.545171 max_abs_grad=1.159436 param_norm=2232.559079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 408/782 [00:07<00:07, 52.50it/s, loss=0.8187]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=400 grad_norm=0.993391 max_abs_grad=0.462444 param_norm=2232.561556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 505/782 [00:09<00:05, 52.42it/s, loss=0.8181]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=500 grad_norm=3.528373 max_abs_grad=0.379514 param_norm=2232.565210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 608/782 [00:11<00:03, 44.34it/s, loss=0.8156]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=600 grad_norm=3.013940 max_abs_grad=0.689278 param_norm=2232.569295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 711/782 [00:13<00:01, 52.25it/s, loss=0.8150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=6 batch=700 grad_norm=1.423980 max_abs_grad=0.224488 param_norm=2232.572385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:15<00:00, 51.95it/s, loss=0.8140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 6...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 6/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8505  (baseline: 0.8512)\n",
      "  MAE:         0.3180\n",
      "  Am√©lioration: +0.1% vs baseline\n",
      "  Corr√©lation: 0.1409\n",
      "  Std preds:   0.0085  (cible: 0.8512)\n",
      "  Mean preds:  0.0332  (cible: 0.0605)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 7] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:   1%|          | 6/782 [00:00<00:14, 53.62it/s, loss=0.7783]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=0 grad_norm=1.850069 max_abs_grad=0.699533 param_norm=2232.574063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  14%|‚ñà‚ñç        | 108/782 [00:02<00:12, 55.32it/s, loss=0.8046]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=100 grad_norm=4.110307 max_abs_grad=0.988191 param_norm=2232.577335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  26%|‚ñà‚ñà‚ñã       | 206/782 [00:03<00:11, 51.48it/s, loss=0.8053]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=200 grad_norm=1.887258 max_abs_grad=0.688309 param_norm=2232.580986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 311/782 [00:05<00:08, 53.20it/s, loss=0.8143]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=300 grad_norm=1.719812 max_abs_grad=0.412045 param_norm=2232.584564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 407/782 [00:07<00:07, 47.36it/s, loss=0.8188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=400 grad_norm=2.191794 max_abs_grad=0.650022 param_norm=2232.588120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 510/782 [00:09<00:05, 47.85it/s, loss=0.8166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=500 grad_norm=1.547731 max_abs_grad=0.209765 param_norm=2232.590746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 609/782 [00:11<00:03, 54.56it/s, loss=0.8184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=600 grad_norm=2.090262 max_abs_grad=0.603115 param_norm=2232.593950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 712/782 [00:13<00:01, 53.58it/s, loss=0.8175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=7 batch=700 grad_norm=1.823815 max_abs_grad=0.340778 param_norm=2232.597976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:15<00:00, 51.63it/s, loss=0.8183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 7...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 7/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8135  (baseline: 0.8143)\n",
      "  MAE:         0.3009\n",
      "  Am√©lioration: +0.1% vs baseline\n",
      "  Corr√©lation: 0.1377\n",
      "  Std preds:   0.0090  (cible: 0.8143)\n",
      "  Mean preds:  0.0069  (cible: 0.0319)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 8] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:   1%|          | 6/782 [00:00<00:14, 52.41it/s, loss=0.7166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=0 grad_norm=2.052806 max_abs_grad=0.752447 param_norm=2232.600442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  14%|‚ñà‚ñç        | 108/782 [00:02<00:12, 52.46it/s, loss=0.8095]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=100 grad_norm=1.781376 max_abs_grad=0.492794 param_norm=2232.602110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  27%|‚ñà‚ñà‚ñã       | 211/782 [00:03<00:10, 55.99it/s, loss=0.8151]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=200 grad_norm=3.139232 max_abs_grad=0.334431 param_norm=2232.606204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  40%|‚ñà‚ñà‚ñà‚ñâ      | 309/782 [00:06<00:09, 48.98it/s, loss=0.8223]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=300 grad_norm=1.428913 max_abs_grad=0.309194 param_norm=2232.609514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 406/782 [00:08<00:07, 49.65it/s, loss=0.8236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=400 grad_norm=2.144724 max_abs_grad=0.892972 param_norm=2232.613596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 510/782 [00:09<00:05, 53.49it/s, loss=0.8208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=500 grad_norm=1.651204 max_abs_grad=0.322458 param_norm=2232.616366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 606/782 [00:11<00:03, 52.33it/s, loss=0.8186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=600 grad_norm=1.346112 max_abs_grad=0.290910 param_norm=2232.619823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 708/782 [00:13<00:01, 50.08it/s, loss=0.8197]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=8 batch=700 grad_norm=4.655700 max_abs_grad=1.206181 param_norm=2232.623042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:15<00:00, 51.52it/s, loss=0.8177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 8...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 8/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6985  (baseline: 0.6995)\n",
      "  MAE:         0.2783\n",
      "  Am√©lioration: +0.1% vs baseline\n",
      "  Corr√©lation: 0.1349\n",
      "  Std preds:   0.0079  (cible: 0.6995)\n",
      "  Mean preds:  0.0472  (cible: 0.0363)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 9] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:   1%|          | 5/782 [00:00<00:18, 42.30it/s, loss=0.8816]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=0 grad_norm=1.480638 max_abs_grad=0.170524 param_norm=2232.626207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  14%|‚ñà‚ñé        | 107/782 [00:02<00:13, 50.57it/s, loss=0.8012]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=100 grad_norm=1.281037 max_abs_grad=0.189341 param_norm=2232.628658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  27%|‚ñà‚ñà‚ñã       | 209/782 [00:04<00:13, 43.21it/s, loss=0.8095]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=200 grad_norm=1.665386 max_abs_grad=0.405972 param_norm=2232.630740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  39%|‚ñà‚ñà‚ñà‚ñâ      | 307/782 [00:06<00:08, 55.66it/s, loss=0.8076]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=300 grad_norm=1.534648 max_abs_grad=0.370911 param_norm=2232.633776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 407/782 [00:07<00:06, 56.48it/s, loss=0.8043]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=400 grad_norm=1.234158 max_abs_grad=0.255626 param_norm=2232.636507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 509/782 [00:09<00:04, 56.41it/s, loss=0.8079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=500 grad_norm=2.825420 max_abs_grad=1.113012 param_norm=2232.638620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 609/782 [00:11<00:03, 55.74it/s, loss=0.8096]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=600 grad_norm=2.409114 max_abs_grad=0.968143 param_norm=2232.643689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 710/782 [00:13<00:01, 51.96it/s, loss=0.8077]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=9 batch=700 grad_norm=2.893303 max_abs_grad=1.234651 param_norm=2232.648739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:14<00:00, 53.36it/s, loss=0.8097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 9...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 9/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7791  (baseline: 0.7804)\n",
      "  MAE:         0.3034\n",
      "  Am√©lioration: +0.2% vs baseline\n",
      "  Corr√©lation: 0.1439\n",
      "  Std preds:   0.0095  (cible: 0.7804)\n",
      "  Mean preds:  0.0577  (cible: 0.0505)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 10] üé≤ √âchantillonnage: 200,000 positions sur 12,767,881\n",
      "‚û°Ô∏è Learning rate courant: 0.000050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:   1%|          | 4/782 [00:00<00:23, 33.60it/s, loss=0.8481]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=0 grad_norm=2.733377 max_abs_grad=1.745903 param_norm=2232.650933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  14%|‚ñà‚ñç        | 108/782 [00:02<00:12, 54.77it/s, loss=0.7921]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=100 grad_norm=2.417979 max_abs_grad=1.117083 param_norm=2232.652865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  27%|‚ñà‚ñà‚ñã       | 210/782 [00:04<00:10, 53.89it/s, loss=0.8031]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=200 grad_norm=1.940448 max_abs_grad=0.228261 param_norm=2232.656209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  39%|‚ñà‚ñà‚ñà‚ñâ      | 307/782 [00:05<00:08, 54.40it/s, loss=0.8027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=300 grad_norm=1.284995 max_abs_grad=0.171064 param_norm=2232.658095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 409/782 [00:07<00:06, 56.06it/s, loss=0.8096]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=400 grad_norm=3.755414 max_abs_grad=1.033444 param_norm=2232.661893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 505/782 [00:09<00:05, 52.76it/s, loss=0.8105]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=500 grad_norm=3.662746 max_abs_grad=0.861382 param_norm=2232.665160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 608/782 [00:11<00:03, 50.15it/s, loss=0.8121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=600 grad_norm=1.159008 max_abs_grad=0.164601 param_norm=2232.669194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 706/782 [00:13<00:01, 46.82it/s, loss=0.8123]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GRAD] epoch=10 batch=700 grad_norm=2.097652 max_abs_grad=1.028810 param_norm=2232.673073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [00:15<00:00, 51.63it/s, loss=0.8122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç √âvaluation epoch 10...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 10/10 - √âvaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8601  (baseline: 0.8599)\n",
      "  MAE:         0.3232\n",
      "  Am√©lioration: -0.0% vs baseline\n",
      "  Corr√©lation: 0.1335\n",
      "  Std preds:   0.0091  (cible: 0.8599)\n",
      "  Mean preds:  0.0642  (cible: 0.0156)\n",
      "  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "üéâ Entra√Ænement termin√©!\n",
      "üìä Meilleur RMSE: 0.4897\n",
      "\n",
      "üíæ Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "‚úÖ Mod√®le sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n"
     ]
    }
   ],
   "source": [
    "# Configurer et lancer le script d'entra√Ænement `ai.NN.torch_train` en adaptant les chemins pour Colab/Drive\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "if DATASET_CSV is None:\n",
    "    raise FileNotFoundError(f\"Dataset non trouv√© dans: {DATASET_DIR}\")\n",
    "\n",
    "# Importer le module d'entra√Ænement (UPDATED: torch_train au lieu de train_torch)\n",
    "import ai.NN.torch_train as trainer\n",
    "\n",
    "# Reload the module to pick up recent changes\n",
    "importlib.reload(trainer)\n",
    "\n",
    "# Rediriger les chemins dataset et checkpoints vers Drive\n",
    "trainer.DATASET_PATH = DATASET_CSV\n",
    "trainer.CHECKPOINT_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.CHECKPOINT_FILE))\n",
    "trainer.WEIGHTS_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.WEIGHTS_FILE))\n",
    "\n",
    "# Harmonisation des param√®tres avec CONFIG\n",
    "try:\n",
    "    trainer.BATCH_SIZE = CONFIG['batch_size']\n",
    "    print(f'‚úÖ Harmonisation: trainer.BATCH_SIZE = {trainer.BATCH_SIZE}')\n",
    "except Exception as e:\n",
    "    print('‚ö†Ô∏è Impossible de d√©finir trainer.BATCH_SIZE:', e)\n",
    "\n",
    "# Appliquer l'architecture NNUE\n",
    "try:\n",
    "    trainer.HIDDEN1 = CONFIG['hidden1']\n",
    "    trainer.HIDDEN2 = CONFIG['hidden2']\n",
    "    trainer.HIDDEN3 = CONFIG['hidden3']\n",
    "    trainer.DROPOUT = CONFIG['dropout']\n",
    "    print(f\"‚úÖ Architecture NNUE appliqu√©e: {trainer.HIDDEN1} ‚Üí {trainer.HIDDEN2} ‚Üí {trainer.HIDDEN3}\")\n",
    "except Exception as e:\n",
    "    print('‚ö†Ô∏è Impossible de d√©finir l\\'architecture NNUE:', e)\n",
    "\n",
    "# Optionnellement ajuster MAX_SAMPLES\n",
    "try:\n",
    "    trainer.MAX_SAMPLES = 200_000\n",
    "    print(f\"‚úÖ MAX_SAMPLES = {trainer.MAX_SAMPLES}\")\n",
    "except Exception as e:\n",
    "    print('‚ö†Ô∏è Impossible de d√©finir trainer.MAX_SAMPLES:', e)\n",
    "\n",
    "# Optionnel: r√©duire pour test rapide (d√©commentez si besoin)\n",
    "# trainer.EPOCHS = 2\n",
    "# trainer.MAX_SAMPLES = 5000\n",
    "\n",
    "print('\\nConfiguration trainer:')\n",
    "print(' DATASET_PATH=', trainer.DATASET_PATH)\n",
    "print(' CHECKPOINT_FILE=', trainer.CHECKPOINT_FILE)\n",
    "print(' WEIGHTS_FILE=', trainer.WEIGHTS_FILE)\n",
    "print(' Architecture: 768 ‚Üí', trainer.HIDDEN1, '‚Üí', trainer.HIDDEN2, '‚Üí', trainer.HIDDEN3, '‚Üí 1')\n",
    "print(' EPOCHS=', trainer.EPOCHS)\n",
    "print(' MAX_SAMPLES=', trainer.MAX_SAMPLES)\n",
    "\n",
    "# Lancer l'entra√Ænement\n",
    "trainer.main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf4e17",
   "metadata": {
    "id": "f2bf4e17"
   },
   "source": [
    "## 12. Visualisation des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46daebdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "error",
     "timestamp": 1763024539909,
     "user": {
      "displayName": "Raph Lebel",
      "userId": "08096249224484363228"
     },
     "user_tz": -60
    },
    "id": "46daebdc",
    "outputId": "a27aa6df-3954-45bb-c175-16e3cfeeb3af"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2834880122.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Graphique 1: Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#2E86AB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'√âpoque'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss (MSE)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurer le style des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Graphique 1: Loss\n",
    "axes[0].plot(history['loss'], linewidth=2, color='#2E86AB', label='Training Loss')\n",
    "axes[0].set_xlabel('√âpoque', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('√âvolution de la perte pendant l\\'entra√Ænement', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Afficher les valeurs min/max\n",
    "min_loss = min(history['loss'])\n",
    "max_loss = max(history['loss'])\n",
    "axes[0].axhline(y=min_loss, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_loss:.6f}')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Graphique 2: MAE (si disponible)\n",
    "if 'mae' in history:\n",
    "    axes[1].plot(history['mae'], linewidth=2, color='#F77F00', label='MAE')\n",
    "    axes[1].set_xlabel('√âpoque', fontsize=12)\n",
    "    axes[1].set_ylabel('MAE', fontsize=12)\n",
    "    axes[1].set_title('Erreur absolue moyenne', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    min_mae = min(history['mae'])\n",
    "    axes[1].axhline(y=min_mae, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_mae:.6f}')\n",
    "    axes[1].legend(fontsize=10)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'MAE non disponible',\n",
    "                ha='center', va='center', fontsize=14, transform=axes[1].transAxes)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Afficher les statistiques finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"Perte minimale: {min_loss:.6f} (√©poque {history['loss'].index(min_loss) + 1})\")\n",
    "if 'mae' in history:\n",
    "    print(f\"MAE final: {history['mae'][-1]:.6f}\")\n",
    "    print(f\"MAE minimal: {min_mae:.6f} (√©poque {history['mae'].index(min_mae) + 1})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f7779",
   "metadata": {
    "id": "859f7779"
   },
   "source": [
    "## 13. Sauvegarde du mod√®le final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6f55e",
   "metadata": {
    "cellView": "form",
    "id": "b0c6f55e"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import datetime\n",
    "\n",
    "# Timestamp pour identifier cette sauvegarde\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Sauvegarder le mod√®le complet avec l'historique\n",
    "final_model_path = f'ai/chess_model_final_{timestamp}.pt'\n",
    "torch.save({\n",
    "    'epoch': CONFIG['epochs'],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'history': history,\n",
    "    'timestamp': timestamp,\n",
    "}, final_model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAUVEGARDE DES MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úì Mod√®le final: {final_model_path}\")\n",
    "\n",
    "# Sauvegarder aussi au format .npz pour compatibilit√© avec l'ancien code\n",
    "weights_path = 'ai/NN/chess_nn_weights.npz'\n",
    "weights = {name: param.cpu().detach().numpy() for name, param in model.named_parameters()}\n",
    "np.savez(weights_path, **weights)\n",
    "print(f\"‚úì Poids .npz: {weights_path}\")\n",
    "\n",
    "# Copier aussi le checkpoint dans NN/\n",
    "import shutil\n",
    "checkpoint_backup = f'ai/NN/chess_model_checkpoint_{timestamp}.pt'\n",
    "if os.path.exists(CONFIG['checkpoint_path']):\n",
    "    shutil.copy(CONFIG['checkpoint_path'], checkpoint_backup)\n",
    "    print(f\"‚úì Checkpoint backup: {checkpoint_backup}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ Tous les fichiers sont sauvegard√©s sur votre Google Drive!\")\n",
    "print(f\"   Chemin: {PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd244",
   "metadata": {
    "id": "c4bfd244"
   },
   "source": [
    "## 14. Test du mod√®le sur des positions al√©atoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0315c06",
   "metadata": {
    "cellView": "form",
    "id": "b0315c06"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Passer le mod√®le en mode √©valuation\n",
    "model.eval()\n",
    "\n",
    "# Tester sur quelques positions al√©atoires\n",
    "num_tests = 10\n",
    "test_indices = np.random.choice(len(X_train), num_tests, replace=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TEST SUR {num_tests} POSITIONS AL√âATOIRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(test_indices, 1):\n",
    "        x = torch.FloatTensor(X_train[idx:idx+1]).to(CONFIG['device'])\n",
    "        y_true = y_train[idx]\n",
    "        y_pred = model(x).cpu().numpy()[0, 0]\n",
    "        error = abs(y_true - y_pred)\n",
    "        errors.append(error)\n",
    "\n",
    "        print(f\"\\nPosition {i}:\")\n",
    "        print(f\"  √âvaluation r√©elle:  {y_true:+8.4f}\")\n",
    "        print(f\"  Pr√©diction mod√®le:  {y_pred:+8.4f}\")\n",
    "        print(f\"  Erreur absolue:     {error:8.4f}\")\n",
    "\n",
    "        # Indicateur visuel de la qualit√©\n",
    "        if error < 0.1:\n",
    "            print(f\"  Qualit√©: ‚úÖ Excellente\")\n",
    "        elif error < 0.3:\n",
    "            print(f\"  Qualit√©: ‚úì Bonne\")\n",
    "        elif error < 0.5:\n",
    "            print(f\"  Qualit√©: ‚ö† Moyenne\")\n",
    "        else:\n",
    "            print(f\"  Qualit√©: ‚ùå Faible\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DES TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Erreur moyenne: {np.mean(errors):.4f}\")\n",
    "print(f\"Erreur m√©diane: {np.median(errors):.4f}\")\n",
    "print(f\"Erreur min:     {np.min(errors):.4f}\")\n",
    "print(f\"Erreur max:     {np.max(errors):.4f}\")\n",
    "print(f\"√âcart-type:     {np.std(errors):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9184e",
   "metadata": {
    "id": "30e9184e"
   },
   "source": [
    "## 15. R√©sum√© et fichiers g√©n√©r√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92229a",
   "metadata": {
    "cellView": "form",
    "id": "cb92229a"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä R√âSUM√â DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìç Projet: {PROJECT_PATH}\")\n",
    "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(f\"   ‚Ä¢ Parties g√©n√©r√©es: {CONFIG['num_games']:,}\")\n",
    "print(f\"   ‚Ä¢ Positions d'entra√Ænement: {len(X_train):,}\")\n",
    "print(f\"   ‚Ä¢ √âpoques: {CONFIG['epochs']}\")\n",
    "print(f\"   ‚Ä¢ Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   ‚Ä¢ Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   ‚Ä¢ Device: {CONFIG['device']}\")\n",
    "\n",
    "print(f\"\\nüìà R√©sultats:\")\n",
    "print(f\"   ‚Ä¢ Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"   ‚Ä¢ Perte minimale: {min(history['loss']):.6f}\")\n",
    "if 'mae' in history:\n",
    "    print(f\"   ‚Ä¢ MAE final: {history['mae'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\nüíæ Fichiers sauvegard√©s sur Drive:\")\n",
    "files_to_check = [\n",
    "    final_model_path,\n",
    "    CONFIG['checkpoint_path'],\n",
    "    weights_path,\n",
    "    'training_history.png'\n",
    "]\n",
    "\n",
    "for filepath in files_to_check:\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / (1024 * 1024)  # Convertir en MB\n",
    "        print(f\"   ‚úì {filepath} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {filepath} (non trouv√©)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTous les fichiers sont automatiquement synchronis√©s avec votre Google Drive.\")\n",
    "print(\"Vous pouvez fermer ce notebook en toute s√©curit√©.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4536d8",
   "metadata": {
    "cellView": "form",
    "id": "eb4536d8"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import os\n",
    "\n",
    "checkpoint_file = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt'\n",
    "\n",
    "if os.path.exists(checkpoint_file):\n",
    "    print(f\"Removing existing checkpoint file: {checkpoint_file}\")\n",
    "    os.remove(checkpoint_file)\n",
    "    print(\"Checkpoint removed.\")\n",
    "else:\n",
    "    print(f\"No checkpoint file found at {checkpoint_file}. No action needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971f1dc",
   "metadata": {
    "cellView": "form",
    "id": "e971f1dc"
   },
   "outputs": [],
   "source": [
    "# Smoke tests automatis√©s ‚Äî 3 runs courts pour comparer configurations NNUE\n",
    "# - Cr√©e une validation fixe, lance 3 exp√©riences courtes (EPOCHS=3, MAX_SAMPLES=100k)\n",
    "# - Sauvegarde checkpoints s√©par√©s et √©value chaque mod√®le sur la validation fixe\n",
    "\n",
    "import time\n",
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print('Lancement des smoke tests (rapides) avec architecture NNUE.\\n')\n",
    "\n",
    "# V√©rifier dataset et donn√©es en m√©moire\n",
    "if 'X_train' not in globals() or 'y_train' not in globals():\n",
    "    print('X_train/y_train non trouv√©s en m√©moire ‚Äî chargement l√©ger depuis trainer.DATASET_PATH (peut prendre du temps)...')\n",
    "    fens, evaluations = trainer.load_data(trainer.DATASET_PATH)\n",
    "    X_train = fens\n",
    "    y_train = evaluations\n",
    "\n",
    "# Cr√©er validation fixe (seed deterministe)\n",
    "val_size = min(5000, len(X_train))\n",
    "rs = np.random.RandomState(42)\n",
    "val_idx = rs.choice(len(X_train), size=val_size, replace=False)\n",
    "val_fens = X_train[val_idx]\n",
    "val_targets = y_train[val_idx]\n",
    "print(f'Validation fixe : {val_size} positions (seed=42)')\n",
    "\n",
    "# Sauvegarder originaux pour restauration\n",
    "orig_keys = ['HIDDEN1','HIDDEN2','HIDDEN3','DROPOUT','LEARNING_RATE','WEIGHT_DECAY','BATCH_SIZE','EPOCHS','MAX_SAMPLES','CHECKPOINT_FILE','WEIGHTS_FILE','EVAL_MAX_SAMPLES']\n",
    "orig = {k: getattr(trainer, k) for k in orig_keys if hasattr(trainer, k)}\n",
    "\n",
    "# Exp√©riences √† tester (NNUE architecture variations)\n",
    "experiments = [\n",
    "    {'name': 'baseline', 'HIDDEN1': 4096, 'HIDDEN2': 256, 'HIDDEN3': 32, 'DROPOUT': 0.0, 'LEARNING_RATE': 0.001},\n",
    "    {'name': 'bigger', 'HIDDEN1': 8192, 'HIDDEN2': 512, 'HIDDEN3': 64, 'DROPOUT': 0.0, 'LEARNING_RATE': 5e-4},\n",
    "    {'name': 'smaller_lr', 'HIDDEN1': 4096, 'HIDDEN2': 256, 'HIDDEN3': 32, 'DROPOUT': 0.0, 'LEARNING_RATE': 1e-4},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    print('\\n' + '='*80)\n",
    "    print(f\"Exp: {exp['name']}\")\n",
    "    print('='*80)\n",
    "\n",
    "    # Set quick test params\n",
    "    trainer.EPOCHS = 3\n",
    "    trainer.MAX_SAMPLES = 100_000\n",
    "    trainer.EVAL_MAX_SAMPLES = 2000\n",
    "\n",
    "    # Apply experiment overrides\n",
    "    trainer.HIDDEN1 = exp['HIDDEN1']\n",
    "    trainer.HIDDEN2 = exp['HIDDEN2']\n",
    "    trainer.HIDDEN3 = exp['HIDDEN3']\n",
    "    trainer.DROPOUT = exp['DROPOUT']\n",
    "    trainer.LEARNING_RATE = exp['LEARNING_RATE']\n",
    "\n",
    "    # Use separate checkpoint/weights files to avoid overwriting\n",
    "    ckpt_path = os.path.join(CKPT_DIR, f\"smoke_{exp['name']}.pt\")\n",
    "    weights_path = os.path.join(CKPT_DIR, f\"smoke_{exp['name']}.npz\")\n",
    "    trainer.CHECKPOINT_FILE = ckpt_path\n",
    "    trainer.WEIGHTS_FILE = weights_path\n",
    "\n",
    "    print('Parameters:')\n",
    "    print(f\" Architecture: 768 ‚Üí {trainer.HIDDEN1} ‚Üí {trainer.HIDDEN2} ‚Üí {trainer.HIDDEN3} ‚Üí 1\")\n",
    "    print(f\" DROPOUT={trainer.DROPOUT}, LR={trainer.LEARNING_RATE}\")\n",
    "    print(f\" EPOCHS={trainer.EPOCHS}, MAX_SAMPLES={trainer.MAX_SAMPLES}\")\n",
    "    print(f\" CHECKPOINT -> {trainer.CHECKPOINT_FILE}\")\n",
    "\n",
    "    # Run training (blocking)\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        trainer.main()\n",
    "    except Exception as e:\n",
    "        print('Erreur pendant trainer.main():', e)\n",
    "    t1 = time.time()\n",
    "    print(f\"Run time: {t1-t0:.1f}s\")\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    try:\n",
    "        model = trainer.TorchNNEvaluator(hidden1=trainer.HIDDEN1, hidden2=trainer.HIDDEN2, hidden3=trainer.HIDDEN3, dropout=trainer.DROPOUT)\n",
    "        optimizer = trainer.optim.AdamW(model.parameters(), lr=trainer.LEARNING_RATE, weight_decay=trainer.WEIGHT_DECAY)\n",
    "        model, optim_state, step = trainer.torch_load_checkpoint(trainer.CHECKPOINT_FILE, model, optimizer, device=trainer.DEVICE)\n",
    "\n",
    "        # Evaluation on fixed val set\n",
    "        eval_dataset = trainer.ChessDataset(val_fens, val_targets)\n",
    "        eval_loader = DataLoader(eval_dataset, batch_size=max(1, trainer.BATCH_SIZE//2), shuffle=False)\n",
    "        rmse, mae, corr, preds, targets = trainer.evaluate_model(model, eval_loader, trainer.DEVICE)\n",
    "        print(f\"Eval results ‚Äî RMSE: {rmse:.4f}, MAE: {mae:.4f}, Corr: {corr:.4f}\")\n",
    "        results.append({'exp': exp['name'], 'rmse': rmse, 'mae': mae, 'corr': corr})\n",
    "    except FileNotFoundError:\n",
    "        print('Checkpoint not found, skipping evaluation for this experiment.')\n",
    "        results.append({'exp': exp['name'], 'rmse': None, 'mae': None, 'corr': None})\n",
    "    except Exception as e:\n",
    "        print('Erreur lors de l\\'√©valuation:', e)\n",
    "        results.append({'exp': exp['name'], 'rmse': None, 'mae': None, 'corr': None})\n",
    "\n",
    "# Restore original trainer settings\n",
    "for k, v in orig.items():\n",
    "    setattr(trainer, k, v)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('R√©sum√© des smoke tests:')\n",
    "for r in results:\n",
    "    print(r)\n",
    "print('='*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967c73b",
   "metadata": {
    "cellView": "form",
    "id": "e967c73b"
   },
   "outputs": [],
   "source": [
    "# Smoke-extended param√©trable ‚Äî runs r√©p√©t√©s et mode rapide (NNUE)\n",
    "# Usage:\n",
    "# - r√©gler FAST_MODE=True pour it√©rations ultra-rapides (EPOCHS=1, MAX_SAMPLES=20k)\n",
    "# - r√©gler REPS pour r√©p√©ter chaque exp√©rience sur plusieurs seeds\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print('\\n=== Smoke-extended d√©marr√© (NNUE) ===')\n",
    "\n",
    "# Param√®tres utilisateur\n",
    "FAST_MODE = False\n",
    "EPOCHS_EXT = 5\n",
    "MAX_SAMPLES_EXT = 200_000\n",
    "REPS = 1\n",
    "BASE_SEED = 42\n",
    "\n",
    "if FAST_MODE:\n",
    "    EPOCHS_EXT = 1\n",
    "    MAX_SAMPLES_EXT = 20_000\n",
    "\n",
    "print(f\"FAST_MODE={FAST_MODE}, EPOCHS={EPOCHS_EXT}, MAX_SAMPLES={MAX_SAMPLES_EXT}, REPS={REPS}\")\n",
    "\n",
    "# V√©rifier que trainer est charg√©\n",
    "if 'trainer' not in globals():\n",
    "    raise RuntimeError('Le module trainer (ai.NN.torch_train) doit √™tre import√© avant d\\'ex√©cuter cette cellule.')\n",
    "\n",
    "# Charger donn√©es si n√©cessaire\n",
    "if 'X_train' not in globals() or 'y_train' not in globals():\n",
    "    print('X_train/y_train non pr√©sents en m√©moire ‚Äî chargement via trainer.load_data(...)')\n",
    "    fens, evaluations = trainer.load_data(trainer.DATASET_PATH)\n",
    "    X_train = fens\n",
    "    y_train = evaluations\n",
    "\n",
    "# Validation fixe\n",
    "val_size = min(5000, len(X_train))\n",
    "rs = np.random.RandomState(42)\n",
    "val_idx = rs.choice(len(X_train), size=val_size, replace=False)\n",
    "val_fens = X_train[val_idx]\n",
    "val_targets = y_train[val_idx]\n",
    "print(f'Validation fixe : {val_size} positions (seed=42)')\n",
    "\n",
    "# Conserver param√®tres originaux\n",
    "orig_keys = ['HIDDEN1','HIDDEN2','HIDDEN3','DROPOUT','LEARNING_RATE','WEIGHT_DECAY','BATCH_SIZE','EPOCHS','MAX_SAMPLES','CHECKPOINT_FILE','WEIGHTS_FILE','EVAL_MAX_SAMPLES']\n",
    "orig = {k: getattr(trainer, k) for k in orig_keys if hasattr(trainer, k)}\n",
    "\n",
    "# Exp√©riences NNUE\n",
    "experiments = [\n",
    "    {'name': 'baseline', 'HIDDEN1': 4096, 'HIDDEN2': 256, 'HIDDEN3': 32, 'DROPOUT': 0.0, 'LEARNING_RATE': 0.001},\n",
    "    {'name': 'bigger', 'HIDDEN1': 8192, 'HIDDEN2': 512, 'HIDDEN3': 64, 'DROPOUT': 0.0, 'LEARNING_RATE': 5e-4},\n",
    "    {'name': 'smaller_lr', 'HIDDEN1': 4096, 'HIDDEN2': 256, 'HIDDEN3': 32, 'DROPOUT': 0.0, 'LEARNING_RATE': 1e-4},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    for rep in range(REPS):\n",
    "        seed = BASE_SEED + rep\n",
    "        run_name = f\"{exp['name']}_r{rep+1}_s{seed}\"\n",
    "        print('\\n' + '='*80)\n",
    "        print(f\"Run: {run_name}\")\n",
    "        print('='*80)\n",
    "\n",
    "        trainer.EPOCHS = EPOCHS_EXT\n",
    "        trainer.MAX_SAMPLES = MAX_SAMPLES_EXT\n",
    "        trainer.EVAL_MAX_SAMPLES = min(2000, MAX_SAMPLES_EXT//50)\n",
    "\n",
    "        trainer.HIDDEN1 = exp['HIDDEN1']\n",
    "        trainer.HIDDEN2 = exp['HIDDEN2']\n",
    "        trainer.HIDDEN3 = exp['HIDDEN3']\n",
    "        trainer.DROPOUT = exp['DROPOUT']\n",
    "        trainer.LEARNING_RATE = exp['LEARNING_RATE']\n",
    "\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"smoke_ext_{run_name}.pt\")\n",
    "        weights_path = os.path.join(CKPT_DIR, f\"smoke_ext_{run_name}.npz\")\n",
    "        trainer.CHECKPOINT_FILE = ckpt_path\n",
    "        trainer.WEIGHTS_FILE = weights_path\n",
    "\n",
    "        print('Params:', f\"Arch: 768‚Üí{trainer.HIDDEN1}‚Üí{trainer.HIDDEN2}‚Üí{trainer.HIDDEN3}‚Üí1, dropout={trainer.DROPOUT}, lr={trainer.LEARNING_RATE}\")\n",
    "        print('Run params:', f\"EPOCHS={trainer.EPOCHS}, MAX_SAMPLES={trainer.MAX_SAMPLES}\")\n",
    "\n",
    "        try:\n",
    "            import torch\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            if trainer.DEVICE and 'cuda' in str(trainer.DEVICE):\n",
    "                torch.cuda.manual_seed_all(seed)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            trainer.main()\n",
    "        except Exception as e:\n",
    "            print('Erreur pendant trainer.main():', e)\n",
    "        t1 = time.time()\n",
    "        print(f'Run time: {t1-t0:.1f}s')\n",
    "\n",
    "        try:\n",
    "            model = trainer.TorchNNEvaluator(hidden1=trainer.HIDDEN1, hidden2=trainer.HIDDEN2, hidden3=trainer.HIDDEN3, dropout=trainer.DROPOUT)\n",
    "            optimizer = trainer.optim.AdamW(model.parameters(), lr=trainer.LEARNING_RATE, weight_decay=getattr(trainer,'WEIGHT_DECAY',1e-4))\n",
    "            model, opt_state, step = trainer.torch_load_checkpoint(trainer.CHECKPOINT_FILE, model, optimizer, device=trainer.DEVICE)\n",
    "\n",
    "            eval_dataset = trainer.ChessDataset(val_fens, val_targets)\n",
    "            eval_loader = DataLoader(eval_dataset, batch_size=max(1, trainer.BATCH_SIZE//2), shuffle=False)\n",
    "            rmse, mae, corr, preds, targets = trainer.evaluate_model(model, eval_loader, trainer.DEVICE)\n",
    "            print(f\"Eval ‚Äî RMSE: {rmse:.4f}, MAE: {mae:.4f}, Corr: {corr:.4f}\")\n",
    "            results.append({'run': run_name, 'exp': exp['name'], 'seed': seed, 'rmse': rmse, 'mae': mae, 'corr': corr, 'ckpt': trainer.CHECKPOINT_FILE})\n",
    "        except FileNotFoundError:\n",
    "            print('Checkpoint introuvable.')\n",
    "            results.append({'run': run_name, 'exp': exp['name'], 'seed': seed, 'rmse': None, 'mae': None, 'corr': None, 'ckpt': trainer.CHECKPOINT_FILE})\n",
    "        except Exception as e:\n",
    "            print('Erreur √©valuation:', e)\n",
    "            results.append({'run': run_name, 'exp': exp['name'], 'seed': seed, 'rmse': None, 'mae': None, 'corr': None, 'ckpt': trainer.CHECKPOINT_FILE})\n",
    "\n",
    "for k, v in orig.items():\n",
    "    setattr(trainer, k, v)\n",
    "\n",
    "print('\\n=== R√©sum√© smoke-extended ===')\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "summary_path = os.path.join(CKPT_DIR, 'smoke_extended_summary.csv')\n",
    "df.to_csv(summary_path, index=False)\n",
    "print('R√©sum√© sauvegard√© dans', summary_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
