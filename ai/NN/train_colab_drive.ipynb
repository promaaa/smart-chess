{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b5a4df",
   "metadata": {},
   "source": [
    "# Entra√Ænement du Neural Network pour Smart Chess sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entra√Æner le r√©seau de neurones pour l'√©valuation d'√©checs en utilisant les ressources GPU de Google Colab.\n",
    "\n",
    "**Chemin du projet sur Drive:** `MyDrive/smart_chess_drive/smart-chess`\n",
    "\n",
    "## Instructions\n",
    "1. Aller dans **Runtime > Change runtime type > GPU** (T4 ou mieux)\n",
    "2. Ex√©cuter les cellules dans l'ordre\n",
    "3. Les mod√®les seront sauvegard√©s automatiquement sur votre Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b4590",
   "metadata": {},
   "source": [
    "## 1. V√©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier la disponibilit√© du GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddd742",
   "metadata": {},
   "source": [
    "## 2. Montage Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e4f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf2990",
   "metadata": {},
   "source": [
    "## 3. Configuration du chemin du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir le chemin vers le projet sur votre Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "os.chdir(PROJECT_PATH)\n",
    "sys.path.insert(0, PROJECT_PATH)\n",
    "\n",
    "print(f\"R√©pertoire de travail: {os.getcwd()}\")\n",
    "print(f\"\\nContenu du r√©pertoire:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20e36c",
   "metadata": {},
   "source": [
    "## 4. Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer les packages n√©cessaires\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy matplotlib tqdm\n",
    "\n",
    "print(\"‚úì Installation termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25365688",
   "metadata": {},
   "source": [
    "## 5. V√©rification de l'environnement PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION SYST√àME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"\\nCUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"M√©moire GPU totale: {props.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ATTENTION: GPU non disponible, l'entra√Ænement sera tr√®s lent!\")\n",
    "    print(\"   Allez dans Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a1e23",
   "metadata": {},
   "source": [
    "## 6. Import des modules du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7397821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les modules n√©cessaires depuis le projet\n",
    "try:\n",
    "    from ai.NN.train_torch import (\n",
    "        train_model,\n",
    "        generate_training_data,\n",
    "        ChessDataset,\n",
    "        ChessNet\n",
    "    )\n",
    "    from ai.Chess_v2 import Chess\n",
    "    print(\"‚úì Modules import√©s avec succ√®s!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erreur d'import: {e}\")\n",
    "    print(\"\\nV√©rifiez que vous √™tes dans le bon r√©pertoire et que tous les fichiers sont pr√©sents.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e668793",
   "metadata": {},
   "source": [
    "## 7. Configuration de l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f87f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param√®tres d'entra√Ænement\n",
    "CONFIG = {\n",
    "    # G√©n√©ration de donn√©es\n",
    "    'num_games': 10000,          # Nombre de parties √† g√©n√©rer pour l'entra√Ænement\n",
    "    \n",
    "    # Hyperparam√®tres\n",
    "    'batch_size': 256,           # Taille du batch (augmenter si GPU puissant)\n",
    "    'epochs': 50,                # Nombre d'√©poques d'entra√Ænement\n",
    "    'learning_rate': 0.001,      # Taux d'apprentissage\n",
    "    \n",
    "    # Configuration syst√®me\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 2,            # Workers pour le DataLoader\n",
    "    \n",
    "    # Sauvegarde\n",
    "    'checkpoint_path': 'ai/chess_model_checkpoint.pt',\n",
    "    'save_interval': 5,          # Sauvegarder tous les N √©poques\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    print(\"\\n‚ö†Ô∏è ATTENTION: Entra√Ænement sur CPU d√©tect√©!\")\n",
    "    print(\"   R√©duisez num_games et epochs pour un test rapide.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ad90f",
   "metadata": {},
   "source": [
    "## 8. G√©n√©ration des donn√©es d'entra√Ænement\n",
    "\n",
    "Cette √©tape g√©n√®re des parties d'√©checs al√©atoires et calcule les √©valuations de position.\n",
    "**Attention:** Cela peut prendre 15-30 minutes selon le nombre de parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(f\"G√©n√©ration de {CONFIG['num_games']} parties...\")\n",
    "print(\"Cette op√©ration peut prendre du temps, soyez patient!\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# G√©n√©rer les donn√©es\n",
    "X_train, y_train = generate_training_data(CONFIG['num_games'])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONN√âES G√âN√âR√âES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Forme de X_train: {X_train.shape}\")\n",
    "print(f\"Forme de y_train: {y_train.shape}\")\n",
    "print(f\"Nombre total de positions: {len(X_train):,}\")\n",
    "print(f\"Temps √©coul√©: {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n",
    "print(f\"Positions/seconde: {len(X_train)/elapsed_time:.1f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques sur les donn√©es\n",
    "print(f\"\\nStatistiques sur les √©valuations:\")\n",
    "print(f\"  Min: {y_train.min():.4f}\")\n",
    "print(f\"  Max: {y_train.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.4f}\")\n",
    "print(f\"  √âcart-type: {y_train.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea4dd7",
   "metadata": {},
   "source": [
    "## 9. Cr√©ation du dataset et du dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Cr√©er le dataset\n",
    "dataset = ChessDataset(X_train, y_train)\n",
    "\n",
    "# Cr√©er le dataloader\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATALOADER CONFIGUR√â\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Taille du dataset: {len(dataset):,} √©chantillons\")\n",
    "print(f\"Nombre de batches: {len(train_loader):,}\")\n",
    "print(f\"Taille du batch: {CONFIG['batch_size']}\")\n",
    "print(f\"Derni√®re batch: {len(dataset) % CONFIG['batch_size']} √©chantillons\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dda22",
   "metadata": {},
   "source": [
    "## 10. Cr√©ation du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d2b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le mod√®le et le d√©placer sur le device appropri√©\n",
    "model = ChessNet().to(CONFIG['device'])\n",
    "\n",
    "# Afficher l'architecture\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHITECTURE DU MOD√àLE\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compter les param√®tres\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nNombre total de param√®tres: {total_params:,}\")\n",
    "print(f\"Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "\n",
    "# Estimer la taille m√©moire du mod√®le\n",
    "param_size_mb = total_params * 4 / (1024 ** 2)  # 4 bytes par float32\n",
    "print(f\"Taille estim√©e du mod√®le: {param_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ba4a7",
   "metadata": {},
   "source": [
    "## 11. Entra√Ænement du mod√®le\n",
    "\n",
    "Cette √©tape lance l'entra√Ænement complet. Les checkpoints sont sauvegard√©s automatiquement sur votre Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"D√âBUT DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"√âpoques: {CONFIG['epochs']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    learning_rate=CONFIG['learning_rate'],\n",
    "    device=CONFIG['device'],\n",
    "    checkpoint_path=CONFIG['checkpoint_path'],\n",
    "    save_interval=CONFIG['save_interval']\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENTRA√éNEMENT TERMIN√â!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Temps total: {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "print(f\"Temps par √©poque: {training_time/CONFIG['epochs']:.1f}s\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf4e17",
   "metadata": {},
   "source": [
    "## 12. Visualisation des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46daebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurer le style des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Graphique 1: Loss\n",
    "axes[0].plot(history['loss'], linewidth=2, color='#2E86AB', label='Training Loss')\n",
    "axes[0].set_xlabel('√âpoque', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('√âvolution de la perte pendant l\\'entra√Ænement', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Afficher les valeurs min/max\n",
    "min_loss = min(history['loss'])\n",
    "max_loss = max(history['loss'])\n",
    "axes[0].axhline(y=min_loss, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_loss:.6f}')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Graphique 2: MAE (si disponible)\n",
    "if 'mae' in history:\n",
    "    axes[1].plot(history['mae'], linewidth=2, color='#F77F00', label='MAE')\n",
    "    axes[1].set_xlabel('√âpoque', fontsize=12)\n",
    "    axes[1].set_ylabel('MAE', fontsize=12)\n",
    "    axes[1].set_title('Erreur absolue moyenne', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    min_mae = min(history['mae'])\n",
    "    axes[1].axhline(y=min_mae, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_mae:.6f}')\n",
    "    axes[1].legend(fontsize=10)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'MAE non disponible', \n",
    "                ha='center', va='center', fontsize=14, transform=axes[1].transAxes)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Afficher les statistiques finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"Perte minimale: {min_loss:.6f} (√©poque {history['loss'].index(min_loss) + 1})\")\n",
    "if 'mae' in history:\n",
    "    print(f\"MAE final: {history['mae'][-1]:.6f}\")\n",
    "    print(f\"MAE minimal: {min_mae:.6f} (√©poque {history['mae'].index(min_mae) + 1})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f7779",
   "metadata": {},
   "source": [
    "## 13. Sauvegarde du mod√®le final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Timestamp pour identifier cette sauvegarde\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Sauvegarder le mod√®le complet avec l'historique\n",
    "final_model_path = f'ai/chess_model_final_{timestamp}.pt'\n",
    "torch.save({\n",
    "    'epoch': CONFIG['epochs'],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'history': history,\n",
    "    'timestamp': timestamp,\n",
    "}, final_model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAUVEGARDE DES MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úì Mod√®le final: {final_model_path}\")\n",
    "\n",
    "# Sauvegarder aussi au format .npz pour compatibilit√© avec l'ancien code\n",
    "weights_path = 'ai/NN/chess_nn_weights.npz'\n",
    "weights = {name: param.cpu().detach().numpy() for name, param in model.named_parameters()}\n",
    "np.savez(weights_path, **weights)\n",
    "print(f\"‚úì Poids .npz: {weights_path}\")\n",
    "\n",
    "# Copier aussi le checkpoint dans NN/\n",
    "import shutil\n",
    "checkpoint_backup = f'ai/NN/chess_model_checkpoint_{timestamp}.pt'\n",
    "if os.path.exists(CONFIG['checkpoint_path']):\n",
    "    shutil.copy(CONFIG['checkpoint_path'], checkpoint_backup)\n",
    "    print(f\"‚úì Checkpoint backup: {checkpoint_backup}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n‚úÖ Tous les fichiers sont sauvegard√©s sur votre Google Drive!\")\n",
    "print(f\"   Chemin: {PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd244",
   "metadata": {},
   "source": [
    "## 14. Test du mod√®le sur des positions al√©atoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0315c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passer le mod√®le en mode √©valuation\n",
    "model.eval()\n",
    "\n",
    "# Tester sur quelques positions al√©atoires\n",
    "num_tests = 10\n",
    "test_indices = np.random.choice(len(X_train), num_tests, replace=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TEST SUR {num_tests} POSITIONS AL√âATOIRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(test_indices, 1):\n",
    "        x = torch.FloatTensor(X_train[idx:idx+1]).to(CONFIG['device'])\n",
    "        y_true = y_train[idx]\n",
    "        y_pred = model(x).cpu().numpy()[0, 0]\n",
    "        error = abs(y_true - y_pred)\n",
    "        errors.append(error)\n",
    "        \n",
    "        print(f\"\\nPosition {i}:\")\n",
    "        print(f\"  √âvaluation r√©elle:  {y_true:+8.4f}\")\n",
    "        print(f\"  Pr√©diction mod√®le:  {y_pred:+8.4f}\")\n",
    "        print(f\"  Erreur absolue:     {error:8.4f}\")\n",
    "        \n",
    "        # Indicateur visuel de la qualit√©\n",
    "        if error < 0.1:\n",
    "            print(f\"  Qualit√©: ‚úÖ Excellente\")\n",
    "        elif error < 0.3:\n",
    "            print(f\"  Qualit√©: ‚úì Bonne\")\n",
    "        elif error < 0.5:\n",
    "            print(f\"  Qualit√©: ‚ö† Moyenne\")\n",
    "        else:\n",
    "            print(f\"  Qualit√©: ‚ùå Faible\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DES TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Erreur moyenne: {np.mean(errors):.4f}\")\n",
    "print(f\"Erreur m√©diane: {np.median(errors):.4f}\")\n",
    "print(f\"Erreur min:     {np.min(errors):.4f}\")\n",
    "print(f\"Erreur max:     {np.max(errors):.4f}\")\n",
    "print(f\"√âcart-type:     {np.std(errors):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9184e",
   "metadata": {},
   "source": [
    "## 15. R√©sum√© et fichiers g√©n√©r√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä R√âSUM√â DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìç Projet: {PROJECT_PATH}\")\n",
    "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
    "print(f\"   ‚Ä¢ Parties g√©n√©r√©es: {CONFIG['num_games']:,}\")\n",
    "print(f\"   ‚Ä¢ Positions d'entra√Ænement: {len(X_train):,}\")\n",
    "print(f\"   ‚Ä¢ √âpoques: {CONFIG['epochs']}\")\n",
    "print(f\"   ‚Ä¢ Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   ‚Ä¢ Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   ‚Ä¢ Device: {CONFIG['device']}\")\n",
    "\n",
    "print(f\"\\nüìà R√©sultats:\")\n",
    "print(f\"   ‚Ä¢ Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"   ‚Ä¢ Perte minimale: {min(history['loss']):.6f}\")\n",
    "if 'mae' in history:\n",
    "    print(f\"   ‚Ä¢ MAE final: {history['mae'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\nüíæ Fichiers sauvegard√©s sur Drive:\")\n",
    "files_to_check = [\n",
    "    final_model_path,\n",
    "    CONFIG['checkpoint_path'],\n",
    "    weights_path,\n",
    "    'training_history.png'\n",
    "]\n",
    "\n",
    "for filepath in files_to_check:\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / (1024 * 1024)  # Convertir en MB\n",
    "        print(f\"   ‚úì {filepath} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {filepath} (non trouv√©)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTous les fichiers sont automatiquement synchronis√©s avec votre Google Drive.\")\n",
    "print(\"Vous pouvez fermer ce notebook en toute s√©curit√©.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f74c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localiser le dataset sur Google Drive et pr√©parer le dossier de checkpoints\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Chemin attendu du dossier contenant le dataset (donn√© par l'utilisateur)\n",
    "DATASET_DIR = '/content/drive/MyDrive/smart_chess_drive/chessData'\n",
    "\n",
    "# Chercher un fichier .csv dans DATASET_DIR\n",
    "DATASET_CSV = None\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    csvs = glob(os.path.join(DATASET_DIR, '*.csv'))\n",
    "    if len(csvs) > 0:\n",
    "        DATASET_CSV = csvs[0]\n",
    "        print(f'‚úÖ Dataset CSV trouv√©: {DATASET_CSV}')\n",
    "    else:\n",
    "        print(f'‚ùå Aucun fichier .csv trouv√© dans {DATASET_DIR}. Placez votre fichier chessData.csv dans ce dossier.')\n",
    "else:\n",
    "    print(f'‚ùå Dossier dataset introuvable: {DATASET_DIR}. V√©rifiez le chemin sur votre Drive.')\n",
    "\n",
    "# Cr√©er un dossier de checkpoints dans le repo sur Drive (persistant)\n",
    "CKPT_DIR = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "print('Dossier de checkpoints (cr√©√© si manquant):', CKPT_DIR)\n",
    "\n",
    "# Exposer variables utiles\n",
    "print('\\nVariables expos√©es:')\n",
    "print(' DATASET_CSV =', DATASET_CSV)\n",
    "print(' CKPT_DIR =', CKPT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer et lancer le script d'entra√Ænement `ai.NN.train_torch` en adaptant les chemins pour Colab/Drive\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "if DATASET_CSV is None:\n",
    "    raise FileNotFoundError(f\"Dataset non trouv√© dans: {DATASET_DIR}\")\n",
    "\n",
    "# Importer le module d'entra√Ænement\n",
    "import ai.NN.train_torch as trainer\n",
    "\n",
    "# Rediriger les chemins dataset et checkpoints vers Drive\n",
    "trainer.DATASET_PATH = DATASET_CSV\n",
    "trainer.CHECKPOINT_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.CHECKPOINT_FILE))\n",
    "trainer.WEIGHTS_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.WEIGHTS_FILE))\n",
    "\n",
    "# Optionnel: r√©duire pour test rapide (d√©commentez si besoin)\n",
    "# trainer.EPOCHS = 2\n",
    "# trainer.MAX_SAMPLES = 5000\n",
    "\n",
    "print('Configuration trainer:')\n",
    "print(' DATASET_PATH=', trainer.DATASET_PATH)\n",
    "print(' CHECKPOINT_FILE=', trainer.CHECKPOINT_FILE)\n",
    "print(' WEIGHTS_FILE=', trainer.WEIGHTS_FILE)\n",
    "print(' EPOCHS=', trainer.EPOCHS)\n",
    "print(' MAX_SAMPLES=', trainer.MAX_SAMPLES)\n",
    "\n",
    "# Lancer l'entra√Ænement\n",
    "trainer.main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
