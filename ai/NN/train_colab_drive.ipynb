{"cells":[{"cell_type":"markdown","id":"12b5a4df","metadata":{"id":"12b5a4df"},"source":["# Entra√Ænement du Neural Network pour Smart Chess sur Google Colab\n","\n","Ce notebook permet d'entra√Æner le r√©seau de neurones pour l'√©valuation d'√©checs en utilisant les ressources GPU de Google Colab.\n","\n","**Chemin du projet sur Drive:** `MyDrive/smart_chess_drive/smart-chess`\n","\n","## Instructions\n","1. Aller dans **Runtime > Change runtime type > GPU** (T4 ou mieux)\n","2. Ex√©cuter les cellules dans l'ordre\n","3. Les mod√®les seront sauvegard√©s automatiquement sur votre Drive"]},{"cell_type":"markdown","id":"de1b4590","metadata":{"id":"de1b4590"},"source":["## 1. V√©rification GPU"]},{"cell_type":"code","execution_count":null,"id":"8d5e0dc5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179,"status":"ok","timestamp":1761571039663,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"8d5e0dc5","outputId":"6d42087b-a9cb-4fd6-9554-468bb8ce71ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Oct 27 13:17:19 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["# V√©rifier la disponibilit√© du GPU\n","!nvidia-smi"]},{"cell_type":"markdown","id":"89ddd742","metadata":{"id":"89ddd742"},"source":["## 2. Montage Google Drive"]},{"cell_type":"code","execution_count":null,"id":"ce5e4f04","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18520,"status":"ok","timestamp":1761572617333,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"ce5e4f04","outputId":"aa8dc79e-61d1-4a93-84b7-649f1b40ec16"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Monter Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"1ccf2990","metadata":{"id":"1ccf2990"},"source":["## 3. Configuration du chemin du projet"]},{"cell_type":"code","execution_count":null,"id":"fabb986a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":829,"status":"ok","timestamp":1761572621857,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"fabb986a","outputId":"87e34ea8-771b-48bb-859b-195d895d3534"},"outputs":[{"name":"stdout","output_type":"stream","text":["R√©pertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n","\n","Contenu du r√©pertoire:\n","  - .git\n","  - .gitignore\n","  - README.md\n","  - ai\n","  - docs\n","  - prototypes\n"]}],"source":["# D√©finir le chemin vers le projet sur votre Drive\n","import os\n","import sys\n","\n","PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n","os.chdir(PROJECT_PATH)\n","sys.path.insert(0, PROJECT_PATH)\n","\n","print(f\"R√©pertoire de travail: {os.getcwd()}\")\n","print(f\"\\nContenu du r√©pertoire:\")\n","for item in sorted(os.listdir('.')):\n","    print(f\"  - {item}\")"]},{"cell_type":"markdown","id":"3f20e36c","metadata":{"id":"3f20e36c"},"source":["## 4. Installation des d√©pendances"]},{"cell_type":"code","execution_count":null,"id":"7783beaf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11360,"status":"ok","timestamp":1761572636808,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"7783beaf","outputId":"b44e4c2a-6aa2-46a6-c8b1-f81a9d616a51"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úì Installation termin√©e\n"]}],"source":["# Installer les packages n√©cessaires\n","!pip install -q torch torchvision torchaudio\n","!pip install -q numpy matplotlib tqdm\n","\n","print(\"‚úì Installation termin√©e\")"]},{"cell_type":"markdown","id":"25365688","metadata":{"id":"25365688"},"source":["## 5. V√©rification de l'environnement PyTorch"]},{"cell_type":"code","execution_count":null,"id":"a76e678b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5047,"status":"ok","timestamp":1761572646437,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"a76e678b","outputId":"bc113e8b-6a04-4a86-dd6a-fa69f71c0b32"},"outputs":[{"name":"stdout","output_type":"stream","text":["============================================================\n","CONFIGURATION SYST√àME\n","============================================================\n","PyTorch version: 2.8.0+cu126\n","NumPy version: 2.0.2\n","\n","CUDA disponible: True\n","CUDA version: 12.6\n","Nom du GPU: Tesla T4\n","M√©moire GPU totale: 15.83 GB\n","Compute Capability: 7.5\n","============================================================\n"]}],"source":["import torch\n","import numpy as np\n","\n","print(\"=\" * 60)\n","print(\"CONFIGURATION SYST√àME\")\n","print(\"=\" * 60)\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"NumPy version: {np.__version__}\")\n","print(f\"\\nCUDA disponible: {torch.cuda.is_available()}\")\n","\n","if torch.cuda.is_available():\n","    print(f\"CUDA version: {torch.version.cuda}\")\n","    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n","    props = torch.cuda.get_device_properties(0)\n","    print(f\"M√©moire GPU totale: {props.total_memory / 1e9:.2f} GB\")\n","    print(f\"Compute Capability: {props.major}.{props.minor}\")\n","else:\n","    print(\"‚ö†Ô∏è ATTENTION: GPU non disponible, l'entra√Ænement sera tr√®s lent!\")\n","    print(\"   Allez dans Runtime > Change runtime type > GPU\")\n","\n","print(\"=\" * 60)"]},{"cell_type":"markdown","id":"f91a1e23","metadata":{"id":"f91a1e23"},"source":["## 6. Import des modules du projet"]},{"cell_type":"code","execution_count":18,"id":"c7397821","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1761573675504,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"c7397821","outputId":"68a09eb3-6a2d-42f1-bdf9-506c0b23668e"},"outputs":[{"output_type":"stream","name":"stdout","text":["R√©pertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n","\n","Quelques fichiers √† la racine du projet:\n","['.git', '.gitignore', 'README.md', 'ai', 'docs', 'prototypes']\n","\n","Contenu du dossier ai/:\n","['AI_reduction', 'Chess.py', 'ChessInteractifv2.py', 'Chess_v2.py', 'NN', 'Null_move_AI', 'Old_AI', 'Player.py', 'Profile', 'Tests.py', '__init__.py', '__pycache__', 'alphabeta.py', 'alphabeta_engine.py', 'alphabeta_engine_v2.py', 'analyze_reduction_overhead.py', 'base_engine.py', 'check_dataset_stats.py', 'check_gpu.py', 'check_performance.py', 'chess_model_checkpoint.pt', 'debug_conversion.py', 'engine_match.py', 'evaluator.py', 'example_move_reduction.py', 'fast_evaluator.py', 'journal-experiments.md', 'optimized_chess.py', 'profile_report_1760344602.txt', 'test_depth_6_performance.py', 'test_depth_6_quick.py', 'test_depth_effectiveness.py', 'test_engines_v2.py', 'test_evaluator_performance.py', 'test_generalization.py', 'test_move_reduction.py', 'test_null_move.py', 'test_null_move_comparison.py', 'test_null_move_effectiveness.py', 'test_null_move_final.py', 'test_null_move_optimization.py', 'test_null_move_quick.py', 'test_timeout_fix.py', 'visualize_sampling.py']\n","\n","‚úÖ Import direct `Chess` OK (module trouv√© via sys.path)\n","\n","‚úì Modules import√©s avec succ√®s!\n"]}],"source":["# Importer les modules n√©cessaires depuis le projet (robuste √† l'emplacement du repo sur Drive)\n","import os\n","import sys\n","import importlib\n","\n","# Assurez-vous que PROJECT_PATH est d√©fini et ajoutez √©galement le dossier `ai` au PYTHONPATH\n","PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n","AI_SUBDIR = os.path.join(PROJECT_PATH, 'ai')\n","\n","# V√©rifier les chemins alternatifs (si l'utilisateur a copi√© le repo dans /content)\n","ALT_PATH = '/content/smart-chess'\n","\n","# Choisir un chemin existant\n","if not os.path.isdir(PROJECT_PATH) and os.path.isdir(ALT_PATH):\n","    PROJECT_PATH = ALT_PATH\n","\n","if not os.path.isdir(PROJECT_PATH):\n","    raise FileNotFoundError(f\"R√©pertoire projet introuvable: {PROJECT_PATH}. Montez Drive et v√©rifiez le chemin.\")\n","\n","# Ajouter au sys.path si n√©cessaire\n","if PROJECT_PATH not in sys.path:\n","    sys.path.insert(0, PROJECT_PATH)\n","if AI_SUBDIR not in sys.path and os.path.isdir(AI_SUBDIR):\n","    sys.path.insert(0, AI_SUBDIR)\n","\n","# Se placer dans le r√©pertoire projet\n","os.chdir(PROJECT_PATH)\n","\n","print('R√©pertoire de travail:', os.getcwd())\n","print('\\nQuelques fichiers √† la racine du projet:')\n","print(sorted(os.listdir(PROJECT_PATH))[:50])\n","print('\\nContenu du dossier ai/:')\n","print(sorted(os.listdir(AI_SUBDIR))[:100])\n","\n","# Diagnostic d'import direct pour le module Chess\n","try:\n","    import Chess\n","    print('\\n‚úÖ Import direct `Chess` OK (module trouv√© via sys.path)')\n","except Exception as e:\n","    print('\\n‚ùå Import direct `Chess` a √©chou√©:', e)\n","    print('V√©rifiez que `ai/Chess.py` existe et que le dossier ai/ est dans sys.path')\n","\n","# Maintenant importer le module d'entra√Ænement (trainer)\n","try:\n","    import ai.NN.train_torch as trainer\n","    import ai.NN.torch_nn_evaluator as torch_eval\n","    from ai.Chess_v2 import Chess\n","    print('\\n‚úì Modules import√©s avec succ√®s!')\n","except Exception as e:\n","    print('\\n‚ùå Erreur d\\'import lors de l\\'import du trainer:', e)\n","    raise\n"]},{"cell_type":"markdown","id":"0e668793","metadata":{"id":"0e668793"},"source":["## 7. Configuration de l'entra√Ænement"]},{"cell_type":"code","execution_count":null,"id":"c9f87f8d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1761572886153,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"c9f87f8d","outputId":"d1f32ea2-f703-461e-c816-0736662b9adf"},"outputs":[{"name":"stdout","output_type":"stream","text":["============================================================\n","CONFIGURATION DE L'ENTRA√éNEMENT\n","============================================================\n","num_games           : 10000\n","batch_size          : 256\n","epochs              : 50\n","learning_rate       : 0.001\n","device              : cuda\n","num_workers         : 2\n","checkpoint_path     : ai/chess_model_checkpoint.pt\n","save_interval       : 5\n","============================================================\n"]}],"source":["# Param√®tres d'entra√Ænement\n","CONFIG = {\n","    # G√©n√©ration de donn√©es\n","    'num_games': 10000,          # Nombre de parties √† g√©n√©rer pour l'entra√Ænement\n","\n","    # Hyperparam√®tres\n","    'batch_size': 256,           # Taille du batch (augmenter si GPU puissant)\n","    'epochs': 50,                # Nombre d'√©poques d'entra√Ænement\n","    'learning_rate': 0.001,      # Taux d'apprentissage\n","\n","    # Configuration syst√®me\n","    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n","    'num_workers': 2,            # Workers pour le DataLoader\n","\n","    # Sauvegarde\n","    'checkpoint_path': 'ai/chess_model_checkpoint.pt',\n","    'save_interval': 5,          # Sauvegarder tous les N √©poques\n","}\n","\n","print(\"=\" * 60)\n","print(\"CONFIGURATION DE L'ENTRA√éNEMENT\")\n","print(\"=\" * 60)\n","for key, value in CONFIG.items():\n","    print(f\"{key:20s}: {value}\")\n","print(\"=\" * 60)\n","\n","if CONFIG['device'] == 'cpu':\n","    print(\"\\n‚ö†Ô∏è ATTENTION: Entra√Ænement sur CPU d√©tect√©!\")\n","    print(\"   R√©duisez num_games et epochs pour un test rapide.\")"]},{"cell_type":"markdown","id":"f72ad90f","metadata":{"id":"f72ad90f"},"source":["## 8. G√©n√©ration des donn√©es d'entra√Ænement\n","\n","Cette √©tape g√©n√®re des parties d'√©checs al√©atoires et calcule les √©valuations de position.\n","**Attention:** Cela peut prendre 15-30 minutes selon le nombre de parties."]},{"cell_type":"code","execution_count":22,"id":"4504f1e6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23864,"status":"ok","timestamp":1761574079676,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"4504f1e6","outputId":"760ae98f-f7dc-4b4f-c367-7ffbac9162e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chargement du dataset (depuis chessData)...\n","üìÇ Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n","üßπ Nettoyage : 190154 lignes corrompues supprim√©es.\n","‚úÖ 12,767,881 positions valides charg√©es.\n","\n","============================================================\n","DONN√âES CHARG√âES\n","============================================================\n","Nombre total de positions: 12,767,881\n","Temps √©coul√©: 23.8s (0.4 min)\n","============================================================\n","\n","Statistiques sur les √©valuations:\n","  Min: -15.3120\n","  Max: 15.3190\n","  Moyenne: 0.0455\n","  √âcart-type: 0.8139\n"]}],"source":["from tqdm import tqdm\n","import time\n","\n","print(\"Chargement du dataset (depuis chessData)...\")\n","\n","# Pr√©f√©rer la variable DATASET_CSV (d√©finie apr√®s le montage Drive) sinon utiliser la valeur par d√©faut du module trainer\n","dataset_path = globals().get('DATASET_CSV') # Use the DATASET_CSV variable directly\n","\n","if dataset_path is None:\n","    raise FileNotFoundError('Aucun chemin de dataset d√©fini. Montez Drive et placez le fichier CSV dans MyDrive/smart_chess_drive/chessData')\n","\n","start_time = time.time()\n","\n","# Utiliser la fonction de chargement du script d'entra√Ænement pour assurer le m√™me pr√©traitement\n","fens, evaluations = trainer.load_data(dataset_path) # Pass the dataset_path explicitly\n","\n","# Variables attendues plus bas dans le notebook\n","X_train = fens\n","y_train = evaluations\n","\n","elapsed_time = time.time() - start_time\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"DONN√âES CHARG√âES\")\n","print(\"=\" * 60)\n","print(f\"Nombre total de positions: {len(X_train):,}\")\n","print(f\"Temps √©coul√©: {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n","print(\"=\" * 60)\n","\n","# Statistiques sur les √©valuations\n","print(f\"\\nStatistiques sur les √©valuations:\")\n","print(f\"  Min: {y_train.min():.4f}\")\n","print(f\"  Max: {y_train.max():.4f}\")\n","print(f\"  Moyenne: {y_train.mean():.4f}\")\n","print(f\"  √âcart-type: {y_train.std():.4f}\")"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cc365442","executionInfo":{"status":"ok","timestamp":1761574090445,"user_tz":-60,"elapsed":11,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"e1333497-be02-43ac-fad9-35e4ad03b34e"},"source":["import inspect\n","import ai.NN.train_torch as trainer\n","\n","try:\n","    # Get the source code of the load_data function\n","    source_code = inspect.getsource(trainer.load_data)\n","    print(\"Source code of trainer.load_data:\")\n","    print(\"=\" * 60)\n","    print(source_code)\n","    print(\"=\" * 60)\n","except TypeError:\n","    print(\"Could not get source code for trainer.load_data. It might not be a function defined in the file.\")\n","except FileNotFoundError:\n","    print(\"Could not find the train_torch.py file.\")\n","except Exception as e:\n","    print(f\"An error occurred while trying to get source code: {e}\")"],"id":"cc365442","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Source code of trainer.load_data:\n","============================================================\n","def load_data(filepath: str):\n","    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n","    print(f\"üìÇ Chargement du dataset depuis {filepath}...\")\n","    \n","    df = pd.read_csv(\n","        filepath, \n","        names=['FEN', 'Evaluation'], \n","        skiprows=1,\n","        comment='#'\n","    )\n","    \n","    initial_count = len(df)\n","    df.dropna(inplace=True)\n","    cleaned_count = len(df)\n","    \n","    if initial_count > cleaned_count:\n","        print(f\"üßπ Nettoyage : {initial_count - cleaned_count} lignes corrompues supprim√©es.\")\n","    \n","    fens = df['FEN'].values\n","    EVAL_SCALE_FACTOR = 1000.0\n","    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n","    \n","    print(f\"‚úÖ {len(fens):,} positions valides charg√©es.\")\n","    return fens, evaluations\n","\n","============================================================\n"]}]},{"cell_type":"code","execution_count":24,"id":"e0b3c66b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1761574094547,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"},"user_tz":-60},"id":"e0b3c66b","outputId":"3f6d4524-6aa9-413c-dc57-74c01c0841d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Could not find the function definition 'def load_data():' in /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py. Please inspect the file manually.\n"]}],"source":["import os\n","\n","file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n","\n","# Read the content of the file\n","with open(file_path, 'r') as f:\n","    content = f.read()\n","\n","# Assuming the load_data function signature is currently load_data():\n","# We need to find the function definition and modify it to accept dataset_path\n","# This is a simple string replacement and might need adjustment based on the actual code\n","old_def = 'def load_data():'\n","new_def = 'def load_data(dataset_path):'\n","old_data_loading_line = \"df = pd.read_csv('C:\\\\\\\\Users\\\\\\\\gauti\\\\\\\\OneDrive\\\\\\\\Documents\\\\\\\\UE commande\\\\\\\\chessData.csv')\" # This is a guess, may need adjustment\n","new_data_loading_line = \"df = pd.read_csv(dataset_path)\"\n","\n","\n","if old_def in content and old_data_loading_line in content:\n","    content = content.replace(old_def, new_def)\n","    content = content.replace(old_data_loading_line, new_data_loading_line)\n","    # Write the modified content back to the file\n","    with open(file_path, 'w') as f:\n","        f.write(content)\n","    print(f\"Successfully modified {file_path} to accept and use dataset_path in load_data function.\")\n","elif old_def in content:\n","     print(f\"Found function definition '{old_def}', but could not find the specific data loading line '{old_data_loading_line}' to replace.\")\n","     print(\"Please inspect the `load_data` function in `ai/NN/train_torch.py` and manually update the file path to use the `dataset_path` argument.\")\n","else:\n","    print(f\"Could not find the function definition '{old_def}' in {file_path}. Please inspect the file manually.\")"]},{"cell_type":"markdown","id":"fdea4dd7","metadata":{"id":"fdea4dd7"},"source":["## 9. Cr√©ation du dataset et du dataloader"]},{"cell_type":"code","execution_count":25,"id":"d0c45e62","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0c45e62","executionInfo":{"status":"ok","timestamp":1761574097494,"user_tz":-60,"elapsed":4,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"5b552671-cca9-4397-cd97-c614f3d00d50"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","DATALOADER CONFIGUR√â\n","============================================================\n","Taille du dataset: 12,767,881 √©chantillons\n","Nombre de batches: 49,875\n","Taille du batch: 256\n","Derni√®re batch: 137 √©chantillons\n","============================================================\n"]}],"source":["from torch.utils.data import DataLoader\n","from ai.NN.train_torch import ChessDataset # Import ChessDataset\n","\n","# Cr√©er le dataset\n","dataset = ChessDataset(X_train, y_train)\n","\n","# Cr√©er le dataloader\n","train_loader = DataLoader(\n","    dataset,\n","    batch_size=CONFIG['batch_size'],\n","    shuffle=True,\n","    num_workers=CONFIG['num_workers'],\n","    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",")\n","\n","print(\"=\" * 60)\n","print(\"DATALOADER CONFIGUR√â\")\n","print(\"=\" * 60)\n","print(f\"Taille du dataset: {len(dataset):,} √©chantillons\")\n","print(f\"Nombre de batches: {len(train_loader):,}\")\n","print(f\"Taille du batch: {CONFIG['batch_size']}\")\n","print(f\"Derni√®re batch: {len(dataset) % CONFIG['batch_size']} √©chantillons\")\n","print(\"=\" * 60)"]},{"cell_type":"markdown","id":"f05dda22","metadata":{"id":"f05dda22"},"source":["## 10. Cr√©ation du mod√®le"]},{"cell_type":"code","execution_count":30,"id":"056d2b3a","metadata":{"id":"056d2b3a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761574170502,"user_tz":-60,"elapsed":250,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"0aaaf6ff-fb3d-4b43-fcad-32111e39dc41"},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","ARCHITECTURE DU MOD√àLE\n","============================================================\n","TorchNNEvaluator(\n","  (l1): Linear(in_features=768, out_features=256, bias=True)\n","  (l2): Linear(in_features=256, out_features=256, bias=True)\n","  (l3): Linear(in_features=256, out_features=1, bias=True)\n","  (dropout1): Dropout(p=0.3, inplace=False)\n","  (dropout2): Dropout(p=0.3, inplace=False)\n","  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",")\n","============================================================\n","\n","Nombre total de param√®tres: 262,913\n","Param√®tres entra√Ænables: 262,913\n","Device: cuda\n","Taille estim√©e du mod√®le: 1.00 MB\n"]}],"source":["# Cr√©er le mod√®le et le d√©placer sur le device appropri√©\n","from ai.NN.torch_nn_evaluator import TorchNNEvaluator # Import TorchNNEvaluator from torch_nn_evaluator\n","\n","model = TorchNNEvaluator().to(CONFIG['device'])\n","\n","# Afficher l'architecture\n","print(\"=\" * 60)\n","print(\"ARCHITECTURE DU MOD√àLE\")\n","print(\"=\" * 60)\n","print(model)\n","print(\"=\" * 60)\n","\n","# Compter les param√®tres\n","total_params = sum(p.numel() for p in model.parameters())\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f\"\\nNombre total de param√®tres: {total_params:,}\")\n","print(f\"Param√®tres entra√Ænables: {trainable_params:,}\")\n","print(f\"Device: {CONFIG['device']}\")\n","\n","# Estimer la taille m√©moire du mod√®le\n","param_size_mb = total_params * 4 / (1024 ** 2)  # 4 bytes par float32\n","print(f\"Taille estim√©e du mod√®le: {param_size_mb:.2f} MB\")"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"22bc571c","executionInfo":{"status":"ok","timestamp":1761574157413,"user_tz":-60,"elapsed":4,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"0cd6d96b-ef10-4f2f-f6eb-0bf9d5ba6716"},"source":["import os\n","\n","file_path = os.path.join(PROJECT_PATH, 'ai/NN/torch_nn_evaluator.py')\n","\n","try:\n","    with open(file_path, 'r') as f:\n","        content = f.read()\n","    print(f\"Content of {file_path}:\")\n","    print(\"=\" * 60)\n","    print(content)\n","    print(\"=\" * 60)\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {file_path}\")\n","except Exception as e:\n","    print(f\"An error occurred while reading the file: {e}\")"],"id":"22bc571c","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Content of /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/torch_nn_evaluator.py:\n","============================================================\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from Chess import Chess\n","\n","\n","class TorchNNEvaluator(nn.Module):\n","    \"\"\"PyTorch implementation √©quivalente du `NeuralNetworkEvaluator` en NumPy.\n","\n","    - architecture: Linear(input -> hidden) -> LeakyReLU -> Dropout -> Linear(hidden -> hidden) -> LeakyReLU -> Dropout -> Linear(hidden -> out)\n","    - fournit des helpers pour charger/sauver au format .npz (compatibilit√© avec l'ancien code NumPy)\n","    - fournit des helpers pour checkpoint/restore PyTorch (optimizer.state_dict)\n","    - Support GPU automatique\n","    \"\"\"\n","\n","    def __init__(self, input_size=768, hidden_size=256, output_size=1, dropout=0.3, leaky_alpha=0.01):\n","        super().__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size)\n","        self.l2 = nn.Linear(hidden_size, hidden_size)\n","        self.l3 = nn.Linear(hidden_size, output_size)\n","        self.dropout1 = nn.Dropout(p=dropout)\n","        self.dropout2 = nn.Dropout(p=dropout)\n","        self.leaky_relu = nn.LeakyReLU(negative_slope=leaky_alpha)\n","\n","        self.piece_to_index = {\n","            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n","            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n","        }\n","        self.input_size = input_size\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = self.leaky_relu(self.l1(x))\n","        x = self.dropout1(x)\n","        x = self.leaky_relu(self.l2(x))\n","        x = self.dropout2(x)\n","        return self.l3(x)\n","\n","    def encode_board(self, chess_instance: Chess, device='cpu') -> torch.Tensor:\n","        vec = np.zeros(self.input_size, dtype=np.float32)\n","        for piece_char, bitboard in chess_instance.bitboards.items():\n","            if bitboard == 0:\n","                continue\n","            piece_index = self.piece_to_index[piece_char]\n","            temp_bb = int(bitboard)\n","            while temp_bb:\n","                square = (temp_bb & -temp_bb).bit_length() - 1\n","                vector_position = piece_index * 64 + square\n","                vec[vector_position] = 1.0\n","                temp_bb &= temp_bb - 1\n","        t = torch.from_numpy(vec).to(torch.float32).to(device)\n","        return t.unsqueeze(0)  # shape (1, input_size)\n","\n","    def evaluate_position(self, chess_instance: Chess, device='cpu') -> float:\n","        x = self.encode_board(chess_instance, device=device)\n","        self.to(device)\n","        self.eval()\n","        with torch.no_grad():\n","            out = self.forward(x)\n","        normalized_score = out[0, 0].item()\n","        EVAL_SCALE_FACTOR = 1000.0\n","        return normalized_score * EVAL_SCALE_FACTOR\n","\n","\n","def save_weights_npz(model: TorchNNEvaluator, filename: str, adam_moments: dict = None):\n","    \"\"\"Sauvegarde les poids du mod√®le dans un .npz compatible avec l'ancien format NumPy.\n","\n","    Le format correspond aux cl√©s attendues par `nn_evaluator.load_evaluator_from_file` :\n","    - w1: shape (input, hidden)\n","    - b1: shape (1, hidden)\n","    - w2, b2, w3, b3\n","    On convertit les poids PyTorch (weight shape: out, in) en (in, out).\n","    \"\"\"\n","    sd = model.state_dict()\n","    save_dict = {\n","        'w1': sd['l1.weight'].cpu().numpy().T,\n","        'b1': sd['l1.bias'].cpu().numpy().reshape(1, -1),\n","        'w2': sd['l2.weight'].cpu().numpy().T,\n","        'b2': sd['l2.bias'].cpu().numpy().reshape(1, -1),\n","        'w3': sd['l3.weight'].cpu().numpy().T,\n","        'b3': sd['l3.bias'].cpu().numpy().reshape(1, -1),\n","    }\n","    if adam_moments is not None:\n","        # ensure numpy arrays\n","        for k, v in dict(adam_moments).items():\n","            save_dict[k] = np.array(v)\n","\n","    np.savez(filename, **save_dict)\n","    if adam_moments is not None:\n","        print(f\"Poids et moments Adam sauvegard√©s (npz) dans {filename}\")\n","    else:\n","        print(f\"Poids sauvegard√©s (npz) dans {filename}\")\n","\n","\n","def load_from_npz(filename: str, device='cpu'):\n","    \"\"\"Charge un .npz produit par la version NumPy et renvoie (model, adam_moments)\n","\n","    - adam_moments (si pr√©sent) est renvoy√© sous forme de dict de tensors (torch.float32)\n","    - si les moments Adam ne sont pas tous pr√©sents, on renvoie None pour adam_moments\n","    \"\"\"\n","    data = np.load(filename)\n","    # infer sizes\n","    w1 = data['w1']\n","    b1 = data['b1']\n","    w2 = data['w2']\n","    b2 = data['b2']\n","    w3 = data['w3']\n","    b3 = data['b3']\n","    input_size = int(w1.shape[0])\n","    hidden_size = int(w1.shape[1])\n","    output_size = int(w3.shape[1]) if w3.ndim == 2 else 1\n","\n","    model = TorchNNEvaluator(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n","    # copy weights (transpose to torch linear layout)\n","    model.l1.weight.data.copy_(torch.from_numpy(w1.T).to(torch.float32))\n","    model.l1.bias.data.copy_(torch.from_numpy(b1.reshape(-1)).to(torch.float32))\n","    model.l2.weight.data.copy_(torch.from_numpy(w2.T).to(torch.float32))\n","    model.l2.bias.data.copy_(torch.from_numpy(b2.reshape(-1)).to(torch.float32))\n","    model.l3.weight.data.copy_(torch.from_numpy(w3.T).to(torch.float32))\n","    model.l3.bias.data.copy_(torch.from_numpy(b3.reshape(-1)).to(torch.float32))\n","\n","    # collect adam moments if all present\n","    adam_moments = None\n","    adam_keys = ['m_w1', 'v_w1', 'm_b1', 'v_b1', 'm_w2', 'v_w2',\n","                 'm_b2', 'v_b2', 'm_w3', 'v_w3', 'm_b3', 'v_b3', 'adam_step']\n","    if all(key in data for key in adam_keys):\n","        adam_moments = {}\n","        for k in adam_keys:\n","            val = data[k]\n","            # convert scalar 0-d to Python int for adam_step\n","            if k == 'adam_step':\n","                adam_moments[k] = int(val)\n","            else:\n","                adam_moments[k] = torch.from_numpy(np.array(val)).to(torch.float32)\n","\n","    model.to(device)\n","    return model, adam_moments\n","\n","\n","def torch_save_checkpoint(path: str, model: TorchNNEvaluator, optimizer=None, step: int = None):\n","    ckpt = {'model': model.state_dict()}\n","    if optimizer is not None:\n","        ckpt['optim'] = optimizer.state_dict()\n","    if step is not None:\n","        ckpt['step'] = int(step)\n","    torch.save(ckpt, path)\n","    print(f\"Checkpoint PyTorch sauvegard√© dans {path}\")\n","\n","\n","def torch_load_checkpoint(path: str, model: TorchNNEvaluator = None, optimizer=None, device='cpu'):\n","    ckpt = torch.load(path, map_location=device)\n","    if model is not None:\n","        model.load_state_dict(ckpt['model'])\n","        model.to(device)\n","    optim_state = ckpt.get('optim')\n","    if optimizer is not None and optim_state is not None:\n","        optimizer.load_state_dict(optim_state)\n","    step = ckpt.get('step')\n","    return model, optim_state, step\n","\n","\n","if __name__ == '__main__':\n","    # Exemple d'utilisation similaire au fichier NumPy original\n","    WEIGHTS_FILE = 'chess_nn_weights_from_torch.npz'\n","    game = Chess()\n","\n","    print('--- Cr√©ation d un r√©seau PyTorch non entra√Æn√© ---')\n","    model = TorchNNEvaluator(input_size=768, hidden_size=256, output_size=1)\n","    # √©valuation cpu\n","    score1 = model.evaluate_position(game)\n","    print(f'Score du r√©seau PyTorch vierge : {score1:.2f}')\n","\n","    # sauvegarde en .npz (pour compatibilit√©)\n","    save_weights_npz(model, WEIGHTS_FILE)\n","\n","    # rechargement depuis .npz\n","    print(f\"\\n--- Chargement du r√©seau depuis le fichier '{WEIGHTS_FILE}' ---\")\n","    loaded_model, adam_moms = load_from_npz(WEIGHTS_FILE)\n","    score2 = loaded_model.evaluate_position(game)\n","    print(f\"Score du r√©seau charg√© : {score2:.2f}\")\n","    if adam_moms is not None:\n","        print(f\"Moments Adam charg√©s (step={adam_moms['adam_step']})\")\n","    # la valeur peut l√©g√®rement diff√©rer en float32 mais doit √™tre proche\n","    try:\n","        assert abs(score1 - score2) < 1e-3\n","    except AssertionError:\n","        print('Attention: score initial et score charg√© diff√®rent; v√©rifie dtypes/precision')\n","\n","============================================================\n"]}]},{"cell_type":"markdown","id":"aa1ba4a7","metadata":{"id":"aa1ba4a7"},"source":["## 11. Entra√Ænement du mod√®le\n","\n","Cette √©tape lance l'entra√Ænement complet. Les checkpoints sont sauvegard√©s automatiquement sur votre Drive."]},{"cell_type":"code","execution_count":35,"id":"54ee49f6","metadata":{"id":"54ee49f6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761574281406,"user_tz":-60,"elapsed":5,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"fc94458f-3b70-45ec-c903-a7d1ca17e9a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["The training process is handled by calling trainer.main() in cell 9887d4b8.\n","Please run cell 9887d4b8 to start the training.\n"]}],"source":["# This cell is no longer needed as trainer.main() handles the training loop.\n","# The training will be started by running cell 9887d4b8.\n","# You can keep this cell as a placeholder or delete it if you prefer.\n","# The training history will be available after trainer.main() completes if the script returns it or saves it.\n","\n","print(\"The training process is handled by calling trainer.main() in cell 9887d4b8.\")\n","print(\"Please run cell 9887d4b8 to start the training.\")\n","\n","# Keep the history variable assignment as a placeholder if the script returns it\n","# history = None # Or whatever trainer.main() might return"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9399818c","executionInfo":{"status":"ok","timestamp":1761574296277,"user_tz":-60,"elapsed":95,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"db08d410-4a1d-4512-accb-b3e7988f48bb"},"source":["import os\n","\n","file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n","\n","try:\n","    with open(file_path, 'r') as f:\n","        content = f.read()\n","\n","    # Remove the verbose=True argument from ReduceLROnPlateau\n","    old_scheduler_init = \"patience=LR_PATIENCE, verbose=True\"\n","    new_scheduler_init = \"patience=LR_PATIENCE\" # Remove verbose argument\n","\n","    if old_scheduler_init in content:\n","        content = content.replace(old_scheduler_init, new_scheduler_init)\n","        # Write the modified content back to the file\n","        with open(file_path, 'w') as f:\n","            f.write(content)\n","        print(f\"Successfully removed 'verbose=True' from ReduceLROnPlateau in {file_path}.\")\n","    else:\n","        print(f\"'verbose=True' not found in ReduceLROnPlateau initialization in {file_path}. No changes made.\")\n","\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {file_path}\")\n","except Exception as e:\n","    print(f\"An error occurred while trying to modify the file: {e}\")"],"id":"9399818c","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully removed 'verbose=True' from ReduceLROnPlateau in /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"a04ce84b","executionInfo":{"status":"ok","timestamp":1761574238241,"user_tz":-60,"elapsed":14,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"b73f017a-7e01-4f5b-db53-9b3aa3eb0ffe"},"source":["# @title\n","import os\n","\n","file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n","\n","try:\n","    with open(file_path, 'r') as f:\n","        content = f.read()\n","    print(f\"Content of {file_path}:\")\n","    print(\"=\" * 60)\n","    print(content)\n","    print(\"=\" * 60)\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {file_path}\")\n","except Exception as e:\n","    print(f\"An error occurred while reading the file: {e}\")"],"id":"a04ce84b","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Content of /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py:\n","============================================================\n","\"\"\"\n","Script d'entra√Ænement PyTorch optimis√© pour GPU\n","Compatible avec Google Colab et machines locales avec GPU\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","import os\n","\n","from Chess import Chess\n","from ai.NN.torch_nn_evaluator import TorchNNEvaluator, save_weights_npz, load_from_npz, torch_save_checkpoint, torch_load_checkpoint\n","\n","# --- CONFIGURATION DE L'ENTRA√éNEMENT ---\n","DATASET_PATH = \"C:\\\\Users\\\\gauti\\\\OneDrive\\\\Documents\\\\UE commande\\\\chessData.csv\"  # Adapt√© pour Colab (fichier √† la racine)\n","WEIGHTS_FILE = \"chess_nn_weights.npz\"\n","CHECKPOINT_FILE = \"chess_model_checkpoint.pt\"\n","\n","# Architecture\n","HIDDEN_SIZE = 256\n","DROPOUT = 0.3\n","LEAKY_ALPHA = 0.01\n","\n","# Hyperparam√®tres\n","LEARNING_RATE = 0.001\n","WEIGHT_DECAY = 1e-4  # L2 regularization (AdamW)\n","EPOCHS = 20\n","BATCH_SIZE = 128  # Plus grand pour GPU\n","MAX_SAMPLES = 500_000  # Plus de donn√©es avec GPU !\n","EVAL_MAX_SAMPLES = 5000\n","\n","# Options\n","USE_SAMPLING = True\n","RESET_WEIGHTS = False\n","DEBUG_STATS = True\n","\n","# LR Scheduler\n","USE_LR_SCHEDULER = True\n","LR_PATIENCE = 2\n","LR_FACTOR = 0.5\n","\n","# LR Warmup\n","USE_LR_WARMUP = True\n","WARMUP_EPOCHS = 3\n","WARMUP_START_LR = 0.0001\n","\n","# Device (auto-d√©tection GPU)\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"üñ•Ô∏è  Device: {DEVICE}\")\n","if torch.cuda.is_available():\n","    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","\n","\n","class ChessDataset(Dataset):\n","    \"\"\"Dataset PyTorch pour les positions d'√©checs\"\"\"\n","    def __init__(self, fens, evaluations):\n","        self.fens = fens\n","        self.evaluations = evaluations\n","        self.chess = Chess()\n","        \n","        # Pr√©calculer l'encodage pour acc√©l√©rer (optionnel, consomme plus de RAM)\n","        # self.encoded = [self._encode_fen(fen) for fen in tqdm(fens, desc=\"Encoding positions\")]\n","        \n","    def __len__(self):\n","        return len(self.fens)\n","    \n","    def __getitem__(self, idx):\n","        fen = self.fens[idx]\n","        target = self.evaluations[idx]\n","        \n","        # Encoder la position\n","        self.chess.load_fen(fen)\n","        encoded = self._encode_board(self.chess)\n","        \n","        return torch.from_numpy(encoded).float(), torch.tensor([target], dtype=torch.float32)\n","    \n","    def _encode_board(self, chess_instance):\n","        \"\"\"Encode le plateau en vecteur 768D (identique √† nn_evaluator.py)\"\"\"\n","        piece_to_index = {\n","            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n","            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n","        }\n","        vec = np.zeros(768, dtype=np.float32)\n","        for piece_char, bitboard in chess_instance.bitboards.items():\n","            if bitboard == 0:\n","                continue\n","            piece_index = piece_to_index[piece_char]\n","            temp_bb = int(bitboard)\n","            while temp_bb:\n","                square = (temp_bb & -temp_bb).bit_length() - 1\n","                vector_position = piece_index * 64 + square\n","                vec[vector_position] = 1.0\n","                temp_bb &= temp_bb - 1\n","        return vec\n","\n","\n","def load_data(filepath: str):\n","    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n","    print(f\"üìÇ Chargement du dataset depuis {filepath}...\")\n","    \n","    df = pd.read_csv(\n","        filepath, \n","        names=['FEN', 'Evaluation'], \n","        skiprows=1,\n","        comment='#'\n","    )\n","    \n","    initial_count = len(df)\n","    df.dropna(inplace=True)\n","    cleaned_count = len(df)\n","    \n","    if initial_count > cleaned_count:\n","        print(f\"üßπ Nettoyage : {initial_count - cleaned_count} lignes corrompues supprim√©es.\")\n","    \n","    fens = df['FEN'].values\n","    EVAL_SCALE_FACTOR = 1000.0\n","    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n","    \n","    print(f\"‚úÖ {len(fens):,} positions valides charg√©es.\")\n","    return fens, evaluations\n","\n","\n","def evaluate_model(model, dataloader, device):\n","    \"\"\"√âvalue le mod√®le sur un dataset\"\"\"\n","    model.eval()\n","    predictions = []\n","    targets = []\n","    \n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            predictions.extend(outputs.cpu().numpy().flatten())\n","            targets.extend(labels.numpy().flatten())\n","    \n","    predictions = np.array(predictions)\n","    targets = np.array(targets)\n","    \n","    rmse = float(np.sqrt(np.mean((predictions - targets) ** 2)))\n","    mae = float(np.mean(np.abs(predictions - targets)))\n","    corr = float(np.corrcoef(predictions, targets)[0, 1]) if len(predictions) > 1 else 0.0\n","    \n","    return rmse, mae, corr, predictions, targets\n","\n","\n","def main():\n","    # 1. Charger les donn√©es\n","    all_fens, all_evaluations = load_data(DATASET_PATH)\n","    \n","    print(f\"\\nüìä Dataset complet: {len(all_fens):,} positions\")\n","    \n","    eval_mean = float(np.mean(all_evaluations))\n","    \n","    # 2. Initialiser le mod√®le\n","    if RESET_WEIGHTS and os.path.exists(WEIGHTS_FILE):\n","        print(f\"üóëÔ∏è  Suppression des anciens poids: {WEIGHTS_FILE}\")\n","        os.remove(WEIGHTS_FILE)\n","    \n","    if os.path.exists(CHECKPOINT_FILE):\n","        print(f\"üì• Chargement du checkpoint PyTorch: {CHECKPOINT_FILE}\")\n","        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n","        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        model, _, start_step = torch_load_checkpoint(CHECKPOINT_FILE, model, optimizer, device=DEVICE)\n","        print(f\"‚úÖ Checkpoint charg√© (step {start_step})\")\n","    elif os.path.exists(WEIGHTS_FILE):\n","        print(f\"üì• Chargement des poids NumPy: {WEIGHTS_FILE}\")\n","        model, adam_moments = load_from_npz(WEIGHTS_FILE, device=DEVICE)\n","        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        # TODO: Restaurer les moments Adam si pr√©sents\n","        print(f\"‚úÖ Poids charg√©s depuis NumPy\")\n","    else:\n","        print(\"üÜï Cr√©ation d'un nouveau r√©seau...\")\n","        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n","        # Initialisation He (PyTorch le fait d√©j√† par d√©faut pour Linear + ReLU)\n","        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        \n","        # Warm-start du biais de sortie\n","        with torch.no_grad():\n","            model.l3.bias[0] = eval_mean\n","    \n","    model.to(DEVICE)\n","    \n","    # 3. Configuration de l'entra√Ænement\n","    criterion = nn.MSELoss()\n","    \n","    # LR Scheduler\n","    if USE_LR_SCHEDULER:\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer, mode='min', factor=LR_FACTOR, \n","            patience=LR_PATIENCE, verbose=True\n","        )\n","    \n","    print(f\"\\n{'='*70}\")\n","    print(f\"Configuration:\")\n","    print(f\"  Dataset complet: {len(all_fens):,} positions\")\n","    print(f\"  √âchantillon/epoch: {MAX_SAMPLES if USE_SAMPLING else len(all_fens):,} positions\")\n","    print(f\"  Architecture: 768 ‚Üí {HIDDEN_SIZE} ‚Üí {HIDDEN_SIZE} ‚Üí 1\")\n","    print(f\"  Dropout: {DROPOUT}\")\n","    print(f\"  LeakyReLU alpha: {LEAKY_ALPHA}\")\n","    print(f\"  Learning rate: {LEARNING_RATE} (AdamW, weight decay: {WEIGHT_DECAY})\")\n","    print(f\"  LR Warmup: {USE_LR_WARMUP} ({WARMUP_START_LR if USE_LR_WARMUP else 'N/A'} ‚Üí {LEARNING_RATE})\")\n","    print(f\"  LR Scheduler: {USE_LR_SCHEDULER} (patience: {LR_PATIENCE if USE_LR_SCHEDULER else 'N/A'})\")\n","    print(f\"  Batch size: {BATCH_SIZE}\")\n","    print(f\"  Epochs: {EPOCHS}\")\n","    print(f\"  Device: {DEVICE}\")\n","    print(f\"{'='*70}\\n\")\n","    \n","    # 4. Boucle d'entra√Ænement\n","    best_rmse = float('inf')\n","    \n","    for epoch in range(EPOCHS):\n","        # √âchantillonnage √† chaque epoch\n","        if USE_SAMPLING and len(all_fens) > MAX_SAMPLES:\n","            print(f\"\\n[Epoch {epoch+1}] üé≤ √âchantillonnage: {MAX_SAMPLES:,} positions sur {len(all_fens):,}\")\n","            idx = np.random.choice(len(all_fens), size=MAX_SAMPLES, replace=False)\n","            fens = all_fens[idx]\n","            evaluations = all_evaluations[idx]\n","        else:\n","            fens = all_fens\n","            evaluations = all_evaluations\n","        \n","        # LR Warmup\n","        if USE_LR_WARMUP and epoch < WARMUP_EPOCHS:\n","            warmup_progress = (epoch + 1) / WARMUP_EPOCHS\n","            lr = WARMUP_START_LR + (LEARNING_RATE - WARMUP_START_LR) * warmup_progress\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr\n","            print(f\"üî• Warmup epoch {epoch+1}/{WARMUP_EPOCHS}: LR = {lr:.6f}\")\n","        \n","        # Cr√©er le dataset et dataloader\n","        train_dataset = ChessDataset(fens, evaluations)\n","        train_loader = DataLoader(\n","            train_dataset, \n","            batch_size=BATCH_SIZE, \n","            shuffle=True,\n","            num_workers=0,  # Augmenter si CPU multi-core (ex: 4)\n","            pin_memory=True if torch.cuda.is_available() else False\n","        )\n","        \n","        # Training\n","        model.train()\n","        total_loss = 0\n","        num_batches = 0\n","        \n","        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\")\n","        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n","            inputs = inputs.to(DEVICE)\n","            targets = targets.to(DEVICE)\n","            \n","            # Forward\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            \n","            # Backward\n","            loss.backward()\n","            \n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n","            \n","            # Update\n","            optimizer.step()\n","            \n","            total_loss += loss.item()\n","            num_batches += 1\n","            \n","            # Debug stats (premier batch)\n","            if DEBUG_STATS and epoch == 0 and batch_idx == 0:\n","                with torch.no_grad():\n","                    preds = outputs.cpu().numpy().flatten()\n","                    targs = targets.cpu().numpy().flatten()\n","                    batch_rmse = np.sqrt(np.mean((preds - targs) ** 2))\n","                    corr = np.corrcoef(preds, targs)[0, 1] if len(preds) > 1 else 0.0\n","                    print(f\"\\n[DEBUG batch 0] targets mean={targs.mean():.4f} std={targs.std():.4f}; \"\n","                          f\"preds mean={preds.mean():.4f} std={preds.std():.4f}; \"\n","                          f\"RMSE={batch_rmse:.4f}; corr={corr:.4f}\")\n","            \n","            # Update progress bar\n","            avg_loss = total_loss / num_batches\n","            progress_bar.set_postfix({\"loss\": f\"{np.sqrt(avg_loss):.4f}\"})\n","        \n","        # √âvaluation fin d'√©poque\n","        print(f\"\\nüîç √âvaluation epoch {epoch+1}...\")\n","        \n","        # √âchantillon d'√©valuation\n","        if EVAL_MAX_SAMPLES and len(all_fens) > EVAL_MAX_SAMPLES:\n","            eval_idx = np.random.choice(len(all_fens), size=EVAL_MAX_SAMPLES, replace=False)\n","            eval_fens = all_fens[eval_idx]\n","            eval_targets = all_evaluations[eval_idx]\n","        else:\n","            eval_fens = all_fens\n","            eval_targets = all_evaluations\n","        \n","        eval_dataset = ChessDataset(eval_fens, eval_targets)\n","        eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE*2, shuffle=False)\n","        \n","        rmse, mae, corr, preds, targets = evaluate_model(model, eval_loader, DEVICE)\n","        \n","        baseline_rmse = targets.std()\n","        improvement = 100 * (1 - rmse / baseline_rmse) if baseline_rmse > 0 else 0\n","        \n","        # Affichage\n","        print(f\"\\n{'='*70}\")\n","        print(f\"EPOCH {epoch+1}/{EPOCHS} - √âvaluation sur {len(eval_fens):,} positions\")\n","        print(f\"{'='*70}\")\n","        print(f\"  RMSE:        {rmse:.4f}  (baseline: {baseline_rmse:.4f})\")\n","        print(f\"  MAE:         {mae:.4f}\")\n","        print(f\"  Am√©lioration: {improvement:+.1f}% vs baseline\")\n","        print(f\"  Corr√©lation: {corr:.4f}\")\n","        print(f\"  Std preds:   {preds.std():.4f}  (cible: {targets.std():.4f})\")\n","        print(f\"  Mean preds:  {preds.mean():.4f}  (cible: {targets.mean():.4f})\")\n","        \n","        if improvement > 50:\n","            print(f\"  ‚úì‚úì Performance excellente!\")\n","        elif improvement > 30:\n","            print(f\"  ‚úì  Bon apprentissage!\")\n","        elif improvement > 10:\n","            print(f\"  ‚Üí  Apprentissage en cours\")\n","        else:\n","            print(f\"  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\")\n","        print(f\"{'='*70}\\n\")\n","        \n","        # LR Scheduler\n","        if USE_LR_SCHEDULER and (not USE_LR_WARMUP or epoch >= WARMUP_EPOCHS):\n","            scheduler.step(rmse)\n","        \n","        # Sauvegarder le meilleur mod√®le\n","        if rmse < best_rmse:\n","            best_rmse = rmse\n","            print(f\"üíæ Nouveau meilleur RMSE: {best_rmse:.4f} - Sauvegarde...\")\n","            torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, epoch)\n","            save_weights_npz(model, WEIGHTS_FILE)\n","    \n","    print(\"\\nüéâ Entra√Ænement termin√©!\")\n","    print(f\"üìä Meilleur RMSE: {best_rmse:.4f}\")\n","    \n","    # Sauvegarde finale\n","    print(f\"\\nüíæ Sauvegarde finale...\")\n","    torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, EPOCHS)\n","    save_weights_npz(model, WEIGHTS_FILE)\n","    print(f\"‚úÖ Mod√®le sauvegard√© dans {CHECKPOINT_FILE} et {WEIGHTS_FILE}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","============================================================\n"]}]},{"cell_type":"markdown","id":"f2bf4e17","metadata":{"id":"f2bf4e17"},"source":["## 12. Visualisation des r√©sultats"]},{"cell_type":"code","execution_count":null,"id":"46daebdc","metadata":{"id":"46daebdc"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Configurer le style des graphiques\n","plt.style.use('seaborn-v0_8-darkgrid')\n","fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n","\n","# Graphique 1: Loss\n","axes[0].plot(history['loss'], linewidth=2, color='#2E86AB', label='Training Loss')\n","axes[0].set_xlabel('√âpoque', fontsize=12)\n","axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n","axes[0].set_title('√âvolution de la perte pendant l\\'entra√Ænement', fontsize=14, fontweight='bold')\n","axes[0].legend(fontsize=10)\n","axes[0].grid(True, alpha=0.3)\n","\n","# Afficher les valeurs min/max\n","min_loss = min(history['loss'])\n","max_loss = max(history['loss'])\n","axes[0].axhline(y=min_loss, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_loss:.6f}')\n","axes[0].legend(fontsize=10)\n","\n","# Graphique 2: MAE (si disponible)\n","if 'mae' in history:\n","    axes[1].plot(history['mae'], linewidth=2, color='#F77F00', label='MAE')\n","    axes[1].set_xlabel('√âpoque', fontsize=12)\n","    axes[1].set_ylabel('MAE', fontsize=12)\n","    axes[1].set_title('Erreur absolue moyenne', fontsize=14, fontweight='bold')\n","    axes[1].legend(fontsize=10)\n","    axes[1].grid(True, alpha=0.3)\n","\n","    min_mae = min(history['mae'])\n","    axes[1].axhline(y=min_mae, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_mae:.6f}')\n","    axes[1].legend(fontsize=10)\n","else:\n","    axes[1].text(0.5, 0.5, 'MAE non disponible',\n","                ha='center', va='center', fontsize=14, transform=axes[1].transAxes)\n","    axes[1].set_xticks([])\n","    axes[1].set_yticks([])\n","\n","plt.tight_layout()\n","plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n","plt.show()\n","\n","# Afficher les statistiques finales\n","print(\"\\n\" + \"=\" * 60)\n","print(\"STATISTIQUES FINALES\")\n","print(\"=\" * 60)\n","print(f\"Perte finale: {history['loss'][-1]:.6f}\")\n","print(f\"Perte minimale: {min_loss:.6f} (√©poque {history['loss'].index(min_loss) + 1})\")\n","if 'mae' in history:\n","    print(f\"MAE final: {history['mae'][-1]:.6f}\")\n","    print(f\"MAE minimal: {min_mae:.6f} (√©poque {history['mae'].index(min_mae) + 1})\")\n","print(\"=\" * 60)"]},{"cell_type":"markdown","id":"859f7779","metadata":{"id":"859f7779"},"source":["## 13. Sauvegarde du mod√®le final"]},{"cell_type":"code","execution_count":null,"id":"b0c6f55e","metadata":{"id":"b0c6f55e"},"outputs":[],"source":["import datetime\n","\n","# Timestamp pour identifier cette sauvegarde\n","timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","\n","# Sauvegarder le mod√®le complet avec l'historique\n","final_model_path = f'ai/chess_model_final_{timestamp}.pt'\n","torch.save({\n","    'epoch': CONFIG['epochs'],\n","    'model_state_dict': model.state_dict(),\n","    'config': CONFIG,\n","    'history': history,\n","    'timestamp': timestamp,\n","}, final_model_path)\n","\n","print(\"=\" * 60)\n","print(\"SAUVEGARDE DES MOD√àLES\")\n","print(\"=\" * 60)\n","print(f\"‚úì Mod√®le final: {final_model_path}\")\n","\n","# Sauvegarder aussi au format .npz pour compatibilit√© avec l'ancien code\n","weights_path = 'ai/NN/chess_nn_weights.npz'\n","weights = {name: param.cpu().detach().numpy() for name, param in model.named_parameters()}\n","np.savez(weights_path, **weights)\n","print(f\"‚úì Poids .npz: {weights_path}\")\n","\n","# Copier aussi le checkpoint dans NN/\n","import shutil\n","checkpoint_backup = f'ai/NN/chess_model_checkpoint_{timestamp}.pt'\n","if os.path.exists(CONFIG['checkpoint_path']):\n","    shutil.copy(CONFIG['checkpoint_path'], checkpoint_backup)\n","    print(f\"‚úì Checkpoint backup: {checkpoint_backup}\")\n","\n","print(\"=\" * 60)\n","print(\"\\n‚úÖ Tous les fichiers sont sauvegard√©s sur votre Google Drive!\")\n","print(f\"   Chemin: {PROJECT_PATH}\")"]},{"cell_type":"markdown","id":"c4bfd244","metadata":{"id":"c4bfd244"},"source":["## 14. Test du mod√®le sur des positions al√©atoires"]},{"cell_type":"code","execution_count":null,"id":"b0315c06","metadata":{"id":"b0315c06"},"outputs":[],"source":["# Passer le mod√®le en mode √©valuation\n","model.eval()\n","\n","# Tester sur quelques positions al√©atoires\n","num_tests = 10\n","test_indices = np.random.choice(len(X_train), num_tests, replace=False)\n","\n","print(\"=\" * 60)\n","print(f\"TEST SUR {num_tests} POSITIONS AL√âATOIRES\")\n","print(\"=\" * 60)\n","\n","errors = []\n","\n","with torch.no_grad():\n","    for i, idx in enumerate(test_indices, 1):\n","        x = torch.FloatTensor(X_train[idx:idx+1]).to(CONFIG['device'])\n","        y_true = y_train[idx]\n","        y_pred = model(x).cpu().numpy()[0, 0]\n","        error = abs(y_true - y_pred)\n","        errors.append(error)\n","\n","        print(f\"\\nPosition {i}:\")\n","        print(f\"  √âvaluation r√©elle:  {y_true:+8.4f}\")\n","        print(f\"  Pr√©diction mod√®le:  {y_pred:+8.4f}\")\n","        print(f\"  Erreur absolue:     {error:8.4f}\")\n","\n","        # Indicateur visuel de la qualit√©\n","        if error < 0.1:\n","            print(f\"  Qualit√©: ‚úÖ Excellente\")\n","        elif error < 0.3:\n","            print(f\"  Qualit√©: ‚úì Bonne\")\n","        elif error < 0.5:\n","            print(f\"  Qualit√©: ‚ö† Moyenne\")\n","        else:\n","            print(f\"  Qualit√©: ‚ùå Faible\")\n","\n","print(\"\\n\" + \"=\" * 60)\n","print(\"STATISTIQUES DES TESTS\")\n","print(\"=\" * 60)\n","print(f\"Erreur moyenne: {np.mean(errors):.4f}\")\n","print(f\"Erreur m√©diane: {np.median(errors):.4f}\")\n","print(f\"Erreur min:     {np.min(errors):.4f}\")\n","print(f\"Erreur max:     {np.max(errors):.4f}\")\n","print(f\"√âcart-type:     {np.std(errors):.4f}\")\n","print(\"=\" * 60)"]},{"cell_type":"markdown","id":"30e9184e","metadata":{"id":"30e9184e"},"source":["## 15. R√©sum√© et fichiers g√©n√©r√©s"]},{"cell_type":"code","execution_count":null,"id":"cb92229a","metadata":{"id":"cb92229a"},"outputs":[],"source":["print(\"\\n\" + \"=\"*60)\n","print(\"üìä R√âSUM√â DE L'ENTRA√éNEMENT\")\n","print(\"=\"*60)\n","print(f\"\\nüìç Projet: {PROJECT_PATH}\")\n","print(f\"\\n‚öôÔ∏è Configuration:\")\n","print(f\"   ‚Ä¢ Parties g√©n√©r√©es: {CONFIG['num_games']:,}\")\n","print(f\"   ‚Ä¢ Positions d'entra√Ænement: {len(X_train):,}\")\n","print(f\"   ‚Ä¢ √âpoques: {CONFIG['epochs']}\")\n","print(f\"   ‚Ä¢ Batch size: {CONFIG['batch_size']}\")\n","print(f\"   ‚Ä¢ Learning rate: {CONFIG['learning_rate']}\")\n","print(f\"   ‚Ä¢ Device: {CONFIG['device']}\")\n","\n","print(f\"\\nüìà R√©sultats:\")\n","print(f\"   ‚Ä¢ Perte finale: {history['loss'][-1]:.6f}\")\n","print(f\"   ‚Ä¢ Perte minimale: {min(history['loss']):.6f}\")\n","if 'mae' in history:\n","    print(f\"   ‚Ä¢ MAE final: {history['mae'][-1]:.6f}\")\n","\n","print(f\"\\nüíæ Fichiers sauvegard√©s sur Drive:\")\n","files_to_check = [\n","    final_model_path,\n","    CONFIG['checkpoint_path'],\n","    weights_path,\n","    'training_history.png'\n","]\n","\n","for filepath in files_to_check:\n","    if os.path.exists(filepath):\n","        size = os.path.getsize(filepath) / (1024 * 1024)  # Convertir en MB\n","        print(f\"   ‚úì {filepath} ({size:.2f} MB)\")\n","    else:\n","        print(f\"   ‚úó {filepath} (non trouv√©)\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS!\")\n","print(\"=\"*60)\n","print(\"\\nTous les fichiers sont automatiquement synchronis√©s avec votre Google Drive.\")\n","print(\"Vous pouvez fermer ce notebook en toute s√©curit√©.\\n\")"]},{"cell_type":"code","execution_count":21,"id":"76f74c05","metadata":{"id":"76f74c05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761573913516,"user_tz":-60,"elapsed":15,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"fb621a16-ed55-4cbf-ac3d-1c0496679c3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Dataset CSV trouv√©: /content/drive/MyDrive/smart_chess_drive/chessData.csv\n","Dossier de checkpoints (cr√©√© si manquant): /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n","\n","Variables expos√©es:\n"," DATASET_CSV = /content/drive/MyDrive/smart_chess_drive/chessData.csv\n"," CKPT_DIR = /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n"]}],"source":["# Localiser le dataset sur Google Drive et pr√©parer le dossier de checkpoints\n","import os\n","from glob import glob\n","\n","# Chemin attendu du dossier contenant le dataset (donn√© par l'user)\n","# Updated based on user's feedback that the file is directly in smart_chess_drive\n","DATASET_DIR = '/content/drive/MyDrive/smart_chess_drive/'\n","\n","# Chercher un fichier .csv dans DATASET_DIR\n","DATASET_CSV = None\n","if os.path.exists(DATASET_DIR):\n","    csvs = glob(os.path.join(DATASET_DIR, '*.csv'))\n","    if len(csvs) > 0:\n","        # Assuming there's only one relevant CSV in that dir, pick the first one\n","        DATASET_CSV = csvs[0]\n","        print(f'‚úÖ Dataset CSV trouv√©: {DATASET_CSV}')\n","    else:\n","        print(f'‚ùå Aucun fichier .csv trouv√© dans {DATASET_DIR}. Placez votre fichier chessData.csv dans ce dossier.')\n","else:\n","    print(f'‚ùå Dossier dataset introuvable: {DATASET_DIR}. V√©rifiez le chemin sur votre Drive.')\n","\n","# Cr√©er un dossier de checkpoints dans le repo sur Drive (persistant)\n","CKPT_DIR = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints'\n","os.makedirs(CKPT_DIR, exist_ok=True)\n","print('Dossier de checkpoints (cr√©√© si manquant):', CKPT_DIR)\n","\n","# Exposer variables utiles\n","print('\\nVariables expos√©es:')\n","print(' DATASET_CSV =', DATASET_CSV)\n","print(' CKPT_DIR =', CKPT_DIR)"]},{"cell_type":"code","execution_count":null,"id":"9887d4b8","metadata":{"id":"9887d4b8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c5355e2-b976-48ef-b0b8-e1b79efd0391"},"outputs":[{"output_type":"stream","name":"stdout","text":["üñ•Ô∏è  Device: cuda\n","üöÄ GPU: Tesla T4\n","üíæ GPU Memory: 15.83 GB\n","Configuration trainer:\n"," DATASET_PATH= /content/drive/MyDrive/smart_chess_drive/chessData.csv\n"," CHECKPOINT_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n"," WEIGHTS_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n"," EPOCHS= 20\n"," MAX_SAMPLES= 500000\n","üìÇ Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n","üßπ Nettoyage : 190154 lignes corrompues supprim√©es.\n","‚úÖ 12,767,881 positions valides charg√©es.\n","\n","üìä Dataset complet: 12,767,881 positions\n","üÜï Cr√©ation d'un nouveau r√©seau...\n","\n","======================================================================\n","Configuration:\n","  Dataset complet: 12,767,881 positions\n","  √âchantillon/epoch: 500,000 positions\n","  Architecture: 768 ‚Üí 256 ‚Üí 256 ‚Üí 1\n","  Dropout: 0.3\n","  LeakyReLU alpha: 0.01\n","  Learning rate: 0.001 (AdamW, weight decay: 0.0001)\n","  LR Warmup: True (0.0001 ‚Üí 0.001)\n","  LR Scheduler: True (patience: 2)\n","  Batch size: 128\n","  Epochs: 20\n","  Device: cuda\n","======================================================================\n","\n","\n","[Epoch 1] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n","üî• Warmup epoch 1/3: LR = 0.000400\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/20:   0%|          | 10/3907 [00:01<05:52, 11.05it/s, loss=0.8637]"]},{"output_type":"stream","name":"stdout","text":["\n","[DEBUG batch 0] targets mean=0.1219 std=1.0175; preds mean=0.0330 std=0.0197; RMSE=1.0226; corr=-0.0520\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:42<00:00, 92.85it/s, loss=0.7508]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 1...\n","\n","======================================================================\n","EPOCH 1/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.7361  (baseline: 0.8272)\n","  MAE:         0.3011\n","  Am√©lioration: +11.0% vs baseline\n","  Corr√©lation: 0.4572\n","  Std preds:   0.3802  (cible: 0.8272)\n","  Mean preds:  0.0679  (cible: 0.0439)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.7361 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 2] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n","üî• Warmup epoch 2/3: LR = 0.000700\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.43it/s, loss=0.7174]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 2...\n","\n","======================================================================\n","EPOCH 2/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6632  (baseline: 0.7421)\n","  MAE:         0.2794\n","  Am√©lioration: +10.6% vs baseline\n","  Corr√©lation: 0.4557\n","  Std preds:   0.3790  (cible: 0.7421)\n","  Mean preds:  0.0032  (cible: 0.0466)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.6632 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 3] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n","üî• Warmup epoch 3/3: LR = 0.001000\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 95.03it/s, loss=0.7113]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 3...\n","\n","======================================================================\n","EPOCH 3/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6985  (baseline: 0.8209)\n","  MAE:         0.2809\n","  Am√©lioration: +14.9% vs baseline\n","  Corr√©lation: 0.5380\n","  Std preds:   0.3521  (cible: 0.8209)\n","  Mean preds:  0.0112  (cible: 0.0441)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 4] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.42it/s, loss=0.6964]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 4...\n","\n","======================================================================\n","EPOCH 4/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6412  (baseline: 0.7321)\n","  MAE:         0.2753\n","  Am√©lioration: +12.4% vs baseline\n","  Corr√©lation: 0.4867\n","  Std preds:   0.3773  (cible: 0.7321)\n","  Mean preds:  0.0774  (cible: 0.0358)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.6412 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 5] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 95.02it/s, loss=0.6904]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 5...\n","\n","======================================================================\n","EPOCH 5/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6604  (baseline: 0.7852)\n","  MAE:         0.2656\n","  Am√©lioration: +15.9% vs baseline\n","  Corr√©lation: 0.5508\n","  Std preds:   0.3511  (cible: 0.7852)\n","  Mean preds:  0.0436  (cible: 0.0511)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 6] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.75it/s, loss=0.6880]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 6...\n","\n","======================================================================\n","EPOCH 6/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6780  (baseline: 0.8147)\n","  MAE:         0.2650\n","  Am√©lioration: +16.8% vs baseline\n","  Corr√©lation: 0.5602\n","  Std preds:   0.4098  (cible: 0.8147)\n","  Mean preds:  0.0101  (cible: 0.0563)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 7] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.71it/s, loss=0.6810]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 7...\n","\n","======================================================================\n","EPOCH 7/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6952  (baseline: 0.8424)\n","  MAE:         0.2917\n","  Am√©lioration: +17.5% vs baseline\n","  Corr√©lation: 0.5675\n","  Std preds:   0.4515  (cible: 0.8424)\n","  Mean preds:  0.0750  (cible: 0.0359)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 8] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.37it/s, loss=0.6647]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 8...\n","\n","======================================================================\n","EPOCH 8/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6579  (baseline: 0.8487)\n","  MAE:         0.2670\n","  Am√©lioration: +22.5% vs baseline\n","  Corr√©lation: 0.6417\n","  Std preds:   0.4546  (cible: 0.8487)\n","  Mean preds:  0.0248  (cible: 0.0573)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 9] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.75it/s, loss=0.6582]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 9...\n","\n","======================================================================\n","EPOCH 9/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.7049  (baseline: 0.8894)\n","  MAE:         0.2850\n","  Am√©lioration: +20.7% vs baseline\n","  Corr√©lation: 0.6203\n","  Std preds:   0.4526  (cible: 0.8894)\n","  Mean preds:  0.0479  (cible: 0.0275)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 10] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.54it/s, loss=0.6547]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 10...\n","\n","======================================================================\n","EPOCH 10/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6081  (baseline: 0.7996)\n","  MAE:         0.2502\n","  Am√©lioration: +23.9% vs baseline\n","  Corr√©lation: 0.6500\n","  Std preds:   0.4957  (cible: 0.7996)\n","  Mean preds:  0.0382  (cible: 0.0317)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.6081 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 11] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.27it/s, loss=0.6524]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 11...\n","\n","======================================================================\n","EPOCH 11/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.5861  (baseline: 0.7644)\n","  MAE:         0.2503\n","  Am√©lioration: +23.3% vs baseline\n","  Corr√©lation: 0.6428\n","  Std preds:   0.4730  (cible: 0.7644)\n","  Mean preds:  0.0315  (cible: 0.0482)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.5861 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 12] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.74it/s, loss=0.6556]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 12...\n","\n","======================================================================\n","EPOCH 12/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6185  (baseline: 0.7926)\n","  MAE:         0.2592\n","  Am√©lioration: +22.0% vs baseline\n","  Corr√©lation: 0.6306\n","  Std preds:   0.4348  (cible: 0.7926)\n","  Mean preds:  0.0477  (cible: 0.0509)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 13] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.99it/s, loss=0.6507]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 13...\n","\n","======================================================================\n","EPOCH 13/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6738  (baseline: 0.8656)\n","  MAE:         0.2726\n","  Am√©lioration: +22.2% vs baseline\n","  Corr√©lation: 0.6304\n","  Std preds:   0.4989  (cible: 0.8656)\n","  Mean preds:  0.0542  (cible: 0.0354)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 14] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.97it/s, loss=0.6464]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 14...\n","\n","======================================================================\n","EPOCH 14/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.5737  (baseline: 0.7574)\n","  MAE:         0.2491\n","  Am√©lioration: +24.3% vs baseline\n","  Corr√©lation: 0.6564\n","  Std preds:   0.4484  (cible: 0.7574)\n","  Mean preds:  0.0630  (cible: 0.0481)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.5737 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 15] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 94.12it/s, loss=0.6474]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 15...\n","\n","======================================================================\n","EPOCH 15/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6533  (baseline: 0.8367)\n","  MAE:         0.2682\n","  Am√©lioration: +21.9% vs baseline\n","  Corr√©lation: 0.6275\n","  Std preds:   0.4759  (cible: 0.8367)\n","  Mean preds:  0.0536  (cible: 0.0529)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 16] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.61it/s, loss=0.6394]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 16...\n","\n","======================================================================\n","EPOCH 16/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.5655  (baseline: 0.7429)\n","  MAE:         0.2473\n","  Am√©lioration: +23.9% vs baseline\n","  Corr√©lation: 0.6523\n","  Std preds:   0.4327  (cible: 0.7429)\n","  Mean preds:  0.0428  (cible: 0.0362)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","üíæ Nouveau meilleur RMSE: 0.5655 - Sauvegarde...\n","Checkpoint PyTorch sauvegard√© dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n","Poids sauvegard√©s (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n","\n","[Epoch 17] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.95it/s, loss=0.6485]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 17...\n","\n","======================================================================\n","EPOCH 17/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6056  (baseline: 0.8039)\n","  MAE:         0.2586\n","  Am√©lioration: +24.7% vs baseline\n","  Corr√©lation: 0.6635\n","  Std preds:   0.4633  (cible: 0.8039)\n","  Mean preds:  0.0448  (cible: 0.0557)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 18] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:41<00:00, 93.36it/s, loss=0.6445]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 18...\n","\n","======================================================================\n","EPOCH 18/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6239  (baseline: 0.7956)\n","  MAE:         0.2563\n","  Am√©lioration: +21.6% vs baseline\n","  Corr√©lation: 0.6237\n","  Std preds:   0.4457  (cible: 0.7956)\n","  Mean preds:  0.0490  (cible: 0.0515)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 19] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3907/3907 [00:42<00:00, 92.89it/s, loss=0.6401]\n"]},{"output_type":"stream","name":"stdout","text":["\n","üîç √âvaluation epoch 19...\n","\n","======================================================================\n","EPOCH 19/20 - √âvaluation sur 5,000 positions\n","======================================================================\n","  RMSE:        0.6288  (baseline: 0.8655)\n","  MAE:         0.2590\n","  Am√©lioration: +27.3% vs baseline\n","  Corr√©lation: 0.6983\n","  Std preds:   0.4966  (cible: 0.8655)\n","  Mean preds:  0.0456  (cible: 0.0492)\n","  ‚Üí  Apprentissage en cours\n","======================================================================\n","\n","\n","[Epoch 20] üé≤ √âchantillonnage: 500,000 positions sur 12,767,881\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 20/20:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 2188/3907 [00:25<00:20, 82.10it/s, loss=0.6322]"]}],"source":["# Configurer et lancer le script d'entra√Ænement `ai.NN.train_torch` en adaptant les chemins pour Colab/Drive\n","import os\n","import importlib\n","\n","if DATASET_CSV is None:\n","    raise FileNotFoundError(f\"Dataset non trouv√© dans: {DATASET_DIR}\")\n","\n","# Importer le module d'entra√Ænement\n","import ai.NN.train_torch as trainer\n","\n","# Reload the module to pick up recent changes\n","importlib.reload(trainer)\n","\n","\n","# Rediriger les chemins dataset et checkpoints vers Drive\n","trainer.DATASET_PATH = DATASET_CSV\n","trainer.CHECKPOINT_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.CHECKPOINT_FILE))\n","trainer.WEIGHTS_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.WEIGHTS_FILE))\n","\n","# Optionally set other CONFIG parameters from the notebook if needed\n","# trainer.EPOCHS = CONFIG['epochs']\n","# trainer.BATCH_SIZE = CONFIG['batch_size']\n","# trainer.LEARNING_RATE = CONFIG['learning_rate']\n","# trainer.DEVICE = CONFIG['device']\n","# trainer.MAX_SAMPLES = CONFIG['num_games'] # Assuming num_games in CONFIG is similar to MAX_SAMPLES\n","\n","# Optionnel: r√©duire pour test rapide (d√©commentez si besoin)\n","# trainer.EPOCHS = 2\n","# trainer.MAX_SAMPLES = 5000\n","\n","print('Configuration trainer:')\n","print(' DATASET_PATH=', trainer.DATASET_PATH)\n","print(' CHECKPOINT_FILE=', trainer.CHECKPOINT_FILE)\n","print(' WEIGHTS_FILE=', trainer.WEIGHTS_FILE)\n","print(' EPOCHS=', trainer.EPOCHS)\n","print(' MAX_SAMPLES=', trainer.MAX_SAMPLES)\n","\n","\n","# Lancer l'entra√Ænement\n","trainer.main()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f5525dae","executionInfo":{"status":"ok","timestamp":1761574373656,"user_tz":-60,"elapsed":16,"user":{"displayName":"Gautier de Marsac","userId":"07528850342203083749"}},"outputId":"43c34ee0-a8e1-4e85-f097-d2f2b6b1d7c0"},"source":["import os\n","\n","file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n","\n","try:\n","    with open(file_path, 'r') as f:\n","        content = f.read()\n","    print(f\"Content of {file_path}:\")\n","    print(\"=\" * 60)\n","    print(content)\n","    print(\"=\" * 60)\n","except FileNotFoundError:\n","    print(f\"Error: File not found at {file_path}\")\n","except Exception as e:\n","    print(f\"An error occurred while reading the file: {e}\")"],"id":"f5525dae","execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Content of /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py:\n","============================================================\n","\"\"\"\n","Script d'entra√Ænement PyTorch optimis√© pour GPU\n","Compatible avec Google Colab et machines locales avec GPU\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","import os\n","\n","from Chess import Chess\n","from ai.NN.torch_nn_evaluator import TorchNNEvaluator, save_weights_npz, load_from_npz, torch_save_checkpoint, torch_load_checkpoint\n","\n","# --- CONFIGURATION DE L'ENTRA√éNEMENT ---\n","DATASET_PATH = \"C:\\\\Users\\\\gauti\\\\OneDrive\\\\Documents\\\\UE commande\\\\chessData.csv\"  # Adapt√© pour Colab (fichier √† la racine)\n","WEIGHTS_FILE = \"chess_nn_weights.npz\"\n","CHECKPOINT_FILE = \"chess_model_checkpoint.pt\"\n","\n","# Architecture\n","HIDDEN_SIZE = 256\n","DROPOUT = 0.3\n","LEAKY_ALPHA = 0.01\n","\n","# Hyperparam√®tres\n","LEARNING_RATE = 0.001\n","WEIGHT_DECAY = 1e-4  # L2 regularization (AdamW)\n","EPOCHS = 20\n","BATCH_SIZE = 128  # Plus grand pour GPU\n","MAX_SAMPLES = 500_000  # Plus de donn√©es avec GPU !\n","EVAL_MAX_SAMPLES = 5000\n","\n","# Options\n","USE_SAMPLING = True\n","RESET_WEIGHTS = False\n","DEBUG_STATS = True\n","\n","# LR Scheduler\n","USE_LR_SCHEDULER = True\n","LR_PATIENCE = 2\n","LR_FACTOR = 0.5\n","\n","# LR Warmup\n","USE_LR_WARMUP = True\n","WARMUP_EPOCHS = 3\n","WARMUP_START_LR = 0.0001\n","\n","# Device (auto-d√©tection GPU)\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"üñ•Ô∏è  Device: {DEVICE}\")\n","if torch.cuda.is_available():\n","    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n","    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","\n","\n","class ChessDataset(Dataset):\n","    \"\"\"Dataset PyTorch pour les positions d'√©checs\"\"\"\n","    def __init__(self, fens, evaluations):\n","        self.fens = fens\n","        self.evaluations = evaluations\n","        self.chess = Chess()\n","        \n","        # Pr√©calculer l'encodage pour acc√©l√©rer (optionnel, consomme plus de RAM)\n","        # self.encoded = [self._encode_fen(fen) for fen in tqdm(fens, desc=\"Encoding positions\")]\n","        \n","    def __len__(self):\n","        return len(self.fens)\n","    \n","    def __getitem__(self, idx):\n","        fen = self.fens[idx]\n","        target = self.evaluations[idx]\n","        \n","        # Encoder la position\n","        self.chess.load_fen(fen)\n","        encoded = self._encode_board(self.chess)\n","        \n","        return torch.from_numpy(encoded).float(), torch.tensor([target], dtype=torch.float32)\n","    \n","    def _encode_board(self, chess_instance):\n","        \"\"\"Encode le plateau en vecteur 768D (identique √† nn_evaluator.py)\"\"\"\n","        piece_to_index = {\n","            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n","            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n","        }\n","        vec = np.zeros(768, dtype=np.float32)\n","        for piece_char, bitboard in chess_instance.bitboards.items():\n","            if bitboard == 0:\n","                continue\n","            piece_index = piece_to_index[piece_char]\n","            temp_bb = int(bitboard)\n","            while temp_bb:\n","                square = (temp_bb & -temp_bb).bit_length() - 1\n","                vector_position = piece_index * 64 + square\n","                vec[vector_position] = 1.0\n","                temp_bb &= temp_bb - 1\n","        return vec\n","\n","\n","def load_data(filepath: str):\n","    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n","    print(f\"üìÇ Chargement du dataset depuis {filepath}...\")\n","    \n","    df = pd.read_csv(\n","        filepath, \n","        names=['FEN', 'Evaluation'], \n","        skiprows=1,\n","        comment='#'\n","    )\n","    \n","    initial_count = len(df)\n","    df.dropna(inplace=True)\n","    cleaned_count = len(df)\n","    \n","    if initial_count > cleaned_count:\n","        print(f\"üßπ Nettoyage : {initial_count - cleaned_count} lignes corrompues supprim√©es.\")\n","    \n","    fens = df['FEN'].values\n","    EVAL_SCALE_FACTOR = 1000.0\n","    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n","    \n","    print(f\"‚úÖ {len(fens):,} positions valides charg√©es.\")\n","    return fens, evaluations\n","\n","\n","def evaluate_model(model, dataloader, device):\n","    \"\"\"√âvalue le mod√®le sur un dataset\"\"\"\n","    model.eval()\n","    predictions = []\n","    targets = []\n","    \n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            predictions.extend(outputs.cpu().numpy().flatten())\n","            targets.extend(labels.numpy().flatten())\n","    \n","    predictions = np.array(predictions)\n","    targets = np.array(targets)\n","    \n","    rmse = float(np.sqrt(np.mean((predictions - targets) ** 2)))\n","    mae = float(np.mean(np.abs(predictions - targets)))\n","    corr = float(np.corrcoef(predictions, targets)[0, 1]) if len(predictions) > 1 else 0.0\n","    \n","    return rmse, mae, corr, predictions, targets\n","\n","\n","def main():\n","    # 1. Charger les donn√©es\n","    all_fens, all_evaluations = load_data(DATASET_PATH)\n","    \n","    print(f\"\\nüìä Dataset complet: {len(all_fens):,} positions\")\n","    \n","    eval_mean = float(np.mean(all_evaluations))\n","    \n","    # 2. Initialiser le mod√®le\n","    if RESET_WEIGHTS and os.path.exists(WEIGHTS_FILE):\n","        print(f\"üóëÔ∏è  Suppression des anciens poids: {WEIGHTS_FILE}\")\n","        os.remove(WEIGHTS_FILE)\n","    \n","    if os.path.exists(CHECKPOINT_FILE):\n","        print(f\"üì• Chargement du checkpoint PyTorch: {CHECKPOINT_FILE}\")\n","        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n","        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        model, _, start_step = torch_load_checkpoint(CHECKPOINT_FILE, model, optimizer, device=DEVICE)\n","        print(f\"‚úÖ Checkpoint charg√© (step {start_step})\")\n","    elif os.path.exists(WEIGHTS_FILE):\n","        print(f\"üì• Chargement des poids NumPy: {WEIGHTS_FILE}\")\n","        model, adam_moments = load_from_npz(WEIGHTS_FILE, device=DEVICE)\n","        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        # TODO: Restaurer les moments Adam si pr√©sents\n","        print(f\"‚úÖ Poids charg√©s depuis NumPy\")\n","    else:\n","        print(\"üÜï Cr√©ation d'un nouveau r√©seau...\")\n","        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n","        # Initialisation He (PyTorch le fait d√©j√† par d√©faut pour Linear + ReLU)\n","        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n","        \n","        # Warm-start du biais de sortie\n","        with torch.no_grad():\n","            model.l3.bias[0] = eval_mean\n","    \n","    model.to(DEVICE)\n","    \n","    # 3. Configuration de l'entra√Ænement\n","    criterion = nn.MSELoss()\n","    \n","    # LR Scheduler\n","    if USE_LR_SCHEDULER:\n","        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","            optimizer, mode='min', factor=LR_FACTOR, \n","            patience=LR_PATIENCE\n","        )\n","    \n","    print(f\"\\n{'='*70}\")\n","    print(f\"Configuration:\")\n","    print(f\"  Dataset complet: {len(all_fens):,} positions\")\n","    print(f\"  √âchantillon/epoch: {MAX_SAMPLES if USE_SAMPLING else len(all_fens):,} positions\")\n","    print(f\"  Architecture: 768 ‚Üí {HIDDEN_SIZE} ‚Üí {HIDDEN_SIZE} ‚Üí 1\")\n","    print(f\"  Dropout: {DROPOUT}\")\n","    print(f\"  LeakyReLU alpha: {LEAKY_ALPHA}\")\n","    print(f\"  Learning rate: {LEARNING_RATE} (AdamW, weight decay: {WEIGHT_DECAY})\")\n","    print(f\"  LR Warmup: {USE_LR_WARMUP} ({WARMUP_START_LR if USE_LR_WARMUP else 'N/A'} ‚Üí {LEARNING_RATE})\")\n","    print(f\"  LR Scheduler: {USE_LR_SCHEDULER} (patience: {LR_PATIENCE if USE_LR_SCHEDULER else 'N/A'})\")\n","    print(f\"  Batch size: {BATCH_SIZE}\")\n","    print(f\"  Epochs: {EPOCHS}\")\n","    print(f\"  Device: {DEVICE}\")\n","    print(f\"{'='*70}\\n\")\n","    \n","    # 4. Boucle d'entra√Ænement\n","    best_rmse = float('inf')\n","    \n","    for epoch in range(EPOCHS):\n","        # √âchantillonnage √† chaque epoch\n","        if USE_SAMPLING and len(all_fens) > MAX_SAMPLES:\n","            print(f\"\\n[Epoch {epoch+1}] üé≤ √âchantillonnage: {MAX_SAMPLES:,} positions sur {len(all_fens):,}\")\n","            idx = np.random.choice(len(all_fens), size=MAX_SAMPLES, replace=False)\n","            fens = all_fens[idx]\n","            evaluations = all_evaluations[idx]\n","        else:\n","            fens = all_fens\n","            evaluations = all_evaluations\n","        \n","        # LR Warmup\n","        if USE_LR_WARMUP and epoch < WARMUP_EPOCHS:\n","            warmup_progress = (epoch + 1) / WARMUP_EPOCHS\n","            lr = WARMUP_START_LR + (LEARNING_RATE - WARMUP_START_LR) * warmup_progress\n","            for param_group in optimizer.param_groups:\n","                param_group['lr'] = lr\n","            print(f\"üî• Warmup epoch {epoch+1}/{WARMUP_EPOCHS}: LR = {lr:.6f}\")\n","        \n","        # Cr√©er le dataset et dataloader\n","        train_dataset = ChessDataset(fens, evaluations)\n","        train_loader = DataLoader(\n","            train_dataset, \n","            batch_size=BATCH_SIZE, \n","            shuffle=True,\n","            num_workers=0,  # Augmenter si CPU multi-core (ex: 4)\n","            pin_memory=True if torch.cuda.is_available() else False\n","        )\n","        \n","        # Training\n","        model.train()\n","        total_loss = 0\n","        num_batches = 0\n","        \n","        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\")\n","        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n","            inputs = inputs.to(DEVICE)\n","            targets = targets.to(DEVICE)\n","            \n","            # Forward\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","            \n","            # Backward\n","            loss.backward()\n","            \n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n","            \n","            # Update\n","            optimizer.step()\n","            \n","            total_loss += loss.item()\n","            num_batches += 1\n","            \n","            # Debug stats (premier batch)\n","            if DEBUG_STATS and epoch == 0 and batch_idx == 0:\n","                with torch.no_grad():\n","                    preds = outputs.cpu().numpy().flatten()\n","                    targs = targets.cpu().numpy().flatten()\n","                    batch_rmse = np.sqrt(np.mean((preds - targs) ** 2))\n","                    corr = np.corrcoef(preds, targs)[0, 1] if len(preds) > 1 else 0.0\n","                    print(f\"\\n[DEBUG batch 0] targets mean={targs.mean():.4f} std={targs.std():.4f}; \"\n","                          f\"preds mean={preds.mean():.4f} std={preds.std():.4f}; \"\n","                          f\"RMSE={batch_rmse:.4f}; corr={corr:.4f}\")\n","            \n","            # Update progress bar\n","            avg_loss = total_loss / num_batches\n","            progress_bar.set_postfix({\"loss\": f\"{np.sqrt(avg_loss):.4f}\"})\n","        \n","        # √âvaluation fin d'√©poque\n","        print(f\"\\nüîç √âvaluation epoch {epoch+1}...\")\n","        \n","        # √âchantillon d'√©valuation\n","        if EVAL_MAX_SAMPLES and len(all_fens) > EVAL_MAX_SAMPLES:\n","            eval_idx = np.random.choice(len(all_fens), size=EVAL_MAX_SAMPLES, replace=False)\n","            eval_fens = all_fens[eval_idx]\n","            eval_targets = all_evaluations[eval_idx]\n","        else:\n","            eval_fens = all_fens\n","            eval_targets = all_evaluations\n","        \n","        eval_dataset = ChessDataset(eval_fens, eval_targets)\n","        eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE*2, shuffle=False)\n","        \n","        rmse, mae, corr, preds, targets = evaluate_model(model, eval_loader, DEVICE)\n","        \n","        baseline_rmse = targets.std()\n","        improvement = 100 * (1 - rmse / baseline_rmse) if baseline_rmse > 0 else 0\n","        \n","        # Affichage\n","        print(f\"\\n{'='*70}\")\n","        print(f\"EPOCH {epoch+1}/{EPOCHS} - √âvaluation sur {len(eval_fens):,} positions\")\n","        print(f\"{'='*70}\")\n","        print(f\"  RMSE:        {rmse:.4f}  (baseline: {baseline_rmse:.4f})\")\n","        print(f\"  MAE:         {mae:.4f}\")\n","        print(f\"  Am√©lioration: {improvement:+.1f}% vs baseline\")\n","        print(f\"  Corr√©lation: {corr:.4f}\")\n","        print(f\"  Std preds:   {preds.std():.4f}  (cible: {targets.std():.4f})\")\n","        print(f\"  Mean preds:  {preds.mean():.4f}  (cible: {targets.mean():.4f})\")\n","        \n","        if improvement > 50:\n","            print(f\"  ‚úì‚úì Performance excellente!\")\n","        elif improvement > 30:\n","            print(f\"  ‚úì  Bon apprentissage!\")\n","        elif improvement > 10:\n","            print(f\"  ‚Üí  Apprentissage en cours\")\n","        else:\n","            print(f\"  ‚ö†  Faible am√©lioration - v√©rifier hyperparam√®tres\")\n","        print(f\"{'='*70}\\n\")\n","        \n","        # LR Scheduler\n","        if USE_LR_SCHEDULER and (not USE_LR_WARMUP or epoch >= WARMUP_EPOCHS):\n","            scheduler.step(rmse)\n","        \n","        # Sauvegarder le meilleur mod√®le\n","        if rmse < best_rmse:\n","            best_rmse = rmse\n","            print(f\"üíæ Nouveau meilleur RMSE: {best_rmse:.4f} - Sauvegarde...\")\n","            torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, epoch)\n","            save_weights_npz(model, WEIGHTS_FILE)\n","    \n","    print(\"\\nüéâ Entra√Ænement termin√©!\")\n","    print(f\"üìä Meilleur RMSE: {best_rmse:.4f}\")\n","    \n","    # Sauvegarde finale\n","    print(f\"\\nüíæ Sauvegarde finale...\")\n","    torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, EPOCHS)\n","    save_weights_npz(model, WEIGHTS_FILE)\n","    print(f\"‚úÖ Mod√®le sauvegard√© dans {CHECKPOINT_FILE} et {WEIGHTS_FILE}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n","\n","============================================================\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"}},"nbformat":4,"nbformat_minor":5}