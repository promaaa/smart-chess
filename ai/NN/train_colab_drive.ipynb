{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b5a4df",
   "metadata": {
    "id": "12b5a4df"
   },
   "source": [
    "# Entra√Ænement du Neural Network pour Smart Chess sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entra√Æner le r√©seau de neurones pour l'√©valuation d'√©checs en utilisant les ressources GPU de Google Colab.\n",
    "\n",
    "**Chemin du projet sur Drive:** `MyDrive/smart_chess_drive/smart-chess`\n",
    "\n",
    "## Instructions\n",
    "1. Aller dans **Runtime > Change runtime type > GPU** (T4 ou mieux)\n",
    "2. Ex√©cuter les cellules dans l'ordre\n",
    "3. Les mod√®les seront sauvegard√©s automatiquement sur votre Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b4590",
   "metadata": {
    "id": "de1b4590"
   },
   "source": [
    "## 1. V√©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5e0dc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1763306645854,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "8d5e0dc5",
    "outputId": "f8987f22-f986-4308-c70e-c67729d749c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 16 15:24:05 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier la disponibilit√© du GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddd742",
   "metadata": {
    "id": "89ddd742"
   },
   "source": [
    "## 2. Montage Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5e4f04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24117,
     "status": "ok",
     "timestamp": 1763306669975,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "ce5e4f04",
    "outputId": "21cbeca0-a7c3-4b78-bb0e-d1ea8c8a53c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf2990",
   "metadata": {
    "id": "1ccf2990"
   },
   "source": [
    "## 3. Configuration du chemin du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabb986a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1531,
     "status": "ok",
     "timestamp": 1763306671509,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "fabb986a",
    "outputId": "665ea746-ae4c-457e-8854-002e7c89130a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n",
      "\n",
      "Contenu du r√©pertoire:\n",
      "  - .git\n",
      "  - .gitignore\n",
      "  - README.md\n",
      "  - ai\n",
      "  - docs\n",
      "  - prototypes\n"
     ]
    }
   ],
   "source": [
    "# D√©finir le chemin vers le projet sur votre Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "os.chdir(PROJECT_PATH)\n",
    "sys.path.insert(0, PROJECT_PATH)\n",
    "\n",
    "print(f\"R√©pertoire de travail: {os.getcwd()}\")\n",
    "print(f\"\\nContenu du r√©pertoire:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20e36c",
   "metadata": {
    "id": "3f20e36c"
   },
   "source": [
    "## 4. Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783beaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7676,
     "status": "ok",
     "timestamp": 1763306679186,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "7783beaf",
    "outputId": "a552dc9f-ec1b-4e26-ac98-7979749a96e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Installation termin√©e\n"
     ]
    }
   ],
   "source": [
    "# Installer les packages n√©cessaires\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy matplotlib tqdm scikit-learn\n",
    "\n",
    "print(\"‚úì Installation termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25365688",
   "metadata": {
    "id": "25365688"
   },
   "source": [
    "## 5. V√©rification de l'environnement PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76e678b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5128,
     "status": "ok",
     "timestamp": 1763306684315,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "a76e678b",
    "outputId": "b553022c-94c8-4d81-adfb-c05ba6444102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION SYST√àME\n",
      "============================================================\n",
      "PyTorch version: 2.8.0+cu126\n",
      "NumPy version: 2.0.2\n",
      "\n",
      "CUDA disponible: True\n",
      "CUDA version: 12.6\n",
      "Nom du GPU: Tesla T4\n",
      "M√©moire GPU totale: 15.83 GB\n",
      "Compute Capability: 7.5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION SYST√àME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"\\nCUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"M√©moire GPU totale: {props.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ATTENTION: GPU non disponible, l'entra√Ænement sera tr√®s lent!\")\n",
    "    print(\"   Allez dans Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a1e23",
   "metadata": {
    "id": "f91a1e23"
   },
   "source": [
    "## 6. Import des modules du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7397821",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4912,
     "status": "ok",
     "timestamp": 1763306689228,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "c7397821",
    "outputId": "8740c380-eb3e-4d3a-d268-9c07de079bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©pertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n",
      "\n",
      "Quelques fichiers √† la racine du projet:\n",
      "['.git', '.gitignore', 'README.md', 'ai', 'docs', 'prototypes']\n",
      "\n",
      "Contenu du dossier ai/:\n",
      "['AI_reduction', 'Chess.py', 'ChessInteractif - v7.py', 'ChessInteractifv10.py', 'ChessInteractifv2.py', 'Chess_v2.py', 'NN', 'Null_move_AI', 'Old_AI', 'Player.py', 'Profile', 'Tests.py', '__init__.py', '__pycache__', 'alphabeta.py', 'alphabeta_engine.py', 'alphabeta_engine_v2.py', 'analyze_reduction_overhead.py', 'base_engine.py', 'check_dataset_stats.py', 'check_gpu.py', 'check_performance.py', 'checkpoints', 'chess_model_checkpoint.pt', 'debug_conversion.py', 'engine.py', 'engine_match.py', 'evaluator.py', 'example_move_reduction.py', 'fast_evaluator.py', 'gaviota.py', 'journal-experiments.md', 'optimized_chess.py', 'pgn.py', 'polyglot.py', 'profile_report_1760344602.txt', 'py.typed', 'svg.py', 'syzygy.py', 'test_depth_6_performance.py', 'test_depth_6_quick.py', 'test_depth_effectiveness.py', 'test_engines_v2.py', 'test_evaluator_performance.py', 'test_generalization.py', 'test_move_reduction.py', 'test_null_move.py', 'test_null_move_comparison.py', 'test_null_move_effectiveness.py', 'test_null_move_final.py', 'test_null_move_optimization.py', 'test_null_move_quick.py', 'test_timeout_fix.py', 'variant.py', 'visualize_sampling.py']\n",
      "\n",
      "‚úÖ Import direct `Chess` OK (module trouv√© via sys.path)\n",
      "üñ•Ô∏è  Device: cuda\n",
      "üöÄ GPU: Tesla T4\n",
      "üíæ GPU Memory: 15.83 GB\n",
      "\n",
      "‚úì Modules import√©s avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "# Importer les modules n√©cessaires depuis le projet (robuste √† l'emplacement du repo sur Drive)\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Assurez-vous que PROJECT_PATH est d√©fini et ajoutez √©galement le dossier `ai` au PYTHONPATH\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "AI_SUBDIR = os.path.join(PROJECT_PATH, 'ai')\n",
    "\n",
    "# V√©rifier les chemins alternatifs (si l'utilisateur a copi√© le repo dans /content)\n",
    "ALT_PATH = '/content/smart-chess'\n",
    "\n",
    "# Choisir un chemin existant\n",
    "if not os.path.isdir(PROJECT_PATH) and os.path.isdir(ALT_PATH):\n",
    "    PROJECT_PATH = ALT_PATH\n",
    "\n",
    "if not os.path.isdir(PROJECT_PATH):\n",
    "    raise FileNotFoundError(f\"R√©pertoire projet introuvable: {PROJECT_PATH}. Montez Drive et v√©rifiez le chemin.\")\n",
    "\n",
    "# Ajouter au sys.path si n√©cessaire\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_PATH)\n",
    "if AI_SUBDIR not in sys.path and os.path.isdir(AI_SUBDIR):\n",
    "    sys.path.insert(0, AI_SUBDIR)\n",
    "\n",
    "# Se placer dans le r√©pertoire projet\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "print('R√©pertoire de travail:', os.getcwd())\n",
    "print('\\nQuelques fichiers √† la racine du projet:')\n",
    "print(sorted(os.listdir(PROJECT_PATH))[:50])\n",
    "print('\\nContenu du dossier ai/:')\n",
    "print(sorted(os.listdir(AI_SUBDIR))[:100])\n",
    "\n",
    "# Diagnostic d'import direct pour le module Chess\n",
    "try:\n",
    "    import Chess\n",
    "    print('\\n‚úÖ Import direct `Chess` OK (module trouv√© via sys.path)')\n",
    "except Exception as e:\n",
    "    print('\\n‚ùå Import direct `Chess` a √©chou√©:', e)\n",
    "    print('V√©rifiez que `ai/Chess.py` existe et que le dossier ai/ est dans sys.path')\n",
    "\n",
    "# Maintenant importer le module d'entra√Ænement (trainer) - UPDATED to torch_train\n",
    "try:\n",
    "    import ai.NN.torch_train as trainer\n",
    "    import ai.NN.torch_nn_evaluator as torch_eval\n",
    "    from ai.Chess_v2 import Chess\n",
    "    print('\\n‚úì Modules import√©s avec succ√®s!')\n",
    "except Exception as e:\n",
    "    print('\\n‚ùå Erreur d\\'import lors de l\\'import du trainer:', e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e668793",
   "metadata": {
    "id": "0e668793"
   },
   "source": [
    "## 7. Configuration de l'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f87f8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1763306689232,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "c9f87f8d",
    "outputId": "3fb38ac9-f3a9-402f-8823-8d209990d3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION DE L'ENTRA√éNEMENT (NNUE)\n",
      "============================================================\n",
      "num_games           : 10000\n",
      "batch_size          : 256\n",
      "epochs              : 50\n",
      "learning_rate       : 0.001\n",
      "hidden1             : 4096\n",
      "hidden2             : 256\n",
      "hidden3             : 32\n",
      "dropout             : 0.0\n",
      "device              : cuda\n",
      "num_workers         : 2\n",
      "checkpoint_path     : ai/chess_model_checkpoint.pt\n",
      "save_interval       : 5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Param√®tres d'entra√Ænement (NNUE architecture)\n",
    "CONFIG = {\n",
    "    # G√©n√©ration de donn√©es\n",
    "    'num_games': 10000,          # Nombre de parties √† g√©n√©rer pour l'entra√Ænement\n",
    "\n",
    "    # Hyperparam√®tres NNUE\n",
    "    'batch_size': 256,           # Taille du batch (augmenter si GPU puissant)\n",
    "    'epochs': 50,                # Nombre d'√©poques d'entra√Ænement\n",
    "    'learning_rate': 0.001,      # Taux d'apprentissage\n",
    "\n",
    "    # Architecture NNUE (768 ‚Üí 4096 ‚Üí 256 ‚Üí 32 ‚Üí 1)\n",
    "    'hidden1': 4096,\n",
    "    'hidden2': 256,\n",
    "    'hidden3': 32,\n",
    "    'dropout': 0.0,              # NNUE ne use pas de dropout\n",
    "\n",
    "    # Configuration syst√®me\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 2,            # Workers pour le DataLoader\n",
    "\n",
    "    # Sauvegarde\n",
    "    'checkpoint_path': 'ai/chess_model_checkpoint.pt',\n",
    "    'save_interval': 5,          # Sauvegarder tous les N √©poques\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION DE L'ENTRA√éNEMENT (NNUE)\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    print(\"\\n‚ö†Ô∏è ATTENTION: Entra√Ænement sur CPU d√©tect√©!\")\n",
    "    print(\"   R√©duisez num_games et epochs pour un test rapide.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ad90f",
   "metadata": {
    "id": "f72ad90f"
   },
   "source": [
    "## 8. G√©n√©ration des donn√©es d'entra√Ænement\n",
    "\n",
    "Cette √©tape g√©n√®re des parties d'√©checs al√©atoires et calcule les √©valuations de position.\n",
    "**Attention:** Cela peut prendre 15-30 minutes selon le nombre de parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f74c05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763306689235,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "76f74c05",
    "outputId": "f0f6d543-e04e-4dfe-dd9d-3ae1c402aa0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset CSV trouv√©: /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      "Dossier de checkpoints (cr√©√© si manquant): /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n",
      "\n",
      "Variables expos√©es:\n",
      " DATASET_CSV = /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      " CKPT_DIR = /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Localiser le dataset sur Google Drive et pr√©parer le dossier de checkpoints\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Chemin attendu du dossier contenant le dataset (donn√© par l'user)\n",
    "# Updated based on user's feedback that the file is directly in smart_chess_drive\n",
    "DATASET_DIR = '/content/drive/MyDrive/smart_chess_drive/'\n",
    "\n",
    "# Chercher un fichier .csv dans DATASET_DIR\n",
    "DATASET_CSV = None\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    csvs = glob(os.path.join(DATASET_DIR, '*.csv'))\n",
    "    if len(csvs) > 0:\n",
    "        # Assuming there's only one relevant CSV in that dir, pick the first one\n",
    "        DATASET_CSV = csvs[0]\n",
    "        print(f'‚úÖ Dataset CSV trouv√©: {DATASET_CSV}')\n",
    "    else:\n",
    "        print(f'‚ùå Aucun fichier .csv trouv√© dans {DATASET_DIR}. Placez votre fichier chessData.csv dans ce dossier.')\n",
    "else:\n",
    "    print(f'‚ùå Dossier dataset introuvable: {DATASET_DIR}. V√©rifiez le chemin sur votre Drive.')\n",
    "\n",
    "# Cr√©er un dossier de checkpoints dans le repo sur Drive (persistant)\n",
    "CKPT_DIR = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "print('Dossier de checkpoints (cr√©√© si manquant):', CKPT_DIR)\n",
    "\n",
    "# Exposer variables utiles\n",
    "print('\\nVariables expos√©es:')\n",
    "print(' DATASET_CSV =', DATASET_CSV)\n",
    "print(' CKPT_DIR =', CKPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4504f1e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22005,
     "status": "ok",
     "timestamp": 1763306711241,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "4504f1e6",
    "outputId": "85b15915-9130-459d-80f9-796bd20c09eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset (depuis chessData)...\n",
      "üìÇ Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "üßπ Nettoyage : 190154 lignes corrompues supprim√©es.\n",
      "‚úÖ 12,767,881 positions valides charg√©es.\n",
      "\n",
      "============================================================\n",
      "DONN√âES CHARG√âES\n",
      "============================================================\n",
      "Nombre total de positions: 12,767,881\n",
      "Temps √©coul√©: 21.9s (0.4 min)\n",
      "============================================================\n",
      "\n",
      "Statistiques sur les √©valuations:\n",
      "  Min: -15.3120\n",
      "  Max: 15.3190\n",
      "  Moyenne: 0.0455\n",
      "  √âcart-type: 0.8139\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Chargement du dataset (depuis chessData)...\")\n",
    "\n",
    "# Pr√©f√©rer la variable DATASET_CSV (d√©finie apr√®s le montage Drive) sinon utiliser la valeur par d√©faut du module trainer\n",
    "dataset_path = globals().get('DATASET_CSV')\n",
    "\n",
    "if dataset_path is None:\n",
    "    raise FileNotFoundError('Aucun chemin de dataset d√©fini. Montez Drive et placez le fichier CSV dans MyDrive/smart_chess_drive/chessData')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Utiliser la fonction de chargement du script d'entra√Ænement pour assurer le m√™me pr√©traitement\n",
    "fens, evaluations = trainer.load_data(dataset_path)\n",
    "\n",
    "# Variables attendues plus bas dans le notebook\n",
    "X_train = fens\n",
    "y_train = evaluations\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONN√âES CHARG√âES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nombre total de positions: {len(X_train):,}\")\n",
    "print(f\"Temps √©coul√©: {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques sur les √©valuations\n",
    "print(f\"\\nStatistiques sur les √©valuations:\")\n",
    "print(f\"  Min: {y_train.min():.4f}\")\n",
    "print(f\"  Max: {y_train.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.4f}\")\n",
    "print(f\"  √âcart-type: {y_train.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2746aac",
   "metadata": {},
   "source": [
    "## 8b. Split du dataset (99% train, 1% validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bfb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split du dataset: 99% training, 1% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.01, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLIT DU DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Donn√©es d'entra√Ænement: {len(X_train):,} positions ({len(X_train)/(len(X_train)+len(X_val))*100:.1f}%)\")\n",
    "print(f\"Donn√©es de validation:  {len(X_val):,} positions ({len(X_val)/(len(X_train)+len(X_val))*100:.1f}%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques sur les ensembles\n",
    "print(f\"\\nStatistiques Training Set:\")\n",
    "print(f\"  Min: {y_train.min():.4f}\")\n",
    "print(f\"  Max: {y_train.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.4f}\")\n",
    "print(f\"  √âcart-type: {y_train.std():.4f}\")\n",
    "\n",
    "print(f\"\\nStatistiques Validation Set:\")\n",
    "print(f\"  Min: {y_val.min():.4f}\")\n",
    "print(f\"  Max: {y_val.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_val.mean():.4f}\")\n",
    "print(f\"  √âcart-type: {y_val.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc365442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1763306711250,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "cc365442",
    "outputId": "5143995a-8dcb-4a66-e54f-ae53c136d1dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code of trainer.load_data:\n",
      "============================================================\n",
      "def load_data(filepath: str):\n",
      "    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n",
      "    print(f\"üìÇ Chargement du dataset depuis {filepath}...\")\n",
      "    \n",
      "    df = pd.read_csv(\n",
      "        filepath, \n",
      "        names=['FEN', 'Evaluation'], \n",
      "        skiprows=1,\n",
      "        comment='#'\n",
      "    )\n",
      "    \n",
      "    initial_count = len(df)\n",
      "    df.dropna(inplace=True)\n",
      "    cleaned_count = len(df)\n",
      "    \n",
      "    if initial_count > cleaned_count:\n",
      "        print(f\"üßπ Nettoyage : {initial_count - cleaned_count} lignes corrompues supprim√©es.\")\n",
      "    \n",
      "    fens = df['FEN'].values\n",
      "    EVAL_SCALE_FACTOR = 1000.0\n",
      "    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n",
      "    \n",
      "    print(f\"‚úÖ {len(fens):,} positions valides charg√©es.\")\n",
      "    return fens, evaluations\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import ai.NN.torch_train as trainer\n",
    "\n",
    "try:\n",
    "    # Get the source code of the load_data function\n",
    "    source_code = inspect.getsource(trainer.load_data)\n",
    "    print(\"Source code of trainer.load_data:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(source_code)\n",
    "    print(\"=\" * 60)\n",
    "except TypeError:\n",
    "    print(\"Could not get source code for trainer.load_data. It might not be a function defined in the file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find the torch_train.py file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to get source code: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b3c66b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1763306711255,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "e0b3c66b",
    "outputId": "dd4a252f-0d29-4254-d2cb-a18dfce4a2df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ La fonction load_data dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/torch_train.py accepte d√©j√† un param√®tre filepath.\n",
      "Aucune modification n√©cessaire.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/torch_train.py')\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Assuming the load_data function signature is currently load_data(filepath: str):\n",
    "# We need to verify it accepts a filepath parameter\n",
    "if 'def load_data(filepath:' in content or 'def load_data(filepath)' in content:\n",
    "    print(f\"‚úÖ La fonction load_data dans {file_path} accepte d√©j√† un param√®tre filepath.\")\n",
    "    print(\"Aucune modification n√©cessaire.\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è La fonction load_data pourrait n√©cessiter une modification.\")\n",
    "    print(\"V√©rifiez manuellement si elle accepte un chemin de fichier en param√®tre.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea4dd7",
   "metadata": {
    "id": "fdea4dd7"
   },
   "source": [
    "## 9. Cr√©ation du dataset et du dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45e62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763306711258,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "d0c45e62",
    "outputId": "272ddd6f-2e84-4a55-9150-93a548b09fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATALOADER CONFIGUR√â\n",
      "============================================================\n",
      "Taille du dataset: 12,767,881 √©chantillons\n",
      "Nombre de batches: 49,875\n",
      "Taille du batch: 256\n",
      "Derni√®re batch: 137 √©chantillons\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from ai.NN.torch_train import ChessDataset\n",
    "\n",
    "# Cr√©er les datasets pour training et validation\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "val_dataset = ChessDataset(X_val, y_val)\n",
    "\n",
    "# Cr√©er les dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATALOADERS CONFIGUR√âS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training dataset: {len(train_dataset):,} √©chantillons\")\n",
    "print(f\"  Nombre de batches: {len(train_loader):,}\")\n",
    "print(f\"  Taille du batch: {CONFIG['batch_size']}\")\n",
    "print(f\"  Derni√®re batch: {len(train_dataset) % CONFIG['batch_size']} √©chantillons\")\n",
    "print()\n",
    "print(f\"Validation dataset: {len(val_dataset):,} √©chantillons\")\n",
    "print(f\"  Nombre de batches: {len(val_loader):,}\")\n",
    "print(f\"  Taille du batch: {CONFIG['batch_size']}\")\n",
    "print(f\"  Derni√®re batch: {len(val_dataset) % CONFIG['batch_size']} √©chantillons\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dda22",
   "metadata": {
    "id": "f05dda22"
   },
   "source": [
    "## 10. Cr√©ation du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "056d2b3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1763306711433,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "056d2b3a",
    "outputId": "a4ce1a32-0979-4346-a12f-0a137d7b4ad8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARCHITECTURE DU MOD√àLE (NNUE-LIKE)\n",
      "============================================================\n",
      "TorchNNEvaluator(\n",
      "  (l1): Linear(in_features=768, out_features=4096, bias=True)\n",
      "  (l2): Linear(in_features=4096, out_features=256, bias=True)\n",
      "  (l3): Linear(in_features=256, out_features=32, bias=True)\n",
      "  (l4): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (act): ReLU()\n",
      ")\n",
      "============================================================\n",
      "\n",
      "Nombre total de param√®tres: 4,206,913\n",
      "Param√®tres entra√Ænables: 4,206,913\n",
      "Device: cuda\n",
      "Taille estim√©e du mod√®le: 16.05 MB\n",
      "\n",
      "Architecture d√©taill√©e:\n",
      "  Input:  768\n",
      "  Layer 1: 4096 (ReLU)\n",
      "  Layer 2: 256 (ReLU)\n",
      "  Layer 3: 32 (ReLU)\n",
      "  Output: 1 (Linear)\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er le mod√®le NNUE et le d√©placer sur le device appropri√©\n",
    "from ai.NN.torch_nn_evaluator import TorchNNEvaluator\n",
    "\n",
    "model = TorchNNEvaluator(\n",
    "    hidden1=CONFIG['hidden1'],\n",
    "    hidden2=CONFIG['hidden2'],\n",
    "    hidden3=CONFIG['hidden3'],\n",
    "    dropout=CONFIG['dropout']\n",
    ").to(CONFIG['device'])\n",
    "\n",
    "# Afficher l'architecture\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHITECTURE DU MOD√àLE (NNUE-LIKE)\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compter les param√®tres\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nNombre total de param√®tres: {total_params:,}\")\n",
    "print(f\"Param√®tres entra√Ænables: {trainable_params:,}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "\n",
    "# Estimer la taille m√©moire du mod√®le\n",
    "param_size_mb = total_params * 4 / (1024 ** 2)  # 4 bytes par float32\n",
    "print(f\"Taille estim√©e du mod√®le: {param_size_mb:.2f} MB\")\n",
    "\n",
    "# Afficher les dimensions des couches\n",
    "print(f\"\\nArchitecture d√©taill√©e:\")\n",
    "print(f\"  Input:  {model.l1.in_features}\")\n",
    "print(f\"  Layer 1: {model.l1.out_features} (ReLU)\")\n",
    "print(f\"  Layer 2: {model.l2.out_features} (ReLU)\")\n",
    "print(f\"  Layer 3: {model.l3.out_features} (ReLU)\")\n",
    "print(f\"  Output: {model.l4.out_features} (Linear)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ba4a7",
   "metadata": {
    "id": "aa1ba4a7"
   },
   "source": [
    "## 11. Entra√Ænement du mod√®le\n",
    "\n",
    "Cette √©tape lance l'entra√Ænement complet. Les checkpoints sont sauvegard√©s automatiquement sur votre Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d4b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9887d4b8",
    "outputId": "691a7bd7-68c3-466a-ea9f-78f2902a9ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Device: cuda\n",
      "üöÄ GPU: Tesla T4\n",
      "üíæ GPU Memory: 15.83 GB\n",
      "‚úÖ Harmonisation: trainer.BATCH_SIZE = 256\n",
      "‚úÖ Architecture NNUE appliqu√©e: 4096 ‚Üí 256 ‚Üí 32\n",
      "‚úÖ MAX_SAMPLES = 200000\n",
      "\n",
      "Configuration trainer:\n",
      " DATASET_PATH= /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      " CHECKPOINT_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      " WEIGHTS_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      " Architecture: 768 ‚Üí 4096 ‚Üí 256 ‚Üí 32 ‚Üí 1\n",
      " EPOCHS= 10\n",
      " MAX_SAMPLES= 200000\n",
      "üìÇ Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "üßπ Nettoyage : 190154 lignes corrompues supprim√©es.\n",
      "‚úÖ 12,767,881 positions valides charg√©es.\n",
      "\n",
      "üìä Dataset complet: 12,767,881 positions\n",
      "üì• Chargement du checkpoint PyTorch: /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "‚úÖ Checkpoint charg√© (step 10), best_rmse=0.4879997968673706\n",
      "‚ÑπÔ∏è Learning rate enregistr√© d√©tect√©: 0.002500\n",
      "Saisir le learning rate de d√©part [0.002500]: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Entra√Ænement manuel avec boucle d'entra√Ænement et validation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# D√©finir la fonction de perte et l'optimiseur\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "# Historique des m√©triques\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'epoch_times': []\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"D√âBUT DE L'ENTRA√éNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # ===== PHASE D'ENTRA√éNEMENT =====\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_batches = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} [Train]\")\n",
    "    for batch_x, batch_y in pbar:\n",
    "        batch_x = batch_x.to(CONFIG['device'])\n",
    "        batch_y = batch_y.to(CONFIG['device'])\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_batches += 1\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    avg_train_loss = train_loss / train_batches\n",
    "    \n",
    "    # ===== PHASE DE VALIDATION =====\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} [Val]\")\n",
    "        for batch_x, batch_y in pbar:\n",
    "            batch_x = batch_x.to(CONFIG['device'])\n",
    "            batch_y = batch_y.to(CONFIG['device'])\n",
    "            \n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            val_batches += 1\n",
    "            \n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "    \n",
    "    avg_val_loss = val_loss / val_batches\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Enregistrer l'historique\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['epoch_times'].append(epoch_time)\n",
    "    \n",
    "    # Afficher les r√©sultats de l'√©poque\n",
    "    print(f\"\\n√âpoque {epoch+1}/{CONFIG['epochs']}:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.6f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.6f}\")\n",
    "    print(f\"  Temps:      {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Sauvegarder le meilleur mod√®le\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        checkpoint_path = os.path.join(CKPT_DIR, 'best_model.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  ‚úÖ Meilleur mod√®le sauvegard√©! (Val Loss: {best_val_loss:.6f})\")\n",
    "    \n",
    "    # Sauvegarder p√©riodiquement\n",
    "    if (epoch + 1) % CONFIG['save_interval'] == 0:\n",
    "        checkpoint_path = os.path.join(CKPT_DIR, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  üíæ Checkpoint sauvegard√©: checkpoint_epoch_{epoch+1}.pt\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ENTRA√éNEMENT TERMIN√â\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Meilleure Val Loss: {best_val_loss:.6f}\")\n",
    "print(f\"Temps total: {sum(history['epoch_times']):.1f}s ({sum(history['epoch_times'])/60:.1f} min)\")\n",
    "print(f\"Temps moyen par √©poque: {sum(history['epoch_times'])/len(history['epoch_times']):.1f}s\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e36e7",
   "metadata": {},
   "source": [
    "## 12. Visualisation des courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cr√©er le graphique des pertes\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Subplot 1: Train vs Val Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = range(1, len(history['train_loss']) + 1)\n",
    "plt.plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "plt.plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Courbes d\\'apprentissage')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Temps par √©poque\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, history['epoch_times'], 'g-', linewidth=2)\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('Temps (secondes)')\n",
    "plt.title('Temps d\\'entra√Ænement par √©poque')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher quelques statistiques\n",
    "print(\"=\" * 60)\n",
    "print(\"STATISTIQUES D'ENTRA√éNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Loss finale (Train): {history['train_loss'][-1]:.6f}\")\n",
    "print(f\"Loss finale (Val):   {history['val_loss'][-1]:.6f}\")\n",
    "print(f\"Meilleure Val Loss:  {min(history['val_loss']):.6f} (√âpoque {history['val_loss'].index(min(history['val_loss']))+1})\")\n",
    "print(f\"√âcart Train/Val:     {abs(history['train_loss'][-1] - history['val_loss'][-1]):.6f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd244",
   "metadata": {
    "id": "c4bfd244"
   },
   "source": [
    "## 13. Test du mod√®le sur des positions de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0315c06",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 603,
     "status": "error",
     "timestamp": 1763306887205,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "b0315c06",
    "outputId": "63c41d8e-71b2-4beb-a230-c23c68bb3988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST SUR 10 POSITIONS AL√âATOIRES\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1872553247.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# Passer le mod√®le en mode √©valuation\n",
    "model.eval()\n",
    "\n",
    "# Tester sur quelques positions de validation\n",
    "num_tests = 10\n",
    "test_indices = np.random.choice(len(X_val), min(num_tests, len(X_val)), replace=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TEST SUR {len(test_indices)} POSITIONS DE VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(test_indices, 1):\n",
    "        x = torch.FloatTensor(X_val[idx:idx+1]).to(CONFIG['device'])\n",
    "        y_true = y_val[idx]\n",
    "        y_pred = model(x).cpu().numpy()[0, 0]\n",
    "        error = abs(y_true - y_pred)\n",
    "        errors.append(error)\n",
    "\n",
    "        print(f\"\\nPosition {i}:\")\n",
    "        print(f\"  √âvaluation r√©elle:  {y_true:+8.4f}\")\n",
    "        print(f\"  Pr√©diction mod√®le:  {y_pred:+8.4f}\")\n",
    "        print(f\"  Erreur absolue:     {error:8.4f}\")\n",
    "\n",
    "        # Indicateur visuel de la qualit√©\n",
    "        if error < 0.1:\n",
    "            print(f\"  Qualit√©: ‚úÖ Excellente\")\n",
    "        elif error < 0.3:\n",
    "            print(f\"  Qualit√©: ‚úì Bonne\")\n",
    "        elif error < 0.5:\n",
    "            print(f\"  Qualit√©: ‚ö† Moyenne\")\n",
    "        else:\n",
    "            print(f\"  Qualit√©: ‚ùå Faible\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DES TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Erreur moyenne: {np.mean(errors):.4f}\")\n",
    "print(f\"Erreur m√©diane: {np.median(errors):.4f}\")\n",
    "print(f\"Erreur min:     {np.min(errors):.4f}\")\n",
    "print(f\"Erreur max:     {np.max(errors):.4f}\")\n",
    "print(f\"√âcart-type:     {np.std(errors):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
