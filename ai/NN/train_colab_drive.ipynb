{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b5a4df",
   "metadata": {
    "id": "12b5a4df"
   },
   "source": [
    "# Entraînement du Neural Network pour Smart Chess sur Google Colab\n",
    "\n",
    "Ce notebook permet d'entraîner le réseau de neurones pour l'évaluation d'échecs en utilisant les ressources GPU de Google Colab.\n",
    "\n",
    "**Chemin du projet sur Drive:** `MyDrive/smart_chess_drive/smart-chess`\n",
    "\n",
    "## Instructions\n",
    "1. Aller dans **Runtime > Change runtime type > GPU** (T4 ou mieux)\n",
    "2. Exécuter les cellules dans l'ordre\n",
    "3. Les modèles seront sauvegardés automatiquement sur votre Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b4590",
   "metadata": {
    "id": "de1b4590"
   },
   "source": [
    "## 1. Vérification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e0dc5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1761571039663,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "8d5e0dc5",
    "outputId": "6d42087b-a9cb-4fd6-9554-468bb8ce71ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 27 13:17:19 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Vérifier la disponibilité du GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddd742",
   "metadata": {
    "id": "89ddd742"
   },
   "source": [
    "## 2. Montage Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e4f04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18520,
     "status": "ok",
     "timestamp": 1761572617333,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "ce5e4f04",
    "outputId": "aa8dc79e-61d1-4a93-84b7-649f1b40ec16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Monter Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccf2990",
   "metadata": {
    "id": "1ccf2990"
   },
   "source": [
    "## 3. Configuration du chemin du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb986a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1761572621857,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "fabb986a",
    "outputId": "87e34ea8-771b-48bb-859b-195d895d3534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n",
      "\n",
      "Contenu du répertoire:\n",
      "  - .git\n",
      "  - .gitignore\n",
      "  - README.md\n",
      "  - ai\n",
      "  - docs\n",
      "  - prototypes\n"
     ]
    }
   ],
   "source": [
    "# Définir le chemin vers le projet sur votre Drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "os.chdir(PROJECT_PATH)\n",
    "sys.path.insert(0, PROJECT_PATH)\n",
    "\n",
    "print(f\"Répertoire de travail: {os.getcwd()}\")\n",
    "print(f\"\\nContenu du répertoire:\")\n",
    "for item in sorted(os.listdir('.')):\n",
    "    print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20e36c",
   "metadata": {
    "id": "3f20e36c"
   },
   "source": [
    "## 4. Installation des dépendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783beaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11360,
     "status": "ok",
     "timestamp": 1761572636808,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "7783beaf",
    "outputId": "b44e4c2a-6aa2-46a6-c8b1-f81a9d616a51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Installation terminée\n"
     ]
    }
   ],
   "source": [
    "# Installer les packages nécessaires\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy matplotlib tqdm\n",
    "\n",
    "print(\"✓ Installation terminée\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25365688",
   "metadata": {
    "id": "25365688"
   },
   "source": [
    "## 5. Vérification de l'environnement PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e678b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5047,
     "status": "ok",
     "timestamp": 1761572646437,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "a76e678b",
    "outputId": "bc113e8b-6a04-4a86-dd6a-fa69f71c0b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION SYSTÈME\n",
      "============================================================\n",
      "PyTorch version: 2.8.0+cu126\n",
      "NumPy version: 2.0.2\n",
      "\n",
      "CUDA disponible: True\n",
      "CUDA version: 12.6\n",
      "Nom du GPU: Tesla T4\n",
      "Mémoire GPU totale: 15.83 GB\n",
      "Compute Capability: 7.5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION SYSTÈME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"\\nCUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Nom du GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"Mémoire GPU totale: {props.total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "else:\n",
    "    print(\"⚠️ ATTENTION: GPU non disponible, l'entraînement sera très lent!\")\n",
    "    print(\"   Allez dans Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91a1e23",
   "metadata": {
    "id": "f91a1e23"
   },
   "source": [
    "## 6. Import des modules du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7397821",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761573675504,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "c7397821",
    "outputId": "68a09eb3-6a2d-42f1-bdf9-506c0b23668e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répertoire de travail: /content/drive/MyDrive/smart_chess_drive/smart-chess\n",
      "\n",
      "Quelques fichiers à la racine du projet:\n",
      "['.git', '.gitignore', 'README.md', 'ai', 'docs', 'prototypes']\n",
      "\n",
      "Contenu du dossier ai/:\n",
      "['AI_reduction', 'Chess.py', 'ChessInteractifv2.py', 'Chess_v2.py', 'NN', 'Null_move_AI', 'Old_AI', 'Player.py', 'Profile', 'Tests.py', '__init__.py', '__pycache__', 'alphabeta.py', 'alphabeta_engine.py', 'alphabeta_engine_v2.py', 'analyze_reduction_overhead.py', 'base_engine.py', 'check_dataset_stats.py', 'check_gpu.py', 'check_performance.py', 'chess_model_checkpoint.pt', 'debug_conversion.py', 'engine_match.py', 'evaluator.py', 'example_move_reduction.py', 'fast_evaluator.py', 'journal-experiments.md', 'optimized_chess.py', 'profile_report_1760344602.txt', 'test_depth_6_performance.py', 'test_depth_6_quick.py', 'test_depth_effectiveness.py', 'test_engines_v2.py', 'test_evaluator_performance.py', 'test_generalization.py', 'test_move_reduction.py', 'test_null_move.py', 'test_null_move_comparison.py', 'test_null_move_effectiveness.py', 'test_null_move_final.py', 'test_null_move_optimization.py', 'test_null_move_quick.py', 'test_timeout_fix.py', 'visualize_sampling.py']\n",
      "\n",
      "✅ Import direct `Chess` OK (module trouvé via sys.path)\n",
      "\n",
      "✓ Modules importés avec succès!\n"
     ]
    }
   ],
   "source": [
    "# Importer les modules nécessaires depuis le projet (robuste à l'emplacement du repo sur Drive)\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Assurez-vous que PROJECT_PATH est défini et ajoutez également le dossier `ai` au PYTHONPATH\n",
    "PROJECT_PATH = '/content/drive/MyDrive/smart_chess_drive/smart-chess'\n",
    "AI_SUBDIR = os.path.join(PROJECT_PATH, 'ai')\n",
    "\n",
    "# Vérifier les chemins alternatifs (si l'utilisateur a copié le repo dans /content)\n",
    "ALT_PATH = '/content/smart-chess'\n",
    "\n",
    "# Choisir un chemin existant\n",
    "if not os.path.isdir(PROJECT_PATH) and os.path.isdir(ALT_PATH):\n",
    "    PROJECT_PATH = ALT_PATH\n",
    "\n",
    "if not os.path.isdir(PROJECT_PATH):\n",
    "    raise FileNotFoundError(f\"Répertoire projet introuvable: {PROJECT_PATH}. Montez Drive et vérifiez le chemin.\")\n",
    "\n",
    "# Ajouter au sys.path si nécessaire\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_PATH)\n",
    "if AI_SUBDIR not in sys.path and os.path.isdir(AI_SUBDIR):\n",
    "    sys.path.insert(0, AI_SUBDIR)\n",
    "\n",
    "# Se placer dans le répertoire projet\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "print('Répertoire de travail:', os.getcwd())\n",
    "print('\\nQuelques fichiers à la racine du projet:')\n",
    "print(sorted(os.listdir(PROJECT_PATH))[:50])\n",
    "print('\\nContenu du dossier ai/:')\n",
    "print(sorted(os.listdir(AI_SUBDIR))[:100])\n",
    "\n",
    "# Diagnostic d'import direct pour le module Chess\n",
    "try:\n",
    "    import Chess\n",
    "    print('\\n✅ Import direct `Chess` OK (module trouvé via sys.path)')\n",
    "except Exception as e:\n",
    "    print('\\n❌ Import direct `Chess` a échoué:', e)\n",
    "    print('Vérifiez que `ai/Chess.py` existe et que le dossier ai/ est dans sys.path')\n",
    "\n",
    "# Maintenant importer le module d'entraînement (trainer)\n",
    "try:\n",
    "    import ai.NN.train_torch as trainer\n",
    "    import ai.NN.torch_nn_evaluator as torch_eval\n",
    "    from ai.Chess_v2 import Chess\n",
    "    print('\\n✓ Modules importés avec succès!')\n",
    "except Exception as e:\n",
    "    print('\\n❌ Erreur d\\'import lors de l\\'import du trainer:', e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e668793",
   "metadata": {
    "id": "0e668793"
   },
   "source": [
    "## 7. Configuration de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f87f8d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761572886153,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "c9f87f8d",
    "outputId": "d1f32ea2-f703-461e-c816-0736662b9adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION DE L'ENTRAÎNEMENT\n",
      "============================================================\n",
      "num_games           : 10000\n",
      "batch_size          : 256\n",
      "epochs              : 50\n",
      "learning_rate       : 0.001\n",
      "device              : cuda\n",
      "num_workers         : 2\n",
      "checkpoint_path     : ai/chess_model_checkpoint.pt\n",
      "save_interval       : 5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Paramètres d'entraînement\n",
    "CONFIG = {\n",
    "    # Génération de données\n",
    "    'num_games': 10000,          # Nombre de parties à générer pour l'entraînement\n",
    "\n",
    "    # Hyperparamètres\n",
    "    'batch_size': 256,           # Taille du batch (augmenter si GPU puissant)\n",
    "    'epochs': 50,                # Nombre d'époques d'entraînement\n",
    "    'learning_rate': 0.001,      # Taux d'apprentissage\n",
    "\n",
    "    # Configuration système\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 2,            # Workers pour le DataLoader\n",
    "\n",
    "    # Sauvegarde\n",
    "    'checkpoint_path': 'ai/chess_model_checkpoint.pt',\n",
    "    'save_interval': 5,          # Sauvegarder tous les N époques\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION DE L'ENTRAÎNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    print(\"\\n⚠️ ATTENTION: Entraînement sur CPU détecté!\")\n",
    "    print(\"   Réduisez num_games et epochs pour un test rapide.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ad90f",
   "metadata": {
    "id": "f72ad90f"
   },
   "source": [
    "## 8. Génération des données d'entraînement\n",
    "\n",
    "Cette étape génère des parties d'échecs aléatoires et calcule les évaluations de position.\n",
    "**Attention:** Cela peut prendre 15-30 minutes selon le nombre de parties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504f1e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23864,
     "status": "ok",
     "timestamp": 1761574079676,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "4504f1e6",
    "outputId": "760ae98f-f7dc-4b4f-c367-7ffbac9162e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataset (depuis chessData)...\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "============================================================\n",
      "DONNÉES CHARGÉES\n",
      "============================================================\n",
      "Nombre total de positions: 12,767,881\n",
      "Temps écoulé: 23.8s (0.4 min)\n",
      "============================================================\n",
      "\n",
      "Statistiques sur les évaluations:\n",
      "  Min: -15.3120\n",
      "  Max: 15.3190\n",
      "  Moyenne: 0.0455\n",
      "  Écart-type: 0.8139\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Chargement du dataset (depuis chessData)...\")\n",
    "\n",
    "# Préférer la variable DATASET_CSV (définie après le montage Drive) sinon utiliser la valeur par défaut du module trainer\n",
    "dataset_path = globals().get('DATASET_CSV') # Use the DATASET_CSV variable directly\n",
    "\n",
    "if dataset_path is None:\n",
    "    raise FileNotFoundError('Aucun chemin de dataset défini. Montez Drive et placez le fichier CSV dans MyDrive/smart_chess_drive/chessData')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Utiliser la fonction de chargement du script d'entraînement pour assurer le même prétraitement\n",
    "fens, evaluations = trainer.load_data(dataset_path) # Pass the dataset_path explicitly\n",
    "\n",
    "# Variables attendues plus bas dans le notebook\n",
    "X_train = fens\n",
    "y_train = evaluations\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DONNÉES CHARGÉES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Nombre total de positions: {len(X_train):,}\")\n",
    "print(f\"Temps écoulé: {elapsed_time:.1f}s ({elapsed_time/60:.1f} min)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Statistiques sur les évaluations\n",
    "print(f\"\\nStatistiques sur les évaluations:\")\n",
    "print(f\"  Min: {y_train.min():.4f}\")\n",
    "print(f\"  Max: {y_train.max():.4f}\")\n",
    "print(f\"  Moyenne: {y_train.mean():.4f}\")\n",
    "print(f\"  Écart-type: {y_train.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc365442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1761574090445,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "cc365442",
    "outputId": "e1333497-be02-43ac-fad9-35e4ad03b34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source code of trainer.load_data:\n",
      "============================================================\n",
      "def load_data(filepath: str):\n",
      "    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n",
      "    print(f\"📂 Chargement du dataset depuis {filepath}...\")\n",
      "    \n",
      "    df = pd.read_csv(\n",
      "        filepath, \n",
      "        names=['FEN', 'Evaluation'], \n",
      "        skiprows=1,\n",
      "        comment='#'\n",
      "    )\n",
      "    \n",
      "    initial_count = len(df)\n",
      "    df.dropna(inplace=True)\n",
      "    cleaned_count = len(df)\n",
      "    \n",
      "    if initial_count > cleaned_count:\n",
      "        print(f\"🧹 Nettoyage : {initial_count - cleaned_count} lignes corrompues supprimées.\")\n",
      "    \n",
      "    fens = df['FEN'].values\n",
      "    EVAL_SCALE_FACTOR = 1000.0\n",
      "    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n",
      "    \n",
      "    print(f\"✅ {len(fens):,} positions valides chargées.\")\n",
      "    return fens, evaluations\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import ai.NN.train_torch as trainer\n",
    "\n",
    "try:\n",
    "    # Get the source code of the load_data function\n",
    "    source_code = inspect.getsource(trainer.load_data)\n",
    "    print(\"Source code of trainer.load_data:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(source_code)\n",
    "    print(\"=\" * 60)\n",
    "except TypeError:\n",
    "    print(\"Could not get source code for trainer.load_data. It might not be a function defined in the file.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Could not find the train_torch.py file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to get source code: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b3c66b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761574094547,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "e0b3c66b",
    "outputId": "3f6d4524-6aa9-413c-dc57-74c01c0841d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the function definition 'def load_data():' in /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py. Please inspect the file manually.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Assuming the load_data function signature is currently load_data():\n",
    "# We need to find the function definition and modify it to accept dataset_path\n",
    "# This is a simple string replacement and might need adjustment based on the actual code\n",
    "old_def = 'def load_data():'\n",
    "new_def = 'def load_data(dataset_path):'\n",
    "old_data_loading_line = \"df = pd.read_csv('C:\\\\\\\\Users\\\\\\\\gauti\\\\\\\\OneDrive\\\\\\\\Documents\\\\\\\\UE commande\\\\\\\\chessData.csv')\" # This is a guess, may need adjustment\n",
    "new_data_loading_line = \"df = pd.read_csv(dataset_path)\"\n",
    "\n",
    "\n",
    "if old_def in content and old_data_loading_line in content:\n",
    "    content = content.replace(old_def, new_def)\n",
    "    content = content.replace(old_data_loading_line, new_data_loading_line)\n",
    "    # Write the modified content back to the file\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    print(f\"Successfully modified {file_path} to accept and use dataset_path in load_data function.\")\n",
    "elif old_def in content:\n",
    "     print(f\"Found function definition '{old_def}', but could not find the specific data loading line '{old_data_loading_line}' to replace.\")\n",
    "     print(\"Please inspect the `load_data` function in `ai/NN/train_torch.py` and manually update the file path to use the `dataset_path` argument.\")\n",
    "else:\n",
    "    print(f\"Could not find the function definition '{old_def}' in {file_path}. Please inspect the file manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea4dd7",
   "metadata": {
    "id": "fdea4dd7"
   },
   "source": [
    "## 9. Création du dataset et du dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c45e62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1761574097494,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "d0c45e62",
    "outputId": "5b552671-cca9-4397-cd97-c614f3d00d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATALOADER CONFIGURÉ\n",
      "============================================================\n",
      "Taille du dataset: 12,767,881 échantillons\n",
      "Nombre de batches: 49,875\n",
      "Taille du batch: 256\n",
      "Dernière batch: 137 échantillons\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from ai.NN.train_torch import ChessDataset # Import ChessDataset\n",
    "\n",
    "# Créer le dataset\n",
    "dataset = ChessDataset(X_train, y_train)\n",
    "\n",
    "# Créer le dataloader\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if CONFIG['device'] == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATALOADER CONFIGURÉ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Taille du dataset: {len(dataset):,} échantillons\")\n",
    "print(f\"Nombre de batches: {len(train_loader):,}\")\n",
    "print(f\"Taille du batch: {CONFIG['batch_size']}\")\n",
    "print(f\"Dernière batch: {len(dataset) % CONFIG['batch_size']} échantillons\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05dda22",
   "metadata": {
    "id": "f05dda22"
   },
   "source": [
    "## 10. Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d2b3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1761574170502,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "056d2b3a",
    "outputId": "0aaaf6ff-fb3d-4b43-fcad-32111e39dc41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ARCHITECTURE DU MODÈLE\n",
      "============================================================\n",
      "TorchNNEvaluator(\n",
      "  (l1): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (l2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (l3): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (leaky_relu): LeakyReLU(negative_slope=0.01)\n",
      ")\n",
      "============================================================\n",
      "\n",
      "Nombre total de paramètres: 262,913\n",
      "Paramètres entraînables: 262,913\n",
      "Device: cuda\n",
      "Taille estimée du modèle: 1.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Créer le modèle et le déplacer sur le device approprié\n",
    "from ai.NN.torch_nn_evaluator import TorchNNEvaluator # Import TorchNNEvaluator from torch_nn_evaluator\n",
    "\n",
    "model = TorchNNEvaluator().to(CONFIG['device'])\n",
    "\n",
    "# Afficher l'architecture\n",
    "print(\"=\" * 60)\n",
    "print(\"ARCHITECTURE DU MODÈLE\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Compter les paramètres\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nNombre total de paramètres: {total_params:,}\")\n",
    "print(f\"Paramètres entraînables: {trainable_params:,}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "\n",
    "# Estimer la taille mémoire du modèle\n",
    "param_size_mb = total_params * 4 / (1024 ** 2)  # 4 bytes par float32\n",
    "print(f\"Taille estimée du modèle: {param_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc571c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1761574157413,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "22bc571c",
    "outputId": "0cd6d96b-ef10-4f2f-f6eb-0bf9d5ba6716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/torch_nn_evaluator.py:\n",
      "============================================================\n",
      "import numpy as np\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "from Chess import Chess\n",
      "\n",
      "\n",
      "class TorchNNEvaluator(nn.Module):\n",
      "    \"\"\"PyTorch implementation équivalente du `NeuralNetworkEvaluator` en NumPy.\n",
      "\n",
      "    - architecture: Linear(input -> hidden) -> LeakyReLU -> Dropout -> Linear(hidden -> hidden) -> LeakyReLU -> Dropout -> Linear(hidden -> out)\n",
      "    - fournit des helpers pour charger/sauver au format .npz (compatibilité avec l'ancien code NumPy)\n",
      "    - fournit des helpers pour checkpoint/restore PyTorch (optimizer.state_dict)\n",
      "    - Support GPU automatique\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, input_size=768, hidden_size=256, output_size=1, dropout=0.3, leaky_alpha=0.01):\n",
      "        super().__init__()\n",
      "        self.l1 = nn.Linear(input_size, hidden_size)\n",
      "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
      "        self.l3 = nn.Linear(hidden_size, output_size)\n",
      "        self.dropout1 = nn.Dropout(p=dropout)\n",
      "        self.dropout2 = nn.Dropout(p=dropout)\n",
      "        self.leaky_relu = nn.LeakyReLU(negative_slope=leaky_alpha)\n",
      "\n",
      "        self.piece_to_index = {\n",
      "            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
      "            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
      "        }\n",
      "        self.input_size = input_size\n",
      "\n",
      "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
      "        x = self.leaky_relu(self.l1(x))\n",
      "        x = self.dropout1(x)\n",
      "        x = self.leaky_relu(self.l2(x))\n",
      "        x = self.dropout2(x)\n",
      "        return self.l3(x)\n",
      "\n",
      "    def encode_board(self, chess_instance: Chess, device='cpu') -> torch.Tensor:\n",
      "        vec = np.zeros(self.input_size, dtype=np.float32)\n",
      "        for piece_char, bitboard in chess_instance.bitboards.items():\n",
      "            if bitboard == 0:\n",
      "                continue\n",
      "            piece_index = self.piece_to_index[piece_char]\n",
      "            temp_bb = int(bitboard)\n",
      "            while temp_bb:\n",
      "                square = (temp_bb & -temp_bb).bit_length() - 1\n",
      "                vector_position = piece_index * 64 + square\n",
      "                vec[vector_position] = 1.0\n",
      "                temp_bb &= temp_bb - 1\n",
      "        t = torch.from_numpy(vec).to(torch.float32).to(device)\n",
      "        return t.unsqueeze(0)  # shape (1, input_size)\n",
      "\n",
      "    def evaluate_position(self, chess_instance: Chess, device='cpu') -> float:\n",
      "        x = self.encode_board(chess_instance, device=device)\n",
      "        self.to(device)\n",
      "        self.eval()\n",
      "        with torch.no_grad():\n",
      "            out = self.forward(x)\n",
      "        normalized_score = out[0, 0].item()\n",
      "        EVAL_SCALE_FACTOR = 1000.0\n",
      "        return normalized_score * EVAL_SCALE_FACTOR\n",
      "\n",
      "\n",
      "def save_weights_npz(model: TorchNNEvaluator, filename: str, adam_moments: dict = None):\n",
      "    \"\"\"Sauvegarde les poids du modèle dans un .npz compatible avec l'ancien format NumPy.\n",
      "\n",
      "    Le format correspond aux clés attendues par `nn_evaluator.load_evaluator_from_file` :\n",
      "    - w1: shape (input, hidden)\n",
      "    - b1: shape (1, hidden)\n",
      "    - w2, b2, w3, b3\n",
      "    On convertit les poids PyTorch (weight shape: out, in) en (in, out).\n",
      "    \"\"\"\n",
      "    sd = model.state_dict()\n",
      "    save_dict = {\n",
      "        'w1': sd['l1.weight'].cpu().numpy().T,\n",
      "        'b1': sd['l1.bias'].cpu().numpy().reshape(1, -1),\n",
      "        'w2': sd['l2.weight'].cpu().numpy().T,\n",
      "        'b2': sd['l2.bias'].cpu().numpy().reshape(1, -1),\n",
      "        'w3': sd['l3.weight'].cpu().numpy().T,\n",
      "        'b3': sd['l3.bias'].cpu().numpy().reshape(1, -1),\n",
      "    }\n",
      "    if adam_moments is not None:\n",
      "        # ensure numpy arrays\n",
      "        for k, v in dict(adam_moments).items():\n",
      "            save_dict[k] = np.array(v)\n",
      "\n",
      "    np.savez(filename, **save_dict)\n",
      "    if adam_moments is not None:\n",
      "        print(f\"Poids et moments Adam sauvegardés (npz) dans {filename}\")\n",
      "    else:\n",
      "        print(f\"Poids sauvegardés (npz) dans {filename}\")\n",
      "\n",
      "\n",
      "def load_from_npz(filename: str, device='cpu'):\n",
      "    \"\"\"Charge un .npz produit par la version NumPy et renvoie (model, adam_moments)\n",
      "\n",
      "    - adam_moments (si présent) est renvoyé sous forme de dict de tensors (torch.float32)\n",
      "    - si les moments Adam ne sont pas tous présents, on renvoie None pour adam_moments\n",
      "    \"\"\"\n",
      "    data = np.load(filename)\n",
      "    # infer sizes\n",
      "    w1 = data['w1']\n",
      "    b1 = data['b1']\n",
      "    w2 = data['w2']\n",
      "    b2 = data['b2']\n",
      "    w3 = data['w3']\n",
      "    b3 = data['b3']\n",
      "    input_size = int(w1.shape[0])\n",
      "    hidden_size = int(w1.shape[1])\n",
      "    output_size = int(w3.shape[1]) if w3.ndim == 2 else 1\n",
      "\n",
      "    model = TorchNNEvaluator(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
      "    # copy weights (transpose to torch linear layout)\n",
      "    model.l1.weight.data.copy_(torch.from_numpy(w1.T).to(torch.float32))\n",
      "    model.l1.bias.data.copy_(torch.from_numpy(b1.reshape(-1)).to(torch.float32))\n",
      "    model.l2.weight.data.copy_(torch.from_numpy(w2.T).to(torch.float32))\n",
      "    model.l2.bias.data.copy_(torch.from_numpy(b2.reshape(-1)).to(torch.float32))\n",
      "    model.l3.weight.data.copy_(torch.from_numpy(w3.T).to(torch.float32))\n",
      "    model.l3.bias.data.copy_(torch.from_numpy(b3.reshape(-1)).to(torch.float32))\n",
      "\n",
      "    # collect adam moments if all present\n",
      "    adam_moments = None\n",
      "    adam_keys = ['m_w1', 'v_w1', 'm_b1', 'v_b1', 'm_w2', 'v_w2',\n",
      "                 'm_b2', 'v_b2', 'm_w3', 'v_w3', 'm_b3', 'v_b3', 'adam_step']\n",
      "    if all(key in data for key in adam_keys):\n",
      "        adam_moments = {}\n",
      "        for k in adam_keys:\n",
      "            val = data[k]\n",
      "            # convert scalar 0-d to Python int for adam_step\n",
      "            if k == 'adam_step':\n",
      "                adam_moments[k] = int(val)\n",
      "            else:\n",
      "                adam_moments[k] = torch.from_numpy(np.array(val)).to(torch.float32)\n",
      "\n",
      "    model.to(device)\n",
      "    return model, adam_moments\n",
      "\n",
      "\n",
      "def torch_save_checkpoint(path: str, model: TorchNNEvaluator, optimizer=None, step: int = None):\n",
      "    ckpt = {'model': model.state_dict()}\n",
      "    if optimizer is not None:\n",
      "        ckpt['optim'] = optimizer.state_dict()\n",
      "    if step is not None:\n",
      "        ckpt['step'] = int(step)\n",
      "    torch.save(ckpt, path)\n",
      "    print(f\"Checkpoint PyTorch sauvegardé dans {path}\")\n",
      "\n",
      "\n",
      "def torch_load_checkpoint(path: str, model: TorchNNEvaluator = None, optimizer=None, device='cpu'):\n",
      "    ckpt = torch.load(path, map_location=device)\n",
      "    if model is not None:\n",
      "        model.load_state_dict(ckpt['model'])\n",
      "        model.to(device)\n",
      "    optim_state = ckpt.get('optim')\n",
      "    if optimizer is not None and optim_state is not None:\n",
      "        optimizer.load_state_dict(optim_state)\n",
      "    step = ckpt.get('step')\n",
      "    return model, optim_state, step\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    # Exemple d'utilisation similaire au fichier NumPy original\n",
      "    WEIGHTS_FILE = 'chess_nn_weights_from_torch.npz'\n",
      "    game = Chess()\n",
      "\n",
      "    print('--- Création d un réseau PyTorch non entraîné ---')\n",
      "    model = TorchNNEvaluator(input_size=768, hidden_size=256, output_size=1)\n",
      "    # évaluation cpu\n",
      "    score1 = model.evaluate_position(game)\n",
      "    print(f'Score du réseau PyTorch vierge : {score1:.2f}')\n",
      "\n",
      "    # sauvegarde en .npz (pour compatibilité)\n",
      "    save_weights_npz(model, WEIGHTS_FILE)\n",
      "\n",
      "    # rechargement depuis .npz\n",
      "    print(f\"\\n--- Chargement du réseau depuis le fichier '{WEIGHTS_FILE}' ---\")\n",
      "    loaded_model, adam_moms = load_from_npz(WEIGHTS_FILE)\n",
      "    score2 = loaded_model.evaluate_position(game)\n",
      "    print(f\"Score du réseau chargé : {score2:.2f}\")\n",
      "    if adam_moms is not None:\n",
      "        print(f\"Moments Adam chargés (step={adam_moms['adam_step']})\")\n",
      "    # la valeur peut légèrement différer en float32 mais doit être proche\n",
      "    try:\n",
      "        assert abs(score1 - score2) < 1e-3\n",
      "    except AssertionError:\n",
      "        print('Attention: score initial et score chargé diffèrent; vérifie dtypes/precision')\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/torch_nn_evaluator.py')\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"Content of {file_path}:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(content)\n",
    "    print(\"=\" * 60)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ba4a7",
   "metadata": {
    "id": "aa1ba4a7"
   },
   "source": [
    "## 11. Entraînement du modèle\n",
    "\n",
    "Cette étape lance l'entraînement complet. Les checkpoints sont sauvegardés automatiquement sur votre Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee49f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761574281406,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "54ee49f6",
    "outputId": "fc94458f-3b70-45ec-c903-a7d1ca17e9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training process is handled by calling trainer.main() in cell 9887d4b8.\n",
      "Please run cell 9887d4b8 to start the training.\n"
     ]
    }
   ],
   "source": [
    "# This cell is no longer needed as trainer.main() handles the training loop.\n",
    "# The training will be started by running cell 9887d4b8.\n",
    "# You can keep this cell as a placeholder or delete it if you prefer.\n",
    "# The training history will be available after trainer.main() completes if the script returns it or saves it.\n",
    "\n",
    "print(\"The training process is handled by calling trainer.main() in cell 9887d4b8.\")\n",
    "print(\"Please run cell 9887d4b8 to start the training.\")\n",
    "\n",
    "# Keep the history variable assignment as a placeholder if the script returns it\n",
    "# history = None # Or whatever trainer.main() might return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9399818c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1761574296277,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "9399818c",
    "outputId": "db08d410-4a1d-4512-accb-b3e7988f48bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully removed 'verbose=True' from ReduceLROnPlateau in /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # Remove the verbose=True argument from ReduceLROnPlateau\n",
    "    old_scheduler_init = \"patience=LR_PATIENCE, verbose=True\"\n",
    "    new_scheduler_init = \"patience=LR_PATIENCE\" # Remove verbose argument\n",
    "\n",
    "    if old_scheduler_init in content:\n",
    "        content = content.replace(old_scheduler_init, new_scheduler_init)\n",
    "        # Write the modified content back to the file\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Successfully removed 'verbose=True' from ReduceLROnPlateau in {file_path}.\")\n",
    "    else:\n",
    "        print(f\"'verbose=True' not found in ReduceLROnPlateau initialization in {file_path}. No changes made.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while trying to modify the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ce84b",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1761574238241,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "a04ce84b",
    "outputId": "b73f017a-7e01-4f5b-db53-9b3aa3eb0ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py:\n",
      "============================================================\n",
      "\"\"\"\n",
      "Script d'entraînement PyTorch optimisé pour GPU\n",
      "Compatible avec Google Colab et machines locales avec GPU\n",
      "\"\"\"\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "from tqdm import tqdm\n",
      "import os\n",
      "\n",
      "from Chess import Chess\n",
      "from ai.NN.torch_nn_evaluator import TorchNNEvaluator, save_weights_npz, load_from_npz, torch_save_checkpoint, torch_load_checkpoint\n",
      "\n",
      "# --- CONFIGURATION DE L'ENTRAÎNEMENT ---\n",
      "DATASET_PATH = \"C:\\\\Users\\\\gauti\\\\OneDrive\\\\Documents\\\\UE commande\\\\chessData.csv\"  # Adapté pour Colab (fichier à la racine)\n",
      "WEIGHTS_FILE = \"chess_nn_weights.npz\"\n",
      "CHECKPOINT_FILE = \"chess_model_checkpoint.pt\"\n",
      "\n",
      "# Architecture\n",
      "HIDDEN_SIZE = 256\n",
      "DROPOUT = 0.3\n",
      "LEAKY_ALPHA = 0.01\n",
      "\n",
      "# Hyperparamètres\n",
      "LEARNING_RATE = 0.001\n",
      "WEIGHT_DECAY = 1e-4  # L2 regularization (AdamW)\n",
      "EPOCHS = 20\n",
      "BATCH_SIZE = 128  # Plus grand pour GPU\n",
      "MAX_SAMPLES = 500_000  # Plus de données avec GPU !\n",
      "EVAL_MAX_SAMPLES = 5000\n",
      "\n",
      "# Options\n",
      "USE_SAMPLING = True\n",
      "RESET_WEIGHTS = False\n",
      "DEBUG_STATS = True\n",
      "\n",
      "# LR Scheduler\n",
      "USE_LR_SCHEDULER = True\n",
      "LR_PATIENCE = 2\n",
      "LR_FACTOR = 0.5\n",
      "\n",
      "# LR Warmup\n",
      "USE_LR_WARMUP = True\n",
      "WARMUP_EPOCHS = 3\n",
      "WARMUP_START_LR = 0.0001\n",
      "\n",
      "# Device (auto-détection GPU)\n",
      "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "print(f\"🖥️  Device: {DEVICE}\")\n",
      "if torch.cuda.is_available():\n",
      "    print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
      "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
      "\n",
      "\n",
      "class ChessDataset(Dataset):\n",
      "    \"\"\"Dataset PyTorch pour les positions d'échecs\"\"\"\n",
      "    def __init__(self, fens, evaluations):\n",
      "        self.fens = fens\n",
      "        self.evaluations = evaluations\n",
      "        self.chess = Chess()\n",
      "        \n",
      "        # Précalculer l'encodage pour accélérer (optionnel, consomme plus de RAM)\n",
      "        # self.encoded = [self._encode_fen(fen) for fen in tqdm(fens, desc=\"Encoding positions\")]\n",
      "        \n",
      "    def __len__(self):\n",
      "        return len(self.fens)\n",
      "    \n",
      "    def __getitem__(self, idx):\n",
      "        fen = self.fens[idx]\n",
      "        target = self.evaluations[idx]\n",
      "        \n",
      "        # Encoder la position\n",
      "        self.chess.load_fen(fen)\n",
      "        encoded = self._encode_board(self.chess)\n",
      "        \n",
      "        return torch.from_numpy(encoded).float(), torch.tensor([target], dtype=torch.float32)\n",
      "    \n",
      "    def _encode_board(self, chess_instance):\n",
      "        \"\"\"Encode le plateau en vecteur 768D (identique à nn_evaluator.py)\"\"\"\n",
      "        piece_to_index = {\n",
      "            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
      "            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
      "        }\n",
      "        vec = np.zeros(768, dtype=np.float32)\n",
      "        for piece_char, bitboard in chess_instance.bitboards.items():\n",
      "            if bitboard == 0:\n",
      "                continue\n",
      "            piece_index = piece_to_index[piece_char]\n",
      "            temp_bb = int(bitboard)\n",
      "            while temp_bb:\n",
      "                square = (temp_bb & -temp_bb).bit_length() - 1\n",
      "                vector_position = piece_index * 64 + square\n",
      "                vec[vector_position] = 1.0\n",
      "                temp_bb &= temp_bb - 1\n",
      "        return vec\n",
      "\n",
      "\n",
      "def load_data(filepath: str):\n",
      "    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n",
      "    print(f\"📂 Chargement du dataset depuis {filepath}...\")\n",
      "    \n",
      "    df = pd.read_csv(\n",
      "        filepath, \n",
      "        names=['FEN', 'Evaluation'], \n",
      "        skiprows=1,\n",
      "        comment='#'\n",
      "    )\n",
      "    \n",
      "    initial_count = len(df)\n",
      "    df.dropna(inplace=True)\n",
      "    cleaned_count = len(df)\n",
      "    \n",
      "    if initial_count > cleaned_count:\n",
      "        print(f\"🧹 Nettoyage : {initial_count - cleaned_count} lignes corrompues supprimées.\")\n",
      "    \n",
      "    fens = df['FEN'].values\n",
      "    EVAL_SCALE_FACTOR = 1000.0\n",
      "    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n",
      "    \n",
      "    print(f\"✅ {len(fens):,} positions valides chargées.\")\n",
      "    return fens, evaluations\n",
      "\n",
      "\n",
      "def evaluate_model(model, dataloader, device):\n",
      "    \"\"\"Évalue le modèle sur un dataset\"\"\"\n",
      "    model.eval()\n",
      "    predictions = []\n",
      "    targets = []\n",
      "    \n",
      "    with torch.no_grad():\n",
      "        for inputs, labels in dataloader:\n",
      "            inputs = inputs.to(device)\n",
      "            outputs = model(inputs)\n",
      "            predictions.extend(outputs.cpu().numpy().flatten())\n",
      "            targets.extend(labels.numpy().flatten())\n",
      "    \n",
      "    predictions = np.array(predictions)\n",
      "    targets = np.array(targets)\n",
      "    \n",
      "    rmse = float(np.sqrt(np.mean((predictions - targets) ** 2)))\n",
      "    mae = float(np.mean(np.abs(predictions - targets)))\n",
      "    corr = float(np.corrcoef(predictions, targets)[0, 1]) if len(predictions) > 1 else 0.0\n",
      "    \n",
      "    return rmse, mae, corr, predictions, targets\n",
      "\n",
      "\n",
      "def main():\n",
      "    # 1. Charger les données\n",
      "    all_fens, all_evaluations = load_data(DATASET_PATH)\n",
      "    \n",
      "    print(f\"\\n📊 Dataset complet: {len(all_fens):,} positions\")\n",
      "    \n",
      "    eval_mean = float(np.mean(all_evaluations))\n",
      "    \n",
      "    # 2. Initialiser le modèle\n",
      "    if RESET_WEIGHTS and os.path.exists(WEIGHTS_FILE):\n",
      "        print(f\"🗑️  Suppression des anciens poids: {WEIGHTS_FILE}\")\n",
      "        os.remove(WEIGHTS_FILE)\n",
      "    \n",
      "    if os.path.exists(CHECKPOINT_FILE):\n",
      "        print(f\"📥 Chargement du checkpoint PyTorch: {CHECKPOINT_FILE}\")\n",
      "        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
      "        model, _, start_step = torch_load_checkpoint(CHECKPOINT_FILE, model, optimizer, device=DEVICE)\n",
      "        print(f\"✅ Checkpoint chargé (step {start_step})\")\n",
      "    elif os.path.exists(WEIGHTS_FILE):\n",
      "        print(f\"📥 Chargement des poids NumPy: {WEIGHTS_FILE}\")\n",
      "        model, adam_moments = load_from_npz(WEIGHTS_FILE, device=DEVICE)\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
      "        # TODO: Restaurer les moments Adam si présents\n",
      "        print(f\"✅ Poids chargés depuis NumPy\")\n",
      "    else:\n",
      "        print(\"🆕 Création d'un nouveau réseau...\")\n",
      "        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n",
      "        # Initialisation He (PyTorch le fait déjà par défaut pour Linear + ReLU)\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
      "        \n",
      "        # Warm-start du biais de sortie\n",
      "        with torch.no_grad():\n",
      "            model.l3.bias[0] = eval_mean\n",
      "    \n",
      "    model.to(DEVICE)\n",
      "    \n",
      "    # 3. Configuration de l'entraînement\n",
      "    criterion = nn.MSELoss()\n",
      "    \n",
      "    # LR Scheduler\n",
      "    if USE_LR_SCHEDULER:\n",
      "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "            optimizer, mode='min', factor=LR_FACTOR, \n",
      "            patience=LR_PATIENCE, verbose=True\n",
      "        )\n",
      "    \n",
      "    print(f\"\\n{'='*70}\")\n",
      "    print(f\"Configuration:\")\n",
      "    print(f\"  Dataset complet: {len(all_fens):,} positions\")\n",
      "    print(f\"  Échantillon/epoch: {MAX_SAMPLES if USE_SAMPLING else len(all_fens):,} positions\")\n",
      "    print(f\"  Architecture: 768 → {HIDDEN_SIZE} → {HIDDEN_SIZE} → 1\")\n",
      "    print(f\"  Dropout: {DROPOUT}\")\n",
      "    print(f\"  LeakyReLU alpha: {LEAKY_ALPHA}\")\n",
      "    print(f\"  Learning rate: {LEARNING_RATE} (AdamW, weight decay: {WEIGHT_DECAY})\")\n",
      "    print(f\"  LR Warmup: {USE_LR_WARMUP} ({WARMUP_START_LR if USE_LR_WARMUP else 'N/A'} → {LEARNING_RATE})\")\n",
      "    print(f\"  LR Scheduler: {USE_LR_SCHEDULER} (patience: {LR_PATIENCE if USE_LR_SCHEDULER else 'N/A'})\")\n",
      "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
      "    print(f\"  Epochs: {EPOCHS}\")\n",
      "    print(f\"  Device: {DEVICE}\")\n",
      "    print(f\"{'='*70}\\n\")\n",
      "    \n",
      "    # 4. Boucle d'entraînement\n",
      "    best_rmse = float('inf')\n",
      "    \n",
      "    for epoch in range(EPOCHS):\n",
      "        # Échantillonnage à chaque epoch\n",
      "        if USE_SAMPLING and len(all_fens) > MAX_SAMPLES:\n",
      "            print(f\"\\n[Epoch {epoch+1}] 🎲 Échantillonnage: {MAX_SAMPLES:,} positions sur {len(all_fens):,}\")\n",
      "            idx = np.random.choice(len(all_fens), size=MAX_SAMPLES, replace=False)\n",
      "            fens = all_fens[idx]\n",
      "            evaluations = all_evaluations[idx]\n",
      "        else:\n",
      "            fens = all_fens\n",
      "            evaluations = all_evaluations\n",
      "        \n",
      "        # LR Warmup\n",
      "        if USE_LR_WARMUP and epoch < WARMUP_EPOCHS:\n",
      "            warmup_progress = (epoch + 1) / WARMUP_EPOCHS\n",
      "            lr = WARMUP_START_LR + (LEARNING_RATE - WARMUP_START_LR) * warmup_progress\n",
      "            for param_group in optimizer.param_groups:\n",
      "                param_group['lr'] = lr\n",
      "            print(f\"🔥 Warmup epoch {epoch+1}/{WARMUP_EPOCHS}: LR = {lr:.6f}\")\n",
      "        \n",
      "        # Créer le dataset et dataloader\n",
      "        train_dataset = ChessDataset(fens, evaluations)\n",
      "        train_loader = DataLoader(\n",
      "            train_dataset, \n",
      "            batch_size=BATCH_SIZE, \n",
      "            shuffle=True,\n",
      "            num_workers=0,  # Augmenter si CPU multi-core (ex: 4)\n",
      "            pin_memory=True if torch.cuda.is_available() else False\n",
      "        )\n",
      "        \n",
      "        # Training\n",
      "        model.train()\n",
      "        total_loss = 0\n",
      "        num_batches = 0\n",
      "        \n",
      "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
      "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
      "            inputs = inputs.to(DEVICE)\n",
      "            targets = targets.to(DEVICE)\n",
      "            \n",
      "            # Forward\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(inputs)\n",
      "            loss = criterion(outputs, targets)\n",
      "            \n",
      "            # Backward\n",
      "            loss.backward()\n",
      "            \n",
      "            # Gradient clipping\n",
      "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
      "            \n",
      "            # Update\n",
      "            optimizer.step()\n",
      "            \n",
      "            total_loss += loss.item()\n",
      "            num_batches += 1\n",
      "            \n",
      "            # Debug stats (premier batch)\n",
      "            if DEBUG_STATS and epoch == 0 and batch_idx == 0:\n",
      "                with torch.no_grad():\n",
      "                    preds = outputs.cpu().numpy().flatten()\n",
      "                    targs = targets.cpu().numpy().flatten()\n",
      "                    batch_rmse = np.sqrt(np.mean((preds - targs) ** 2))\n",
      "                    corr = np.corrcoef(preds, targs)[0, 1] if len(preds) > 1 else 0.0\n",
      "                    print(f\"\\n[DEBUG batch 0] targets mean={targs.mean():.4f} std={targs.std():.4f}; \"\n",
      "                          f\"preds mean={preds.mean():.4f} std={preds.std():.4f}; \"\n",
      "                          f\"RMSE={batch_rmse:.4f}; corr={corr:.4f}\")\n",
      "            \n",
      "            # Update progress bar\n",
      "            avg_loss = total_loss / num_batches\n",
      "            progress_bar.set_postfix({\"loss\": f\"{np.sqrt(avg_loss):.4f}\"})\n",
      "        \n",
      "        # Évaluation fin d'époque\n",
      "        print(f\"\\n🔍 Évaluation epoch {epoch+1}...\")\n",
      "        \n",
      "        # Échantillon d'évaluation\n",
      "        if EVAL_MAX_SAMPLES and len(all_fens) > EVAL_MAX_SAMPLES:\n",
      "            eval_idx = np.random.choice(len(all_fens), size=EVAL_MAX_SAMPLES, replace=False)\n",
      "            eval_fens = all_fens[eval_idx]\n",
      "            eval_targets = all_evaluations[eval_idx]\n",
      "        else:\n",
      "            eval_fens = all_fens\n",
      "            eval_targets = all_evaluations\n",
      "        \n",
      "        eval_dataset = ChessDataset(eval_fens, eval_targets)\n",
      "        eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE*2, shuffle=False)\n",
      "        \n",
      "        rmse, mae, corr, preds, targets = evaluate_model(model, eval_loader, DEVICE)\n",
      "        \n",
      "        baseline_rmse = targets.std()\n",
      "        improvement = 100 * (1 - rmse / baseline_rmse) if baseline_rmse > 0 else 0\n",
      "        \n",
      "        # Affichage\n",
      "        print(f\"\\n{'='*70}\")\n",
      "        print(f\"EPOCH {epoch+1}/{EPOCHS} - Évaluation sur {len(eval_fens):,} positions\")\n",
      "        print(f\"{'='*70}\")\n",
      "        print(f\"  RMSE:        {rmse:.4f}  (baseline: {baseline_rmse:.4f})\")\n",
      "        print(f\"  MAE:         {mae:.4f}\")\n",
      "        print(f\"  Amélioration: {improvement:+.1f}% vs baseline\")\n",
      "        print(f\"  Corrélation: {corr:.4f}\")\n",
      "        print(f\"  Std preds:   {preds.std():.4f}  (cible: {targets.std():.4f})\")\n",
      "        print(f\"  Mean preds:  {preds.mean():.4f}  (cible: {targets.mean():.4f})\")\n",
      "        \n",
      "        if improvement > 50:\n",
      "            print(f\"  ✓✓ Performance excellente!\")\n",
      "        elif improvement > 30:\n",
      "            print(f\"  ✓  Bon apprentissage!\")\n",
      "        elif improvement > 10:\n",
      "            print(f\"  →  Apprentissage en cours\")\n",
      "        else:\n",
      "            print(f\"  ⚠  Faible amélioration - vérifier hyperparamètres\")\n",
      "        print(f\"{'='*70}\\n\")\n",
      "        \n",
      "        # LR Scheduler\n",
      "        if USE_LR_SCHEDULER and (not USE_LR_WARMUP or epoch >= WARMUP_EPOCHS):\n",
      "            scheduler.step(rmse)\n",
      "        \n",
      "        # Sauvegarder le meilleur modèle\n",
      "        if rmse < best_rmse:\n",
      "            best_rmse = rmse\n",
      "            print(f\"💾 Nouveau meilleur RMSE: {best_rmse:.4f} - Sauvegarde...\")\n",
      "            torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, epoch)\n",
      "            save_weights_npz(model, WEIGHTS_FILE)\n",
      "    \n",
      "    print(\"\\n🎉 Entraînement terminé!\")\n",
      "    print(f\"📊 Meilleur RMSE: {best_rmse:.4f}\")\n",
      "    \n",
      "    # Sauvegarde finale\n",
      "    print(f\"\\n💾 Sauvegarde finale...\")\n",
      "    torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, EPOCHS)\n",
      "    save_weights_npz(model, WEIGHTS_FILE)\n",
      "    print(f\"✅ Modèle sauvegardé dans {CHECKPOINT_FILE} et {WEIGHTS_FILE}\")\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"Content of {file_path}:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(content)\n",
    "    print(\"=\" * 60)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf4e17",
   "metadata": {
    "id": "f2bf4e17"
   },
   "source": [
    "## 12. Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46daebdc",
   "metadata": {
    "id": "46daebdc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configurer le style des graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Graphique 1: Loss\n",
    "axes[0].plot(history['loss'], linewidth=2, color='#2E86AB', label='Training Loss')\n",
    "axes[0].set_xlabel('Époque', fontsize=12)\n",
    "axes[0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0].set_title('Évolution de la perte pendant l\\'entraînement', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Afficher les valeurs min/max\n",
    "min_loss = min(history['loss'])\n",
    "max_loss = max(history['loss'])\n",
    "axes[0].axhline(y=min_loss, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_loss:.6f}')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Graphique 2: MAE (si disponible)\n",
    "if 'mae' in history:\n",
    "    axes[1].plot(history['mae'], linewidth=2, color='#F77F00', label='MAE')\n",
    "    axes[1].set_xlabel('Époque', fontsize=12)\n",
    "    axes[1].set_ylabel('MAE', fontsize=12)\n",
    "    axes[1].set_title('Erreur absolue moyenne', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=10)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    min_mae = min(history['mae'])\n",
    "    axes[1].axhline(y=min_mae, color='green', linestyle='--', alpha=0.5, label=f'Min: {min_mae:.6f}')\n",
    "    axes[1].legend(fontsize=10)\n",
    "else:\n",
    "    axes[1].text(0.5, 0.5, 'MAE non disponible',\n",
    "                ha='center', va='center', fontsize=14, transform=axes[1].transAxes)\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Afficher les statistiques finales\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES FINALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"Perte minimale: {min_loss:.6f} (époque {history['loss'].index(min_loss) + 1})\")\n",
    "if 'mae' in history:\n",
    "    print(f\"MAE final: {history['mae'][-1]:.6f}\")\n",
    "    print(f\"MAE minimal: {min_mae:.6f} (époque {history['mae'].index(min_mae) + 1})\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f7779",
   "metadata": {
    "id": "859f7779"
   },
   "source": [
    "## 13. Sauvegarde du modèle final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6f55e",
   "metadata": {
    "id": "b0c6f55e"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Timestamp pour identifier cette sauvegarde\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Sauvegarder le modèle complet avec l'historique\n",
    "final_model_path = f'ai/chess_model_final_{timestamp}.pt'\n",
    "torch.save({\n",
    "    'epoch': CONFIG['epochs'],\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': CONFIG,\n",
    "    'history': history,\n",
    "    'timestamp': timestamp,\n",
    "}, final_model_path)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAUVEGARDE DES MODÈLES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"✓ Modèle final: {final_model_path}\")\n",
    "\n",
    "# Sauvegarder aussi au format .npz pour compatibilité avec l'ancien code\n",
    "weights_path = 'ai/NN/chess_nn_weights.npz'\n",
    "weights = {name: param.cpu().detach().numpy() for name, param in model.named_parameters()}\n",
    "np.savez(weights_path, **weights)\n",
    "print(f\"✓ Poids .npz: {weights_path}\")\n",
    "\n",
    "# Copier aussi le checkpoint dans NN/\n",
    "import shutil\n",
    "checkpoint_backup = f'ai/NN/chess_model_checkpoint_{timestamp}.pt'\n",
    "if os.path.exists(CONFIG['checkpoint_path']):\n",
    "    shutil.copy(CONFIG['checkpoint_path'], checkpoint_backup)\n",
    "    print(f\"✓ Checkpoint backup: {checkpoint_backup}\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n✅ Tous les fichiers sont sauvegardés sur votre Google Drive!\")\n",
    "print(f\"   Chemin: {PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bfd244",
   "metadata": {
    "id": "c4bfd244"
   },
   "source": [
    "## 14. Test du modèle sur des positions aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0315c06",
   "metadata": {
    "id": "b0315c06"
   },
   "outputs": [],
   "source": [
    "# Passer le modèle en mode évaluation\n",
    "model.eval()\n",
    "\n",
    "# Tester sur quelques positions aléatoires\n",
    "num_tests = 10\n",
    "test_indices = np.random.choice(len(X_train), num_tests, replace=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"TEST SUR {num_tests} POSITIONS ALÉATOIRES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(test_indices, 1):\n",
    "        x = torch.FloatTensor(X_train[idx:idx+1]).to(CONFIG['device'])\n",
    "        y_true = y_train[idx]\n",
    "        y_pred = model(x).cpu().numpy()[0, 0]\n",
    "        error = abs(y_true - y_pred)\n",
    "        errors.append(error)\n",
    "\n",
    "        print(f\"\\nPosition {i}:\")\n",
    "        print(f\"  Évaluation réelle:  {y_true:+8.4f}\")\n",
    "        print(f\"  Prédiction modèle:  {y_pred:+8.4f}\")\n",
    "        print(f\"  Erreur absolue:     {error:8.4f}\")\n",
    "\n",
    "        # Indicateur visuel de la qualité\n",
    "        if error < 0.1:\n",
    "            print(f\"  Qualité: ✅ Excellente\")\n",
    "        elif error < 0.3:\n",
    "            print(f\"  Qualité: ✓ Bonne\")\n",
    "        elif error < 0.5:\n",
    "            print(f\"  Qualité: ⚠ Moyenne\")\n",
    "        else:\n",
    "            print(f\"  Qualité: ❌ Faible\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DES TESTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Erreur moyenne: {np.mean(errors):.4f}\")\n",
    "print(f\"Erreur médiane: {np.median(errors):.4f}\")\n",
    "print(f\"Erreur min:     {np.min(errors):.4f}\")\n",
    "print(f\"Erreur max:     {np.max(errors):.4f}\")\n",
    "print(f\"Écart-type:     {np.std(errors):.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9184e",
   "metadata": {
    "id": "30e9184e"
   },
   "source": [
    "## 15. Résumé et fichiers générés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92229a",
   "metadata": {
    "id": "cb92229a"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 RÉSUMÉ DE L'ENTRAÎNEMENT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n📍 Projet: {PROJECT_PATH}\")\n",
    "print(f\"\\n⚙️ Configuration:\")\n",
    "print(f\"   • Parties générées: {CONFIG['num_games']:,}\")\n",
    "print(f\"   • Positions d'entraînement: {len(X_train):,}\")\n",
    "print(f\"   • Époques: {CONFIG['epochs']}\")\n",
    "print(f\"   • Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   • Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   • Device: {CONFIG['device']}\")\n",
    "\n",
    "print(f\"\\n📈 Résultats:\")\n",
    "print(f\"   • Perte finale: {history['loss'][-1]:.6f}\")\n",
    "print(f\"   • Perte minimale: {min(history['loss']):.6f}\")\n",
    "if 'mae' in history:\n",
    "    print(f\"   • MAE final: {history['mae'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\n💾 Fichiers sauvegardés sur Drive:\")\n",
    "files_to_check = [\n",
    "    final_model_path,\n",
    "    CONFIG['checkpoint_path'],\n",
    "    weights_path,\n",
    "    'training_history.png'\n",
    "]\n",
    "\n",
    "for filepath in files_to_check:\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath) / (1024 * 1024)  # Convertir en MB\n",
    "        print(f\"   ✓ {filepath} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ✗ {filepath} (non trouvé)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ ENTRAÎNEMENT TERMINÉ AVEC SUCCÈS!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTous les fichiers sont automatiquement synchronisés avec votre Google Drive.\")\n",
    "print(\"Vous pouvez fermer ce notebook en toute sécurité.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f74c05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1761573913516,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "76f74c05",
    "outputId": "fb621a16-ed55-4cbf-ac3d-1c0496679c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset CSV trouvé: /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      "Dossier de checkpoints (créé si manquant): /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n",
      "\n",
      "Variables exposées:\n",
      " DATASET_CSV = /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      " CKPT_DIR = /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# Localiser le dataset sur Google Drive et préparer le dossier de checkpoints\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Chemin attendu du dossier contenant le dataset (donné par l'user)\n",
    "# Updated based on user's feedback that the file is directly in smart_chess_drive\n",
    "DATASET_DIR = '/content/drive/MyDrive/smart_chess_drive/'\n",
    "\n",
    "# Chercher un fichier .csv dans DATASET_DIR\n",
    "DATASET_CSV = None\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    csvs = glob(os.path.join(DATASET_DIR, '*.csv'))\n",
    "    if len(csvs) > 0:\n",
    "        # Assuming there's only one relevant CSV in that dir, pick the first one\n",
    "        DATASET_CSV = csvs[0]\n",
    "        print(f'✅ Dataset CSV trouvé: {DATASET_CSV}')\n",
    "    else:\n",
    "        print(f'❌ Aucun fichier .csv trouvé dans {DATASET_DIR}. Placez votre fichier chessData.csv dans ce dossier.')\n",
    "else:\n",
    "    print(f'❌ Dossier dataset introuvable: {DATASET_DIR}. Vérifiez le chemin sur votre Drive.')\n",
    "\n",
    "# Créer un dossier de checkpoints dans le repo sur Drive (persistant)\n",
    "CKPT_DIR = '/content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints'\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "print('Dossier de checkpoints (créé si manquant):', CKPT_DIR)\n",
    "\n",
    "# Exposer variables utiles\n",
    "print('\\nVariables exposées:')\n",
    "print(' DATASET_CSV =', DATASET_CSV)\n",
    "print(' CKPT_DIR =', CKPT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9887d4b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598602,
     "status": "ok",
     "timestamp": 1761577453014,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "9887d4b8",
    "outputId": "b40ede36-bc90-4b28-a9f7-5e4d0c29a2a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖥️  Device: cuda\n",
      "🚀 GPU: Tesla T4\n",
      "💾 GPU Memory: 15.83 GB\n",
      "Configuration trainer:\n",
      " DATASET_PATH= /content/drive/MyDrive/smart_chess_drive/chessData.csv\n",
      " CHECKPOINT_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      " WEIGHTS_FILE= /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      " EPOCHS= 20\n",
      " MAX_SAMPLES= 500000\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "📥 Chargement du checkpoint PyTorch: /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "✅ Checkpoint chargé (step 20)\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 500,000 positions\n",
      "  Architecture: 768 → 256 → 256 → 1\n",
      "  Dropout: 0.3\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.001 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.001)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 20\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 8/3907 [00:00<00:54, 71.93it/s, loss=0.5618]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=0.0927 std=0.5291; preds mean=0.0462 std=0.3324; RMSE=0.4315; corr=0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.11it/s, loss=0.6169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6477  (baseline: 0.8621)\n",
      "  MAE:         0.2583\n",
      "  Amélioration: +24.9% vs baseline\n",
      "  Corrélation: 0.6779\n",
      "  Std preds:   0.4511  (cible: 0.8621)\n",
      "  Mean preds:  0.0390  (cible: 0.0280)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.6477 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 3907/3907 [00:41<00:00, 94.00it/s, loss=0.6237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5960  (baseline: 0.8320)\n",
      "  MAE:         0.2640\n",
      "  Amélioration: +28.4% vs baseline\n",
      "  Corrélation: 0.7008\n",
      "  Std preds:   0.5345  (cible: 0.8320)\n",
      "  Mean preds:  -0.0043  (cible: 0.0202)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.5960 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 3907/3907 [00:42<00:00, 90.88it/s, loss=0.6300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6007  (baseline: 0.7926)\n",
      "  MAE:         0.2528\n",
      "  Amélioration: +24.2% vs baseline\n",
      "  Corrélation: 0.6530\n",
      "  Std preds:   0.5032  (cible: 0.7926)\n",
      "  Mean preds:  0.0393  (cible: 0.0213)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 4] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 3907/3907 [00:43<00:00, 90.32it/s, loss=0.6367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 4...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 4/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6376  (baseline: 0.8382)\n",
      "  MAE:         0.2635\n",
      "  Amélioration: +23.9% vs baseline\n",
      "  Corrélation: 0.6627\n",
      "  Std preds:   0.4455  (cible: 0.8382)\n",
      "  Mean preds:  0.0345  (cible: 0.0542)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 5] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 3907/3907 [00:41<00:00, 93.25it/s, loss=0.6403]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 5...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 5/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5827  (baseline: 0.7798)\n",
      "  MAE:         0.2463\n",
      "  Amélioration: +25.3% vs baseline\n",
      "  Corrélation: 0.6693\n",
      "  Std preds:   0.4626  (cible: 0.7798)\n",
      "  Mean preds:  0.0355  (cible: 0.0517)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.5827 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "\n",
      "[Epoch 6] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 3907/3907 [00:42<00:00, 91.13it/s, loss=0.6292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 6...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 6/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6059  (baseline: 0.8022)\n",
      "  MAE:         0.2631\n",
      "  Amélioration: +24.5% vs baseline\n",
      "  Corrélation: 0.6633\n",
      "  Std preds:   0.4507  (cible: 0.8022)\n",
      "  Mean preds:  0.0673  (cible: 0.0569)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 7] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 3907/3907 [00:41<00:00, 93.31it/s, loss=0.6340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 7...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 7/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5934  (baseline: 0.7871)\n",
      "  MAE:         0.2517\n",
      "  Amélioration: +24.6% vs baseline\n",
      "  Corrélation: 0.6584\n",
      "  Std preds:   0.4910  (cible: 0.7871)\n",
      "  Mean preds:  0.0575  (cible: 0.0384)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 8] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 3907/3907 [00:42<00:00, 91.16it/s, loss=0.6330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 8...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 8/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6583  (baseline: 0.8617)\n",
      "  MAE:         0.2633\n",
      "  Amélioration: +23.6% vs baseline\n",
      "  Corrélation: 0.6507\n",
      "  Std preds:   0.4895  (cible: 0.8617)\n",
      "  Mean preds:  0.0381  (cible: 0.0521)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 9] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 3907/3907 [00:43<00:00, 90.09it/s, loss=0.6270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 9...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 9/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6124  (baseline: 0.8446)\n",
      "  MAE:         0.2572\n",
      "  Amélioration: +27.5% vs baseline\n",
      "  Corrélation: 0.6981\n",
      "  Std preds:   0.4930  (cible: 0.8446)\n",
      "  Mean preds:  0.0379  (cible: 0.0360)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 10] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.71it/s, loss=0.6263]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 10...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 10/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6193  (baseline: 0.8211)\n",
      "  MAE:         0.2538\n",
      "  Amélioration: +24.6% vs baseline\n",
      "  Corrélation: 0.6623\n",
      "  Std preds:   0.4735  (cible: 0.8211)\n",
      "  Mean preds:  0.0590  (cible: 0.0464)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 11] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.91it/s, loss=0.6248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 11...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 11/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5758  (baseline: 0.7928)\n",
      "  MAE:         0.2418\n",
      "  Amélioration: +27.4% vs baseline\n",
      "  Corrélation: 0.7046\n",
      "  Std preds:   0.4357  (cible: 0.7928)\n",
      "  Mean preds:  0.0392  (cible: 0.0370)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.5758 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "\n",
      "[Epoch 12] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 3907/3907 [00:43<00:00, 90.06it/s, loss=0.6223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 12...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 12/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6220  (baseline: 0.8393)\n",
      "  MAE:         0.2541\n",
      "  Amélioration: +25.9% vs baseline\n",
      "  Corrélation: 0.6743\n",
      "  Std preds:   0.5152  (cible: 0.8393)\n",
      "  Mean preds:  0.0380  (cible: 0.0505)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 13] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.97it/s, loss=0.6241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 13...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 13/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6435  (baseline: 0.8653)\n",
      "  MAE:         0.2567\n",
      "  Amélioration: +25.6% vs baseline\n",
      "  Corrélation: 0.6920\n",
      "  Std preds:   0.4446  (cible: 0.8653)\n",
      "  Mean preds:  0.0425  (cible: 0.0366)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 14] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 3907/3907 [00:44<00:00, 88.35it/s, loss=0.6218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 14...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 14/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5362  (baseline: 0.7461)\n",
      "  MAE:         0.2336\n",
      "  Amélioration: +28.1% vs baseline\n",
      "  Corrélation: 0.6971\n",
      "  Std preds:   0.4835  (cible: 0.7461)\n",
      "  Mean preds:  0.0610  (cible: 0.0503)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.5362 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "\n",
      "[Epoch 15] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 3907/3907 [00:43<00:00, 90.20it/s, loss=0.6187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 15...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 15/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5871  (baseline: 0.7916)\n",
      "  MAE:         0.2466\n",
      "  Amélioration: +25.8% vs baseline\n",
      "  Corrélation: 0.6729\n",
      "  Std preds:   0.4928  (cible: 0.7916)\n",
      "  Mean preds:  0.0359  (cible: 0.0518)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 16] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.59it/s, loss=0.6172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 16...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 16/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5899  (baseline: 0.8220)\n",
      "  MAE:         0.2468\n",
      "  Amélioration: +28.2% vs baseline\n",
      "  Corrélation: 0.6976\n",
      "  Std preds:   0.5419  (cible: 0.8220)\n",
      "  Mean preds:  0.0371  (cible: 0.0472)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 17] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.26it/s, loss=0.6182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 17...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 17/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5967  (baseline: 0.8040)\n",
      "  MAE:         0.2532\n",
      "  Amélioration: +25.8% vs baseline\n",
      "  Corrélation: 0.6725\n",
      "  Std preds:   0.4964  (cible: 0.8040)\n",
      "  Mean preds:  0.0312  (cible: 0.0389)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 18] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 3907/3907 [00:43<00:00, 90.55it/s, loss=0.6159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 18...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 18/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6148  (baseline: 0.8624)\n",
      "  MAE:         0.2557\n",
      "  Amélioration: +28.7% vs baseline\n",
      "  Corrélation: 0.7115\n",
      "  Std preds:   0.5101  (cible: 0.8624)\n",
      "  Mean preds:  0.0517  (cible: 0.0532)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 19] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 3907/3907 [00:43<00:00, 90.14it/s, loss=0.6082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 19...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 19/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5778  (baseline: 0.8123)\n",
      "  MAE:         0.2394\n",
      "  Amélioration: +28.9% vs baseline\n",
      "  Corrélation: 0.7165\n",
      "  Std preds:   0.4690  (cible: 0.8123)\n",
      "  Mean preds:  0.0319  (cible: 0.0296)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 20] 🎲 Échantillonnage: 500,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 3907/3907 [00:43<00:00, 89.44it/s, loss=0.6116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 20...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 20/20 - Évaluation sur 5,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.5785  (baseline: 0.7720)\n",
      "  MAE:         0.2433\n",
      "  Amélioration: +25.1% vs baseline\n",
      "  Corrélation: 0.6639\n",
      "  Std preds:   0.4806  (cible: 0.7720)\n",
      "  Mean preds:  0.0381  (cible: 0.0565)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.5362\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_model_checkpoint.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/chess_nn_weights.npz\n"
     ]
    }
   ],
   "source": [
    "# Configurer et lancer le script d'entraînement `ai.NN.train_torch` en adaptant les chemins pour Colab/Drive\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "if DATASET_CSV is None:\n",
    "    raise FileNotFoundError(f\"Dataset non trouvé dans: {DATASET_DIR}\")\n",
    "\n",
    "# Importer le module d'entraînement\n",
    "import ai.NN.train_torch as trainer\n",
    "\n",
    "# Reload the module to pick up recent changes\n",
    "importlib.reload(trainer)\n",
    "\n",
    "\n",
    "# Rediriger les chemins dataset et checkpoints vers Drive\n",
    "trainer.DATASET_PATH = DATASET_CSV\n",
    "trainer.CHECKPOINT_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.CHECKPOINT_FILE))\n",
    "trainer.WEIGHTS_FILE = os.path.join(CKPT_DIR, os.path.basename(trainer.WEIGHTS_FILE))\n",
    "\n",
    "# Harmonisation des tailles de batch (Option B):\n",
    "# On force le module trainer à utiliser la valeur définie dans CONFIG['batch_size']\n",
    "try:\n",
    "    trainer.BATCH_SIZE = CONFIG['batch_size']\n",
    "    print(f'✅ Harmonisation: trainer.BATCH_SIZE = {trainer.BATCH_SIZE}')\n",
    "except Exception as e:\n",
    "    print('⚠️ Impossible de définir trainer.BATCH_SIZE:', e)\n",
    "\n",
    "# --- Apply user-requested global hyperparameter changes ---\n",
    "# Increase hidden layer size to 512 and decrease per-epoch samples to 50k\n",
    "try:\n",
    "    trainer.HIDDEN_SIZE = 512\n",
    "    trainer.MAX_SAMPLES = 50_000\n",
    "    print(f\"✅ Applied global changes: trainer.HIDDEN_SIZE={trainer.HIDDEN_SIZE}, trainer.MAX_SAMPLES={trainer.MAX_SAMPLES}\")\n",
    "except Exception as e:\n",
    "    print('⚠️ Impossible de définir trainer.HIDDEN_SIZE / trainer.MAX_SAMPLES:', e)\n",
    "\n",
    "# Optionally set other CONFIG parameters from the notebook if needed\n",
    "# trainer.EPOCHS = CONFIG['epochs']\n",
    "# trainer.LEARNING_RATE = CONFIG['learning_rate']\n",
    "# trainer.DEVICE = CONFIG['device']\n",
    "\n",
    "# Optionnel: réduire pour test rapide (décommentez si besoin)\n",
    "# trainer.EPOCHS = 2\n",
    "# trainer.MAX_SAMPLES = 5000\n",
    "\n",
    "print('Configuration trainer:')\n",
    "print(' DATASET_PATH=', trainer.DATASET_PATH)\n",
    "print(' CHECKPOINT_FILE=', trainer.CHECKPOINT_FILE)\n",
    "print(' WEIGHTS_FILE=', trainer.WEIGHTS_FILE)\n",
    "print(' EPOCHS=', trainer.EPOCHS)\n",
    "print(' MAX_SAMPLES=', trainer.MAX_SAMPLES)\n",
    "\n",
    "\n",
    "# Lancer l'entraînement\n",
    "trainer.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5525dae",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1761574373656,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "f5525dae",
    "outputId": "43c34ee0-a8e1-4e85-f097-d2f2b6b1d7c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/NN/train_torch.py:\n",
      "============================================================\n",
      "\"\"\"\n",
      "Script d'entraînement PyTorch optimisé pour GPU\n",
      "Compatible avec Google Colab et machines locales avec GPU\n",
      "\"\"\"\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.optim as optim\n",
      "from torch.utils.data import Dataset, DataLoader\n",
      "from tqdm import tqdm\n",
      "import os\n",
      "\n",
      "from Chess import Chess\n",
      "from ai.NN.torch_nn_evaluator import TorchNNEvaluator, save_weights_npz, load_from_npz, torch_save_checkpoint, torch_load_checkpoint\n",
      "\n",
      "# --- CONFIGURATION DE L'ENTRAÎNEMENT ---\n",
      "DATASET_PATH = \"C:\\\\Users\\\\gauti\\\\OneDrive\\\\Documents\\\\UE commande\\\\chessData.csv\"  # Adapté pour Colab (fichier à la racine)\n",
      "WEIGHTS_FILE = \"chess_nn_weights.npz\"\n",
      "CHECKPOINT_FILE = \"chess_model_checkpoint.pt\"\n",
      "\n",
      "# Architecture\n",
      "HIDDEN_SIZE = 256\n",
      "DROPOUT = 0.3\n",
      "LEAKY_ALPHA = 0.01\n",
      "\n",
      "# Hyperparamètres\n",
      "LEARNING_RATE = 0.001\n",
      "WEIGHT_DECAY = 1e-4  # L2 regularization (AdamW)\n",
      "EPOCHS = 20\n",
      "BATCH_SIZE = 128  # Plus grand pour GPU\n",
      "MAX_SAMPLES = 500_000  # Plus de données avec GPU !\n",
      "EVAL_MAX_SAMPLES = 5000\n",
      "\n",
      "# Options\n",
      "USE_SAMPLING = True\n",
      "RESET_WEIGHTS = False\n",
      "DEBUG_STATS = True\n",
      "\n",
      "# LR Scheduler\n",
      "USE_LR_SCHEDULER = True\n",
      "LR_PATIENCE = 2\n",
      "LR_FACTOR = 0.5\n",
      "\n",
      "# LR Warmup\n",
      "USE_LR_WARMUP = True\n",
      "WARMUP_EPOCHS = 3\n",
      "WARMUP_START_LR = 0.0001\n",
      "\n",
      "# Device (auto-détection GPU)\n",
      "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
      "print(f\"🖥️  Device: {DEVICE}\")\n",
      "if torch.cuda.is_available():\n",
      "    print(f\"🚀 GPU: {torch.cuda.get_device_name(0)}\")\n",
      "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
      "\n",
      "\n",
      "class ChessDataset(Dataset):\n",
      "    \"\"\"Dataset PyTorch pour les positions d'échecs\"\"\"\n",
      "    def __init__(self, fens, evaluations):\n",
      "        self.fens = fens\n",
      "        self.evaluations = evaluations\n",
      "        self.chess = Chess()\n",
      "        \n",
      "        # Précalculer l'encodage pour accélérer (optionnel, consomme plus de RAM)\n",
      "        # self.encoded = [self._encode_fen(fen) for fen in tqdm(fens, desc=\"Encoding positions\")]\n",
      "        \n",
      "    def __len__(self):\n",
      "        return len(self.fens)\n",
      "    \n",
      "    def __getitem__(self, idx):\n",
      "        fen = self.fens[idx]\n",
      "        target = self.evaluations[idx]\n",
      "        \n",
      "        # Encoder la position\n",
      "        self.chess.load_fen(fen)\n",
      "        encoded = self._encode_board(self.chess)\n",
      "        \n",
      "        return torch.from_numpy(encoded).float(), torch.tensor([target], dtype=torch.float32)\n",
      "    \n",
      "    def _encode_board(self, chess_instance):\n",
      "        \"\"\"Encode le plateau en vecteur 768D (identique à nn_evaluator.py)\"\"\"\n",
      "        piece_to_index = {\n",
      "            'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
      "            'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
      "        }\n",
      "        vec = np.zeros(768, dtype=np.float32)\n",
      "        for piece_char, bitboard in chess_instance.bitboards.items():\n",
      "            if bitboard == 0:\n",
      "                continue\n",
      "            piece_index = piece_to_index[piece_char]\n",
      "            temp_bb = int(bitboard)\n",
      "            while temp_bb:\n",
      "                square = (temp_bb & -temp_bb).bit_length() - 1\n",
      "                vector_position = piece_index * 64 + square\n",
      "                vec[vector_position] = 1.0\n",
      "                temp_bb &= temp_bb - 1\n",
      "        return vec\n",
      "\n",
      "\n",
      "def load_data(filepath: str):\n",
      "    \"\"\"Charge le dataset FEN,Evaluation et le nettoie.\"\"\"\n",
      "    print(f\"📂 Chargement du dataset depuis {filepath}...\")\n",
      "    \n",
      "    df = pd.read_csv(\n",
      "        filepath, \n",
      "        names=['FEN', 'Evaluation'], \n",
      "        skiprows=1,\n",
      "        comment='#'\n",
      "    )\n",
      "    \n",
      "    initial_count = len(df)\n",
      "    df.dropna(inplace=True)\n",
      "    cleaned_count = len(df)\n",
      "    \n",
      "    if initial_count > cleaned_count:\n",
      "        print(f\"🧹 Nettoyage : {initial_count - cleaned_count} lignes corrompues supprimées.\")\n",
      "    \n",
      "    fens = df['FEN'].values\n",
      "    EVAL_SCALE_FACTOR = 1000.0\n",
      "    evaluations = (df['Evaluation'].astype(int).values) / EVAL_SCALE_FACTOR\n",
      "    \n",
      "    print(f\"✅ {len(fens):,} positions valides chargées.\")\n",
      "    return fens, evaluations\n",
      "\n",
      "\n",
      "def evaluate_model(model, dataloader, device):\n",
      "    \"\"\"Évalue le modèle sur un dataset\"\"\"\n",
      "    model.eval()\n",
      "    predictions = []\n",
      "    targets = []\n",
      "    \n",
      "    with torch.no_grad():\n",
      "        for inputs, labels in dataloader:\n",
      "            inputs = inputs.to(device)\n",
      "            outputs = model(inputs)\n",
      "            predictions.extend(outputs.cpu().numpy().flatten())\n",
      "            targets.extend(labels.numpy().flatten())\n",
      "    \n",
      "    predictions = np.array(predictions)\n",
      "    targets = np.array(targets)\n",
      "    \n",
      "    rmse = float(np.sqrt(np.mean((predictions - targets) ** 2)))\n",
      "    mae = float(np.mean(np.abs(predictions - targets)))\n",
      "    corr = float(np.corrcoef(predictions, targets)[0, 1]) if len(predictions) > 1 else 0.0\n",
      "    \n",
      "    return rmse, mae, corr, predictions, targets\n",
      "\n",
      "\n",
      "def main():\n",
      "    # 1. Charger les données\n",
      "    all_fens, all_evaluations = load_data(DATASET_PATH)\n",
      "    \n",
      "    print(f\"\\n📊 Dataset complet: {len(all_fens):,} positions\")\n",
      "    \n",
      "    eval_mean = float(np.mean(all_evaluations))\n",
      "    \n",
      "    # 2. Initialiser le modèle\n",
      "    if RESET_WEIGHTS and os.path.exists(WEIGHTS_FILE):\n",
      "        print(f\"🗑️  Suppression des anciens poids: {WEIGHTS_FILE}\")\n",
      "        os.remove(WEIGHTS_FILE)\n",
      "    \n",
      "    if os.path.exists(CHECKPOINT_FILE):\n",
      "        print(f\"📥 Chargement du checkpoint PyTorch: {CHECKPOINT_FILE}\")\n",
      "        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
      "        model, _, start_step = torch_load_checkpoint(CHECKPOINT_FILE, model, optimizer, device=DEVICE)\n",
      "        print(f\"✅ Checkpoint chargé (step {start_step})\")\n",
      "    elif os.path.exists(WEIGHTS_FILE):\n",
      "        print(f\"📥 Chargement des poids NumPy: {WEIGHTS_FILE}\")\n",
      "        model, adam_moments = load_from_npz(WEIGHTS_FILE, device=DEVICE)\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
      "        # TODO: Restaurer les moments Adam si présents\n",
      "        print(f\"✅ Poids chargés depuis NumPy\")\n",
      "    else:\n",
      "        print(\"🆕 Création d'un nouveau réseau...\")\n",
      "        model = TorchNNEvaluator(hidden_size=HIDDEN_SIZE, dropout=DROPOUT, leaky_alpha=LEAKY_ALPHA)\n",
      "        # Initialisation He (PyTorch le fait déjà par défaut pour Linear + ReLU)\n",
      "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
      "        \n",
      "        # Warm-start du biais de sortie\n",
      "        with torch.no_grad():\n",
      "            model.l3.bias[0] = eval_mean\n",
      "    \n",
      "    model.to(DEVICE)\n",
      "    \n",
      "    # 3. Configuration de l'entraînement\n",
      "    criterion = nn.MSELoss()\n",
      "    \n",
      "    # LR Scheduler\n",
      "    if USE_LR_SCHEDULER:\n",
      "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
      "            optimizer, mode='min', factor=LR_FACTOR, \n",
      "            patience=LR_PATIENCE\n",
      "        )\n",
      "    \n",
      "    print(f\"\\n{'='*70}\")\n",
      "    print(f\"Configuration:\")\n",
      "    print(f\"  Dataset complet: {len(all_fens):,} positions\")\n",
      "    print(f\"  Échantillon/epoch: {MAX_SAMPLES if USE_SAMPLING else len(all_fens):,} positions\")\n",
      "    print(f\"  Architecture: 768 → {HIDDEN_SIZE} → {HIDDEN_SIZE} → 1\")\n",
      "    print(f\"  Dropout: {DROPOUT}\")\n",
      "    print(f\"  LeakyReLU alpha: {LEAKY_ALPHA}\")\n",
      "    print(f\"  Learning rate: {LEARNING_RATE} (AdamW, weight decay: {WEIGHT_DECAY})\")\n",
      "    print(f\"  LR Warmup: {USE_LR_WARMUP} ({WARMUP_START_LR if USE_LR_WARMUP else 'N/A'} → {LEARNING_RATE})\")\n",
      "    print(f\"  LR Scheduler: {USE_LR_SCHEDULER} (patience: {LR_PATIENCE if USE_LR_SCHEDULER else 'N/A'})\")\n",
      "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
      "    print(f\"  Epochs: {EPOCHS}\")\n",
      "    print(f\"  Device: {DEVICE}\")\n",
      "    print(f\"{'='*70}\\n\")\n",
      "    \n",
      "    # 4. Boucle d'entraînement\n",
      "    best_rmse = float('inf')\n",
      "    \n",
      "    for epoch in range(EPOCHS):\n",
      "        # Échantillonnage à chaque epoch\n",
      "        if USE_SAMPLING and len(all_fens) > MAX_SAMPLES:\n",
      "            print(f\"\\n[Epoch {epoch+1}] 🎲 Échantillonnage: {MAX_SAMPLES:,} positions sur {len(all_fens):,}\")\n",
      "            idx = np.random.choice(len(all_fens), size=MAX_SAMPLES, replace=False)\n",
      "            fens = all_fens[idx]\n",
      "            evaluations = all_evaluations[idx]\n",
      "        else:\n",
      "            fens = all_fens\n",
      "            evaluations = all_evaluations\n",
      "        \n",
      "        # LR Warmup\n",
      "        if USE_LR_WARMUP and epoch < WARMUP_EPOCHS:\n",
      "            warmup_progress = (epoch + 1) / WARMUP_EPOCHS\n",
      "            lr = WARMUP_START_LR + (LEARNING_RATE - WARMUP_START_LR) * warmup_progress\n",
      "            for param_group in optimizer.param_groups:\n",
      "                param_group['lr'] = lr\n",
      "            print(f\"🔥 Warmup epoch {epoch+1}/{WARMUP_EPOCHS}: LR = {lr:.6f}\")\n",
      "        \n",
      "        # Créer le dataset et dataloader\n",
      "        train_dataset = ChessDataset(fens, evaluations)\n",
      "        train_loader = DataLoader(\n",
      "            train_dataset, \n",
      "            batch_size=BATCH_SIZE, \n",
      "            shuffle=True,\n",
      "            num_workers=0,  # Augmenter si CPU multi-core (ex: 4)\n",
      "            pin_memory=True if torch.cuda.is_available() else False\n",
      "        )\n",
      "        \n",
      "        # Training\n",
      "        model.train()\n",
      "        total_loss = 0\n",
      "        num_batches = 0\n",
      "        \n",
      "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
      "        for batch_idx, (inputs, targets) in enumerate(progress_bar):\n",
      "            inputs = inputs.to(DEVICE)\n",
      "            targets = targets.to(DEVICE)\n",
      "            \n",
      "            # Forward\n",
      "            optimizer.zero_grad()\n",
      "            outputs = model(inputs)\n",
      "            loss = criterion(outputs, targets)\n",
      "            \n",
      "            # Backward\n",
      "            loss.backward()\n",
      "            \n",
      "            # Gradient clipping\n",
      "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
      "            \n",
      "            # Update\n",
      "            optimizer.step()\n",
      "            \n",
      "            total_loss += loss.item()\n",
      "            num_batches += 1\n",
      "            \n",
      "            # Debug stats (premier batch)\n",
      "            if DEBUG_STATS and epoch == 0 and batch_idx == 0:\n",
      "                with torch.no_grad():\n",
      "                    preds = outputs.cpu().numpy().flatten()\n",
      "                    targs = targets.cpu().numpy().flatten()\n",
      "                    batch_rmse = np.sqrt(np.mean((preds - targs) ** 2))\n",
      "                    corr = np.corrcoef(preds, targs)[0, 1] if len(preds) > 1 else 0.0\n",
      "                    print(f\"\\n[DEBUG batch 0] targets mean={targs.mean():.4f} std={targs.std():.4f}; \"\n",
      "                          f\"preds mean={preds.mean():.4f} std={preds.std():.4f}; \"\n",
      "                          f\"RMSE={batch_rmse:.4f}; corr={corr:.4f}\")\n",
      "            \n",
      "            # Update progress bar\n",
      "            avg_loss = total_loss / num_batches\n",
      "            progress_bar.set_postfix({\"loss\": f\"{np.sqrt(avg_loss):.4f}\"})\n",
      "        \n",
      "        # Évaluation fin d'époque\n",
      "        print(f\"\\n🔍 Évaluation epoch {epoch+1}...\")\n",
      "        \n",
      "        # Échantillon d'évaluation\n",
      "        if EVAL_MAX_SAMPLES and len(all_fens) > EVAL_MAX_SAMPLES:\n",
      "            eval_idx = np.random.choice(len(all_fens), size=EVAL_MAX_SAMPLES, replace=False)\n",
      "            eval_fens = all_fens[eval_idx]\n",
      "            eval_targets = all_evaluations[eval_idx]\n",
      "        else:\n",
      "            eval_fens = all_fens\n",
      "            eval_targets = all_evaluations\n",
      "        \n",
      "        eval_dataset = ChessDataset(eval_fens, eval_targets)\n",
      "        eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE*2, shuffle=False)\n",
      "        \n",
      "        rmse, mae, corr, preds, targets = evaluate_model(model, eval_loader, DEVICE)\n",
      "        \n",
      "        baseline_rmse = targets.std()\n",
      "        improvement = 100 * (1 - rmse / baseline_rmse) if baseline_rmse > 0 else 0\n",
      "        \n",
      "        # Affichage\n",
      "        print(f\"\\n{'='*70}\")\n",
      "        print(f\"EPOCH {epoch+1}/{EPOCHS} - Évaluation sur {len(eval_fens):,} positions\")\n",
      "        print(f\"{'='*70}\")\n",
      "        print(f\"  RMSE:        {rmse:.4f}  (baseline: {baseline_rmse:.4f})\")\n",
      "        print(f\"  MAE:         {mae:.4f}\")\n",
      "        print(f\"  Amélioration: {improvement:+.1f}% vs baseline\")\n",
      "        print(f\"  Corrélation: {corr:.4f}\")\n",
      "        print(f\"  Std preds:   {preds.std():.4f}  (cible: {targets.std():.4f})\")\n",
      "        print(f\"  Mean preds:  {preds.mean():.4f}  (cible: {targets.mean():.4f})\")\n",
      "        \n",
      "        if improvement > 50:\n",
      "            print(f\"  ✓✓ Performance excellente!\")\n",
      "        elif improvement > 30:\n",
      "            print(f\"  ✓  Bon apprentissage!\")\n",
      "        elif improvement > 10:\n",
      "            print(f\"  →  Apprentissage en cours\")\n",
      "        else:\n",
      "            print(f\"  ⚠  Faible amélioration - vérifier hyperparamètres\")\n",
      "        print(f\"{'='*70}\\n\")\n",
      "        \n",
      "        # LR Scheduler\n",
      "        if USE_LR_SCHEDULER and (not USE_LR_WARMUP or epoch >= WARMUP_EPOCHS):\n",
      "            scheduler.step(rmse)\n",
      "        \n",
      "        # Sauvegarder le meilleur modèle\n",
      "        if rmse < best_rmse:\n",
      "            best_rmse = rmse\n",
      "            print(f\"💾 Nouveau meilleur RMSE: {best_rmse:.4f} - Sauvegarde...\")\n",
      "            torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, epoch)\n",
      "            save_weights_npz(model, WEIGHTS_FILE)\n",
      "    \n",
      "    print(\"\\n🎉 Entraînement terminé!\")\n",
      "    print(f\"📊 Meilleur RMSE: {best_rmse:.4f}\")\n",
      "    \n",
      "    # Sauvegarde finale\n",
      "    print(f\"\\n💾 Sauvegarde finale...\")\n",
      "    torch_save_checkpoint(CHECKPOINT_FILE, model, optimizer, EPOCHS)\n",
      "    save_weights_npz(model, WEIGHTS_FILE)\n",
      "    print(f\"✅ Modèle sauvegardé dans {CHECKPOINT_FILE} et {WEIGHTS_FILE}\")\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# @title\n",
    "import os\n",
    "\n",
    "file_path = os.path.join(PROJECT_PATH, 'ai/NN/train_torch.py')\n",
    "\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"Content of {file_path}:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(content)\n",
    "    print(\"=\" * 60)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971f1dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136266,
     "status": "ok",
     "timestamp": 1761578462983,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "e971f1dc",
    "outputId": "a9ad7f7a-8d95-4016-9052-80d15059f2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement des smoke tests (rapides).\n",
      "\n",
      "Validation fixe : 5000 positions (seed=42)\n",
      "\n",
      "================================================================================\n",
      "Exp: baseline\n",
      "================================================================================\n",
      "Parameters:\n",
      " HIDDEN_SIZE=256, DROPOUT=0.3, LR=0.001\n",
      " EPOCHS=3, MAX_SAMPLES=100000\n",
      " CHECKPOINT -> /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.pt\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "🆕 Création d'un nouveau réseau...\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 100,000 positions\n",
      "  Architecture: 768 → 256 → 256 → 1\n",
      "  Dropout: 0.3\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.001 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.001)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 3\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   1%|▏         | 10/782 [00:00<00:07, 97.04it/s, loss=0.8523]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=-0.0954 std=0.8398; preds mean=0.0197 std=0.0206; RMSE=0.8495; corr=-0.0816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 782/782 [00:08<00:00, 93.69it/s, loss=0.7908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7484  (baseline: 0.8009)\n",
      "  MAE:         0.3023\n",
      "  Amélioration: +6.5% vs baseline\n",
      "  Corrélation: 0.3596\n",
      "  Std preds:   0.2819  (cible: 0.8009)\n",
      "  Mean preds:  0.0008  (cible: 0.0412)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7484 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 782/782 [00:08<00:00, 95.37it/s, loss=0.7620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7313  (baseline: 0.8047)\n",
      "  MAE:         0.3036\n",
      "  Amélioration: +9.1% vs baseline\n",
      "  Corrélation: 0.4233\n",
      "  Std preds:   0.2952  (cible: 0.8047)\n",
      "  Mean preds:  0.0497  (cible: 0.0156)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7313 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.npz\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 782/782 [00:08<00:00, 94.23it/s, loss=0.7419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7975  (baseline: 0.9379)\n",
      "  MAE:         0.3361\n",
      "  Amélioration: +15.0% vs baseline\n",
      "  Corrélation: 0.5428\n",
      "  Std preds:   0.3849  (cible: 0.9379)\n",
      "  Mean preds:  0.0718  (cible: 0.0605)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.7313\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_baseline.npz\n",
      "Run time: 45.5s\n",
      "Eval results — RMSE: 0.7478, MAE: 0.2981, Corr: 0.4215\n",
      "\n",
      "================================================================================\n",
      "Exp: bigger\n",
      "================================================================================\n",
      "Parameters:\n",
      " HIDDEN_SIZE=512, DROPOUT=0.2, LR=0.0005\n",
      " EPOCHS=3, MAX_SAMPLES=100000\n",
      " CHECKPOINT -> /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.pt\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "🆕 Création d'un nouveau réseau...\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 100,000 positions\n",
      "  Architecture: 768 → 512 → 512 → 1\n",
      "  Dropout: 0.2\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.0005 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.0005)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 3\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   1%|▏         | 10/782 [00:00<00:08, 94.63it/s, loss=0.8632]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=0.1051 std=0.3792; preds mean=0.0599 std=0.0168; RMSE=0.3844; corr=-0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 782/782 [00:08<00:00, 95.84it/s, loss=0.7811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7916  (baseline: 0.8562)\n",
      "  MAE:         0.3106\n",
      "  Amélioration: +7.5% vs baseline\n",
      "  Corrélation: 0.3909\n",
      "  Std preds:   0.2610  (cible: 0.8562)\n",
      "  Mean preds:  0.0385  (cible: 0.0525)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7916 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 782/782 [00:08<00:00, 93.07it/s, loss=0.7477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7304  (baseline: 0.7993)\n",
      "  MAE:         0.2937\n",
      "  Amélioration: +8.6% vs baseline\n",
      "  Corrélation: 0.4136\n",
      "  Std preds:   0.2700  (cible: 0.7993)\n",
      "  Mean preds:  0.0538  (cible: 0.0693)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7304 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.npz\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 782/782 [00:08<00:00, 94.17it/s, loss=0.7412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6829  (baseline: 0.7569)\n",
      "  MAE:         0.2861\n",
      "  Amélioration: +9.8% vs baseline\n",
      "  Corrélation: 0.4321\n",
      "  Std preds:   0.3429  (cible: 0.7569)\n",
      "  Mean preds:  0.0592  (cible: 0.0449)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.6829 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.npz\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.6829\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_bigger.npz\n",
      "Run time: 45.0s\n",
      "Eval results — RMSE: 0.7523, MAE: 0.3035, Corr: 0.4127\n",
      "\n",
      "================================================================================\n",
      "Exp: smaller_lr\n",
      "================================================================================\n",
      "Parameters:\n",
      " HIDDEN_SIZE=512, DROPOUT=0.2, LR=0.0001\n",
      " EPOCHS=3, MAX_SAMPLES=100000\n",
      " CHECKPOINT -> /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.pt\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "🆕 Création d'un nouveau réseau...\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 100,000 positions\n",
      "  Architecture: 768 → 512 → 512 → 1\n",
      "  Dropout: 0.2\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.0001 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.0001)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 3\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   1%|          | 9/782 [00:00<00:08, 89.44it/s, loss=0.7861]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=-0.0480 std=0.8090; preds mean=0.0281 std=0.0190; RMSE=0.8120; corr=0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 782/782 [00:08<00:00, 94.23it/s, loss=0.7964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7115  (baseline: 0.7599)\n",
      "  MAE:         0.2874\n",
      "  Amélioration: +6.4% vs baseline\n",
      "  Corrélation: 0.3623\n",
      "  Std preds:   0.2119  (cible: 0.7599)\n",
      "  Mean preds:  0.0239  (cible: 0.0463)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7115 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 782/782 [00:08<00:00, 96.92it/s, loss=0.7769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8157  (baseline: 0.8568)\n",
      "  MAE:         0.3187\n",
      "  Amélioration: +4.8% vs baseline\n",
      "  Corrélation: 0.3081\n",
      "  Std preds:   0.2931  (cible: 0.8568)\n",
      "  Mean preds:  0.0621  (cible: 0.0674)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 100,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 782/782 [00:08<00:00, 93.15it/s, loss=0.7590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/3 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.8246  (baseline: 0.8923)\n",
      "  MAE:         0.3201\n",
      "  Amélioration: +7.6% vs baseline\n",
      "  Corrélation: 0.3859\n",
      "  Std preds:   0.3133  (cible: 0.8923)\n",
      "  Mean preds:  0.0292  (cible: 0.0648)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.7115\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_smaller_lr.npz\n",
      "Run time: 44.7s\n",
      "Eval results — RMSE: 0.7484, MAE: 0.2953, Corr: 0.4226\n",
      "\n",
      "================================================================================\n",
      "Résumé des smoke tests:\n",
      "{'exp': 'baseline', 'rmse': 0.7478238344192505, 'mae': 0.29814785718917847, 'corr': 0.4214677341606782}\n",
      "{'exp': 'bigger', 'rmse': 0.7522616982460022, 'mae': 0.30348190665245056, 'corr': 0.41272665945141124}\n",
      "{'exp': 'smaller_lr', 'rmse': 0.7484146952629089, 'mae': 0.29530638456344604, 'corr': 0.4226427413031045}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Smoke tests automatisés — 3 runs courts pour comparer configurations\n",
    "# - Crée une validation fixe, lance 3 expériences courtes (EPOCHS=3, MAX_SAMPLES=50k)\n",
    "# - Sauvegarde checkpoints séparés et évalue chaque modèle sur la validation fixe\n",
    "\n",
    "import time\n",
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print('Lancement des smoke tests (rapides).\\n')\n",
    "\n",
    "# Vérifier dataset et données en mémoire\n",
    "if 'X_train' not in globals() or 'y_train' not in globals():\n",
    "    print('X_train/y_train non trouvés en mémoire — chargement léger depuis trainer.DATASET_PATH (peut prendre du temps)...')\n",
    "    fens, evaluations = trainer.load_data(trainer.DATASET_PATH)\n",
    "    X_train = fens\n",
    "    y_train = evaluations\n",
    "\n",
    "# Créer validation fixe (seed deterministe)\n",
    "val_size = min(5000, len(X_train))\n",
    "rs = np.random.RandomState(42)\n",
    "val_idx = rs.choice(len(X_train), size=val_size, replace=False)\n",
    "val_fens = X_train[val_idx]\n",
    "val_targets = y_train[val_idx]\n",
    "print(f'Validation fixe : {val_size} positions (seed=42)')\n",
    "\n",
    "# Sauvegarder originaux pour restauration\n",
    "orig_keys = ['HIDDEN_SIZE','DROPOUT','LEARNING_RATE','WEIGHT_DECAY','BATCH_SIZE','EPOCHS','MAX_SAMPLES','CHECKPOINT_FILE','WEIGHTS_FILE','EVAL_MAX_SAMPLES']\n",
    "orig = {k: getattr(trainer, k) for k in orig_keys if hasattr(trainer, k)}\n",
    "\n",
    "# Expériences à tester (changes applied on top of orig)\n",
    "experiments = [\n",
    "    {'name': 'baseline', 'HIDDEN_SIZE': orig.get('HIDDEN_SIZE', 256), 'DROPOUT': orig.get('DROPOUT', 0.3), 'LEARNING_RATE': orig.get('LEARNING_RATE', 0.001)},\n",
    "    {'name': 'bigger', 'HIDDEN_SIZE': 512, 'DROPOUT': 0.2, 'LEARNING_RATE': 5e-4},\n",
    "    {'name': 'smaller_lr', 'HIDDEN_SIZE': 512, 'DROPOUT': 0.2, 'LEARNING_RATE': 1e-4},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    print('\\n' + '='*80)\n",
    "    print(f\"Exp: {exp['name']}\")\n",
    "    print('='*80)\n",
    "\n",
    "    # Set quick test params\n",
    "    trainer.EPOCHS = 3\n",
    "    trainer.MAX_SAMPLES = 50_000\n",
    "    trainer.EVAL_MAX_SAMPLES = 2000\n",
    "\n",
    "    # Apply experiment overrides\n",
    "    trainer.HIDDEN_SIZE = exp['HIDDEN_SIZE']\n",
    "    trainer.DROPOUT = exp['DROPOUT']\n",
    "    trainer.LEARNING_RATE = exp['LEARNING_RATE']\n",
    "\n",
    "    # Use separate checkpoint/weights files to avoid overwriting\n",
    "    ckpt_path = os.path.join(CKPT_DIR, f\"smoke_{exp['name']}.pt\")\n",
    "    weights_path = os.path.join(CKPT_DIR, f\"smoke_{exp['name']}.npz\")\n",
    "    trainer.CHECKPOINT_FILE = ckpt_path\n",
    "    trainer.WEIGHTS_FILE = weights_path\n",
    "\n",
    "    print('Parameters:')\n",
    "    print(f\" HIDDEN_SIZE={trainer.HIDDEN_SIZE}, DROPOUT={trainer.DROPOUT}, LR={trainer.LEARNING_RATE}\")\n",
    "    print(f\" EPOCHS={trainer.EPOCHS}, MAX_SAMPLES={trainer.MAX_SAMPLES}\")\n",
    "    print(f\" CHECKPOINT -> {trainer.CHECKPOINT_FILE}\")\n",
    "\n",
    "    # Run training (blocking)\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        trainer.main()\n",
    "    except Exception as e:\n",
    "        print('Erreur pendant trainer.main():', e)\n",
    "        # continue to evaluation attempt (if checkpoint exists)\n",
    "    t1 = time.time()\n",
    "    print(f\"Run time: {t1-t0:.1f}s\")\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    try:\n",
    "        model = trainer.TorchNNEvaluator(hidden_size=trainer.HIDDEN_SIZE, dropout=trainer.DROPOUT, leaky_alpha=trainer.LEAKY_ALPHA)\n",
    "        optimizer = trainer.optim.AdamW(model.parameters(), lr=trainer.LEARNING_RATE, weight_decay=trainer.WEIGHT_DECAY)\n",
    "        model, optim_state, step = trainer.torch_load_checkpoint(trainer.CHECKPOINT_FILE, model, optimizer, device=trainer.DEVICE)\n",
    "\n",
    "        # Evaluation on fixed val set\n",
    "        eval_dataset = trainer.ChessDataset(val_fens, val_targets)\n",
    "        eval_loader = DataLoader(eval_dataset, batch_size=max(1, trainer.BATCH_SIZE//2), shuffle=False)\n",
    "        rmse, mae, corr, preds, targets = trainer.evaluate_model(model, eval_loader, trainer.DEVICE)\n",
    "        print(f\"Eval results — RMSE: {rmse:.4f}, MAE: {mae:.4f}, Corr: {corr:.4f}\")\n",
    "        results.append({'exp': exp['name'], 'rmse': rmse, 'mae': mae, 'corr': corr})\n",
    "    except FileNotFoundError:\n",
    "        print('Checkpoint not found, skipping evaluation for this experiment.')\n",
    "        results.append({'exp': exp['name'], 'rmse': None, 'mae': None, 'corr': None})\n",
    "    except Exception as e:\n",
    "        print('Erreur lors de l\\'évaluation:', e)\n",
    "        results.append({'exp': exp['name'], 'rmse': None, 'mae': None, 'corr': None})\n",
    "\n",
    "    # Restore original trainer settings\n",
    "    for k, v in orig.items():\n",
    "        setattr(trainer, k, v)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('Résumé des smoke tests:')\n",
    "for r in results:\n",
    "    print(r)\n",
    "print('='*80)\n",
    "\n",
    "# End of smoke tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967c73b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320251,
     "status": "ok",
     "timestamp": 1761579911773,
     "user": {
      "displayName": "Gautier de Marsac",
      "userId": "07528850342203083749"
     },
     "user_tz": -60
    },
    "id": "e967c73b",
    "outputId": "d29f6a3e-878b-4c3c-aa0a-776f408f3bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Smoke-extended démarré ===\n",
      "FAST_MODE=False, EPOCHS=5, MAX_SAMPLES=200000, REPS=1\n",
      "Validation fixe : 5000 positions (seed=42)\n",
      "\n",
      "================================================================================\n",
      "Run: baseline_r1_s42\n",
      "================================================================================\n",
      "Params: H=256, dropout=0.3, lr=0.001\n",
      "Run params: EPOCHS=5, MAX_SAMPLES=200000\n",
      "Checkpoint: /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.pt\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "🆕 Création d'un nouveau réseau...\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 200,000 positions\n",
      "  Architecture: 768 → 256 → 256 → 1\n",
      "  Dropout: 0.3\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.001 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.001)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 5\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   1%|          | 10/1563 [00:00<00:16, 96.28it/s, loss=0.8121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=0.0066 std=0.5872; preds mean=0.0398 std=0.0211; RMSE=0.5890; corr=-0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.64it/s, loss=0.7683] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7690  (baseline: 0.8461)\n",
      "  MAE:         0.3093\n",
      "  Amélioration: +9.1% vs baseline\n",
      "  Corrélation: 0.4204\n",
      "  Std preds:   0.3180  (cible: 0.8461)\n",
      "  Mean preds:  0.0279  (cible: 0.0530)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7690 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 1563/1563 [00:16<00:00, 94.14it/s, loss=0.7514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6892  (baseline: 0.7700)\n",
      "  MAE:         0.2941\n",
      "  Amélioration: +10.5% vs baseline\n",
      "  Corrélation: 0.4477\n",
      "  Std preds:   0.3750  (cible: 0.7700)\n",
      "  Mean preds:  0.0466  (cible: 0.0428)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.6892 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.npz\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 1563/1563 [00:16<00:00, 94.53it/s, loss=0.7330]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7087  (baseline: 0.7935)\n",
      "  MAE:         0.2947\n",
      "  Amélioration: +10.7% vs baseline\n",
      "  Corrélation: 0.4514\n",
      "  Std preds:   0.3618  (cible: 0.7935)\n",
      "  Mean preds:  0.0751  (cible: 0.0449)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 4] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 1563/1563 [00:16<00:00, 94.32it/s, loss=0.7103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 4...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 4/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7154  (baseline: 0.8226)\n",
      "  MAE:         0.2909\n",
      "  Amélioration: +13.0% vs baseline\n",
      "  Corrélation: 0.5043\n",
      "  Std preds:   0.3408  (cible: 0.8226)\n",
      "  Mean preds:  0.0697  (cible: 0.0283)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 5] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 1563/1563 [00:16<00:00, 95.96it/s, loss=0.7139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 5...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 5/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7420  (baseline: 0.8668)\n",
      "  MAE:         0.3103\n",
      "  Amélioration: +14.4% vs baseline\n",
      "  Corrélation: 0.5216\n",
      "  Std preds:   0.3995  (cible: 0.8668)\n",
      "  Mean preds:  0.0839  (cible: 0.0555)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.6892\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_baseline_r1_s42.npz\n",
      "Run time: 105.9s\n",
      "Eval — RMSE: 0.7096, MAE: 0.2863, Corr: 0.5116\n",
      "\n",
      "================================================================================\n",
      "Run: bigger_r1_s42\n",
      "================================================================================\n",
      "Params: H=512, dropout=0.2, lr=0.0005\n",
      "Run params: EPOCHS=5, MAX_SAMPLES=200000\n",
      "Checkpoint: /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.pt\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "🆕 Création d'un nouveau réseau...\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 200,000 positions\n",
      "  Architecture: 768 → 512 → 512 → 1\n",
      "  Dropout: 0.2\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.0005 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.0005)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 5\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   1%|          | 9/1563 [00:00<00:17, 88.58it/s, loss=0.8375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=0.0171 std=0.5975; preds mean=0.0703 std=0.0156; RMSE=0.5992; corr=0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 1563/1563 [00:16<00:00, 94.86it/s, loss=0.7670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7691  (baseline: 0.8461)\n",
      "  MAE:         0.3104\n",
      "  Amélioration: +9.1% vs baseline\n",
      "  Corrélation: 0.4199\n",
      "  Std preds:   0.3238  (cible: 0.8461)\n",
      "  Mean preds:  0.0250  (cible: 0.0530)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7691 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.70it/s, loss=0.7467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6976  (baseline: 0.7700)\n",
      "  MAE:         0.2915\n",
      "  Amélioration: +9.4% vs baseline\n",
      "  Corrélation: 0.4266\n",
      "  Std preds:   0.3335  (cible: 0.7700)\n",
      "  Mean preds:  0.0022  (cible: 0.0428)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.6976 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.npz\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.12it/s, loss=0.7267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7056  (baseline: 0.7935)\n",
      "  MAE:         0.2929\n",
      "  Amélioration: +11.1% vs baseline\n",
      "  Corrélation: 0.4578\n",
      "  Std preds:   0.3505  (cible: 0.7935)\n",
      "  Mean preds:  0.0469  (cible: 0.0449)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 4] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.54it/s, loss=0.6997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 4...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 4/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.6933  (baseline: 0.8226)\n",
      "  MAE:         0.2841\n",
      "  Amélioration: +15.7% vs baseline\n",
      "  Corrélation: 0.5655\n",
      "  Std preds:   0.3274  (cible: 0.8226)\n",
      "  Mean preds:  0.0659  (cible: 0.0283)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.6933 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.npz\n",
      "\n",
      "[Epoch 5] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 1563/1563 [00:16<00:00, 92.05it/s, loss=0.6999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 5...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 5/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7186  (baseline: 0.8668)\n",
      "  MAE:         0.3050\n",
      "  Amélioration: +17.1% vs baseline\n",
      "  Corrélation: 0.5688\n",
      "  Std preds:   0.4142  (cible: 0.8668)\n",
      "  Mean preds:  0.0995  (cible: 0.0555)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.6933\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_bigger_r1_s42.npz\n",
      "Run time: 106.4s\n",
      "Eval — RMSE: 0.6877, MAE: 0.2863, Corr: 0.5567\n",
      "\n",
      "================================================================================\n",
      "Run: smaller_lr_r1_s42\n",
      "================================================================================\n",
      "Params: H=512, dropout=0.2, lr=0.0001\n",
      "Run params: EPOCHS=5, MAX_SAMPLES=200000\n",
      "Checkpoint: /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.pt\n",
      "📂 Chargement du dataset depuis /content/drive/MyDrive/smart_chess_drive/chessData.csv...\n",
      "🧹 Nettoyage : 190154 lignes corrompues supprimées.\n",
      "✅ 12,767,881 positions valides chargées.\n",
      "\n",
      "📊 Dataset complet: 12,767,881 positions\n",
      "🆕 Création d'un nouveau réseau...\n",
      "\n",
      "======================================================================\n",
      "Configuration:\n",
      "  Dataset complet: 12,767,881 positions\n",
      "  Échantillon/epoch: 200,000 positions\n",
      "  Architecture: 768 → 512 → 512 → 1\n",
      "  Dropout: 0.2\n",
      "  LeakyReLU alpha: 0.01\n",
      "  Learning rate: 0.0001 (AdamW, weight decay: 0.0001)\n",
      "  LR Warmup: True (0.0001 → 0.0001)\n",
      "  LR Scheduler: True (patience: 2)\n",
      "  Batch size: 128\n",
      "  Epochs: 5\n",
      "  Device: cuda\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 1] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 1/3: LR = 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   1%|          | 9/1563 [00:00<00:17, 86.75it/s, loss=0.8390]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG batch 0] targets mean=0.0171 std=0.5975; preds mean=0.0703 std=0.0156; RMSE=0.5992; corr=0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.36it/s, loss=0.7834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 1...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 1/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7738  (baseline: 0.8461)\n",
      "  MAE:         0.3097\n",
      "  Amélioration: +8.5% vs baseline\n",
      "  Corrélation: 0.4130\n",
      "  Std preds:   0.2835  (cible: 0.8461)\n",
      "  Mean preds:  0.0275  (cible: 0.0530)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7738 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.npz\n",
      "\n",
      "[Epoch 2] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 2/3: LR = 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 1563/1563 [00:17<00:00, 91.79it/s, loss=0.7517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 2...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 2/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7011  (baseline: 0.7700)\n",
      "  MAE:         0.2888\n",
      "  Amélioration: +8.9% vs baseline\n",
      "  Corrélation: 0.4156\n",
      "  Std preds:   0.3176  (cible: 0.7700)\n",
      "  Mean preds:  0.0099  (cible: 0.0428)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "💾 Nouveau meilleur RMSE: 0.7011 - Sauvegarde...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.npz\n",
      "\n",
      "[Epoch 3] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n",
      "🔥 Warmup epoch 3/3: LR = 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 1563/1563 [00:16<00:00, 92.32it/s, loss=0.7288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 3...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 3/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7161  (baseline: 0.7935)\n",
      "  MAE:         0.2941\n",
      "  Amélioration: +9.8% vs baseline\n",
      "  Corrélation: 0.4312\n",
      "  Std preds:   0.3495  (cible: 0.7935)\n",
      "  Mean preds:  0.0364  (cible: 0.0449)\n",
      "  ⚠  Faible amélioration - vérifier hyperparamètres\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 4] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.12it/s, loss=0.7043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 4...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 4/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7098  (baseline: 0.8226)\n",
      "  MAE:         0.2882\n",
      "  Amélioration: +13.7% vs baseline\n",
      "  Corrélation: 0.5228\n",
      "  Std preds:   0.3267  (cible: 0.8226)\n",
      "  Mean preds:  0.0658  (cible: 0.0283)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "[Epoch 5] 🎲 Échantillonnage: 200,000 positions sur 12,767,881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 1563/1563 [00:16<00:00, 93.14it/s, loss=0.7053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Évaluation epoch 5...\n",
      "\n",
      "======================================================================\n",
      "EPOCH 5/5 - Évaluation sur 2,000 positions\n",
      "======================================================================\n",
      "  RMSE:        0.7439  (baseline: 0.8668)\n",
      "  MAE:         0.3054\n",
      "  Amélioration: +14.2% vs baseline\n",
      "  Corrélation: 0.5209\n",
      "  Std preds:   0.3759  (cible: 0.8668)\n",
      "  Mean preds:  0.0659  (cible: 0.0555)\n",
      "  →  Apprentissage en cours\n",
      "======================================================================\n",
      "\n",
      "\n",
      "🎉 Entraînement terminé!\n",
      "📊 Meilleur RMSE: 0.7011\n",
      "\n",
      "💾 Sauvegarde finale...\n",
      "Checkpoint PyTorch sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.pt\n",
      "Poids sauvegardés (npz) dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.npz\n",
      "✅ Modèle sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.pt et /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_ext_smaller_lr_r1_s42.npz\n",
      "Run time: 106.7s\n",
      "Eval — RMSE: 0.6988, MAE: 0.2826, Corr: 0.5368\n",
      "\n",
      "=== Résumé smoke-extended ===\n",
      "                 run         exp  seed      rmse       mae      corr  \\\n",
      "0    baseline_r1_s42    baseline    42  0.709627  0.286289  0.511601   \n",
      "1      bigger_r1_s42      bigger    42  0.687712  0.286316  0.556707   \n",
      "2  smaller_lr_r1_s42  smaller_lr    42  0.698762  0.282603  0.536845   \n",
      "\n",
      "                                                ckpt  \n",
      "0  /content/drive/MyDrive/smart_chess_drive/smart...  \n",
      "1  /content/drive/MyDrive/smart_chess_drive/smart...  \n",
      "2  /content/drive/MyDrive/smart_chess_drive/smart...  \n",
      "Résumé sauvegardé dans /content/drive/MyDrive/smart_chess_drive/smart-chess/ai/checkpoints/smoke_extended_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Smoke-extended paramétrable — runs répétés et mode rapide\n",
    "# Usage:\n",
    "# - régler FAST_MODE=True pour itérations ultra-rapides (EPOCHS=1, MAX_SAMPLES=20k)\n",
    "# - régler REPS pour répéter chaque expérience sur plusieurs seeds\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print('\\n=== Smoke-extended démarré ===')\n",
    "\n",
    "# Paramètres utilisateur\n",
    "FAST_MODE = False        # True -> very fast (useful for quick checks)\n",
    "EPOCHS_EXT = 5\n",
    "MAX_SAMPLES_EXT = 50_000\n",
    "REPS = 1                # nombre de répétitions par configuration\n",
    "BASE_SEED = 42\n",
    "\n",
    "if FAST_MODE:\n",
    "    EPOCHS_EXT = 1\n",
    "    MAX_SAMPLES_EXT = 20_000\n",
    "\n",
    "print(f\"FAST_MODE={FAST_MODE}, EPOCHS={EPOCHS_EXT}, MAX_SAMPLES={MAX_SAMPLES_EXT}, REPS={REPS}\")\n",
    "\n",
    "# Vérifier que trainer est chargé\n",
    "if 'trainer' not in globals():\n",
    "    raise RuntimeError('Le module trainer (ai.NN.train_torch) doit être importé avant d\\'exécuter cette cellule.')\n",
    "\n",
    "# Charger données si nécessaire\n",
    "if 'X_train' not in globals() or 'y_train' not in globals():\n",
    "    print('X_train/y_train non présents en mémoire — chargement via trainer.load_data(...) (peut être long)')\n",
    "    fens, evaluations = trainer.load_data(trainer.DATASET_PATH)\n",
    "    X_train = fens\n",
    "    y_train = evaluations\n",
    "\n",
    "# Création d'une validation fixe\n",
    "val_size = min(5000, len(X_train))\n",
    "rs = np.random.RandomState(42)\n",
    "val_idx = rs.choice(len(X_train), size=val_size, replace=False)\n",
    "val_fens = X_train[val_idx]\n",
    "val_targets = y_train[val_idx]\n",
    "print(f'Validation fixe : {val_size} positions (seed=42)')\n",
    "\n",
    "# Conserver paramètres originaux\n",
    "orig_keys = ['HIDDEN_SIZE','DROPOUT','LEARNING_RATE','WEIGHT_DECAY','BATCH_SIZE','EPOCHS','MAX_SAMPLES','CHECKPOINT_FILE','WEIGHTS_FILE','EVAL_MAX_SAMPLES']\n",
    "orig = {k: getattr(trainer, k) for k in orig_keys if hasattr(trainer, k)}\n",
    "\n",
    "# Expériences à tester\n",
    "experiments = [\n",
    "    {'name': 'baseline', 'HIDDEN_SIZE': orig.get('HIDDEN_SIZE', 256), 'DROPOUT': orig.get('DROPOUT', 0.3), 'LEARNING_RATE': orig.get('LEARNING_RATE', 0.001)},\n",
    "    {'name': 'bigger', 'HIDDEN_SIZE': 512, 'DROPOUT': 0.2, 'LEARNING_RATE': 5e-4},\n",
    "    {'name': 'smaller_lr', 'HIDDEN_SIZE': 512, 'DROPOUT': 0.2, 'LEARNING_RATE': 1e-4},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    for rep in range(REPS):\n",
    "        seed = BASE_SEED + rep\n",
    "        run_name = f\"{exp['name']}_r{rep+1}_s{seed}\"\n",
    "        print('\\n' + '='*80)\n",
    "        print(f\"Run: {run_name}\")\n",
    "        print('='*80)\n",
    "\n",
    "        # appliquer paramètres rapides\n",
    "        trainer.EPOCHS = EPOCHS_EXT\n",
    "        trainer.MAX_SAMPLES = MAX_SAMPLES_EXT\n",
    "        trainer.EVAL_MAX_SAMPLES = min(2000, MAX_SAMPLES_EXT//50)\n",
    "\n",
    "        # appliquer overrides de l'expérience\n",
    "        trainer.HIDDEN_SIZE = exp['HIDDEN_SIZE']\n",
    "        trainer.DROPOUT = exp['DROPOUT']\n",
    "        trainer.LEARNING_RATE = exp['LEARNING_RATE']\n",
    "\n",
    "        # checkpoints séparés\n",
    "        ckpt_path = os.path.join(CKPT_DIR, f\"smoke_ext_{run_name}.pt\")\n",
    "        weights_path = os.path.join(CKPT_DIR, f\"smoke_ext_{run_name}.npz\")\n",
    "        trainer.CHECKPOINT_FILE = ckpt_path\n",
    "        trainer.WEIGHTS_FILE = weights_path\n",
    "\n",
    "        print('Params:', f\"H={trainer.HIDDEN_SIZE}, dropout={trainer.DROPOUT}, lr={trainer.LEARNING_RATE}\")\n",
    "        print('Run params:', f\"EPOCHS={trainer.EPOCHS}, MAX_SAMPLES={trainer.MAX_SAMPLES}\")\n",
    "        print('Checkpoint:', trainer.CHECKPOINT_FILE)\n",
    "\n",
    "        # Fix seeds where possible\n",
    "        try:\n",
    "            import torch\n",
    "            np.random.seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "            if trainer.DEVICE and 'cuda' in str(trainer.DEVICE):\n",
    "                torch.cuda.manual_seed_all(seed)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            trainer.main()\n",
    "        except Exception as e:\n",
    "            print('Erreur pendant trainer.main():', e)\n",
    "        t1 = time.time()\n",
    "        print(f'Run time: {t1-t0:.1f}s')\n",
    "\n",
    "        # Évaluation sur la validation fixe\n",
    "        try:\n",
    "            model = trainer.TorchNNEvaluator(hidden_size=trainer.HIDDEN_SIZE, dropout=trainer.DROPOUT, leaky_alpha=getattr(trainer,'LEAKY_ALPHA',0.01))\n",
    "            optimizer = trainer.optim.AdamW(model.parameters(), lr=trainer.LEARNING_RATE, weight_decay=getattr(trainer,'WEIGHT_DECAY',1e-4))\n",
    "            model, opt_state, step = trainer.torch_load_checkpoint(trainer.CHECKPOINT_FILE, model, optimizer, device=trainer.DEVICE)\n",
    "\n",
    "            eval_dataset = trainer.ChessDataset(val_fens, val_targets)\n",
    "            eval_loader = DataLoader(eval_dataset, batch_size=max(1, trainer.BATCH_SIZE//2), shuffle=False)\n",
    "            rmse, mae, corr, preds, targets = trainer.evaluate_model(model, eval_loader, trainer.DEVICE)\n",
    "            print(f\"Eval — RMSE: {rmse:.4f}, MAE: {mae:.4f}, Corr: {corr:.4f}\")\n",
    "            results.append({'run': run_name, 'exp': exp['name'], 'seed': seed, 'rmse': rmse, 'mae': mae, 'corr': corr, 'ckpt': trainer.CHECKPOINT_FILE})\n",
    "        except FileNotFoundError:\n",
    "            print('Checkpoint introuvable, évaluation sautée.')\n",
    "            results.append({'run': run_name, 'exp': exp['name'], 'seed': seed, 'rmse': None, 'mae': None, 'corr': None, 'ckpt': trainer.CHECKPOINT_FILE})\n",
    "        except Exception as e:\n",
    "            print('Erreur pendant l\\'évaluation:', e)\n",
    "            results.append({'run': run_name, 'exp': exp['name'], 'seed': seed, 'rmse': None, 'mae': None, 'corr': None, 'ckpt': trainer.CHECKPOINT_FILE})\n",
    "\n",
    "        # Restaurer paramètres d'origine\n",
    "        for k, v in orig.items():\n",
    "            setattr(trainer, k, v)\n",
    "\n",
    "print('\\n=== Résumé smoke-extended ===')\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "# Sauvegarder résumé csv\n",
    "summary_path = os.path.join(CKPT_DIR, 'smoke_extended_summary.csv')\n",
    "df.to_csv(summary_path, index=False)\n",
    "print('Résumé sauvegardé dans', summary_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
